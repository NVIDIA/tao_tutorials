{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1defea36",
   "metadata": {},
   "source": [
    "### Notebook to demonstrate TAO SSL MAE Pretraining and Finetuning through FTMS \n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "### TAO Self-Supervised Learning with Masked Autoencoders\n",
    "\n",
    "This notebook demonstrates how to use Self-Supervised Learning (SSL) with Masked Autoencoders (MAE) for model pretraining, followed by finetuning on downstream classification tasks. This two-stage approach helps improve model performance, particularly in scenarios where labeled data is limited but a large volume of unlabeled images is available.\n",
    "\n",
    "Self-Supervised Learning enables a model to learn useful representations from unlabeled data, making it highly effective for domain adaptation. By pretraining on tens or even hundreds of thousands of domain-specific, unlabeled images, the model develops an internal understanding of visual patterns relevant to your use case. This self-learned knowledge becomes a valuable foundation for improving performance on downstream tasks like classification.\n",
    "\n",
    "<img src=\"assets/ssl_mae_workflow_diagram.png\" width=\"800\"/>\n",
    "\n",
    "#### Architecture diagram for MAE\n",
    "\n",
    "<img align=\"center\" src=\"sample_images/mask_auto_encoder.png\" width=\"640\">\n",
    "\n",
    "The process consists of two main stages:\n",
    "\n",
    "**Pretraining Stage**: In this stage, the model is trained using a Masked Autoencoder, which hides (or \"masks\") parts of each input image and trains the model to reconstruct the missing regions. This forces the model to learn meaningful visual features from the data without requiring any labels.\n",
    "\n",
    "**Finetuning Stage**: After pretraining, the model can be finetuned using a smaller set of labeled data. Since the model has already learned generalized visual features, it requires fewer labeled examples to adapt to specific tasks such as classification.\n",
    "\n",
    "SSL with MAE is especially useful if your model isn’t reaching the desired accuracy when trained on labeled data alone, and you have access to a large repository of unlabeled images. It’s a powerful tool to boost performance through domain adaptation—without the costly effort of manual annotation.\n",
    "\n",
    "---\n",
    "The sample image below shows how Self Supervised Learning helps improve the model to look for better domain specific features using unlabelled images.\n",
    "\n",
    "<img align=\"center\" title=\"missing component\" src=\"sample_images/sample_domain_adaptation.png\" width=\"400\" >\n",
    "\n",
    "### The workflow in a nutshell\n",
    "This notebook demonstrates how to use Self-Supervised Learning (SSL) with Masked Autoencoders (MAE) for model pretraining, followed by finetuning on downstream classification tasks. \n",
    "\n",
    "1) Configure Connection to TAO FTMS \n",
    "2) Login & Create Cloud Workspace\n",
    "3) Register Train, Validation and Test datasets\n",
    "4) Pretrain the Masked Auto Encoder backbone through SSL \n",
    "5) Finetune model using pretrained backbone on a classification task \n",
    "6) Export model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5ac1de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Requirements\n",
    "Prior to running this notebook you must have: \n",
    "1) A TAO FTMS server.  [(Setup Guide here)](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)\n",
    "2) The sample MVTec dataset from the [mvtec_ad_classification_dataset_format.ipynb](https://github.com/NVIDIA/tao_tutorials/tree/main/notebooks/tao_api_starter_kit/dataset_prepare/mvtec_ad_classification/mvtec_ad_classification_dataset_format.ipynb) notebook uploaded to your cloud storage.\n",
    "3) Set the `<>` enclosed variables with values in the Configuration section of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001d4256",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Expected outcome\n",
    "The expected output of this notebook is a backbone that's been adapted to the Anomaly detection domain using MAE and a finetuned classification model initialized from the domain adapted backbone.\n",
    "\n",
    "Detailed documentation about the Self-Supervised Learning via Mask Auto Encoders is available in the TAO [documentation](https://docs.nvidia.com/tao/tao-toolkit/text/cv_finetuning/pytorch/self_supervised_learning/mae.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f812175",
   "metadata": {},
   "source": [
    "---\n",
    "### Debugging Finetuning Microservice and Jobs\n",
    "\n",
    "When working with the TAO API, you may encounter issues at different stages. Use the following guidance to debug effectively:\n",
    "\n",
    "#### 1. Dataset, Experiment, or Workspace CRUD Operation Errors\n",
    "\n",
    "If you encounter errors related to creating, reading, updating, or deleting datasets, experiments, or workspaces **and the error messages are not clear**, check the logs of the TAO API service pods:\n",
    "\n",
    "```bash\n",
    "kubectl logs -f <pod name starting with tao-api-app-pod>\n",
    "```\n",
    "\n",
    "#### 2. Errors During Job Launch\n",
    "\n",
    "For issues that occur **while launching a job**, check both the app and workflow pods:\n",
    "\n",
    "```bash\n",
    "kubectl logs -f <pod name starting with tao-api-app-pod>\n",
    "kubectl logs -f <pod name starting with tao-api-workflow-pod>\n",
    "```\n",
    "\n",
    "#### 3. Errors After Job Launch\n",
    "\n",
    "If errors occur **after a job has been launched**, inspect the job pod logs:\n",
    "\n",
    "```bash\n",
    "kubectl logs -f tao-api-sts-<job_id>-0\n",
    "```\n",
    "\n",
    "> **Note:**  \n",
    "> Run these `kubectl` commands on the machine where your Kubernetes service is deployed.\n",
    "\n",
    "#### Additional Debugging Tips\n",
    "\n",
    "- **Job logs are automatically uploaded** to your cloud workspace at:\n",
    "  `/results/<job_id>/microservices_log.txt`\n",
    "\n",
    "- **You can also view logs via the Jobs API endpoint:**  \n",
    "  ```\n",
    "  /api/v1/orgs/<org_name>/<experiments|datasets>/<experiment_id|dataset_id>/jobs/<job_id>/logs\n",
    "  ```\n",
    "\n",
    "**Summary Table**\n",
    "\n",
    "| Error Type                | Where to Check Logs                                      |\n",
    "|-------------------------- |---------------------------------------------------------|\n",
    "| CRUD operation errors     | `tao-api-app-pod`                                       |\n",
    "| Job launch errors         | `tao-api-app-pod`, `tao-api-workflow-pod`               |\n",
    "| Post-launch job errors    | `tao-api-sts-<job_id>-0`                                |\n",
    "| All job logs (cloud)      | `/results/<job_id>/microservices_log.txt`               |\n",
    "| All job logs (API)        | `/api/v1/orgs/<org_name>/<experiments|datasets>/<experiment_id|dataset_id>/jobs/<job_id>/logs` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3aea05",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Performance Benchmarks\n",
    "\n",
    "#### Execution Time Breakdown\n",
    "\n",
    "The following table shows the approximate time required for each stage of the MAE SSL workflow:\n",
    "\n",
    "| **Stage** | **Duration** | **Description** |\n",
    "|-----------|--------------|-----------------|\n",
    "| Train Dataset Pull | **2min** | Train dataset verification and preprocessing |\n",
    "| Val/Test Dataset Pull | **1min** | Validation and test dataset verification |\n",
    "| SSL Pre-Training | **80min** | SSL using MAE on a ConvNext Tiny backbone |\n",
    "| Classification Model Finetuning | **70min** | Finetuning stage to attach a classification task head and train the full model on classifying defects |\n",
    "| Evaluate Finetuned Model | **4min** | Performance assessment of finetuned model |\n",
    "| Export Model to ONNX | **4min** | Export finetuned model to ONNX format |\n",
    "| TRT Engine Generation | **4min** | Generate optimized TensorRT engine |\n",
    "\n",
    "The end to end workflow is estimated to take 165 mins on a single NVIDIA A30 GPU.\n",
    "\n",
    "### Test Environment Specifications\n",
    "\n",
    "| **Component** | **Specification** |\n",
    "|---------------|-------------------|\n",
    "| **GPU** | 1x NVIDIA A30 |\n",
    "| **Training Dataset** | 3747 images (3.4GB total) |\n",
    "| **Validation Dataset** | 803 images (800MB total) |\n",
    "| **Test Dataset** | 804 images (800MB total) |\n",
    "| **Training Epochs** | 80 (both pre-training and finetuning) |\n",
    "| **Model Architecture** | MAE with ConvNext-Tiny backbone |\n",
    "| **Task** | Anomaly defect classification |\n",
    "\n",
    "### Performance Factors\n",
    "\n",
    "> **Important Note:**\n",
    "> Actual execution times may vary significantly based on:\n",
    ">\n",
    "> - **Hardware Configuration**: GPU type, memory, and compute capability\n",
    "> - **Storage Performance**: Local disk I/O speed and cloud storage latency\n",
    "> - **Network Conditions**: Bandwidth and latency to cloud storage\n",
    "> - **System Load**: Other concurrent processes and resource utilization\n",
    "> - **Dataset Size**: Number of images and total data volume\n",
    "> - **Batch Size**: Number of images processed in parallel. Higher batch sizes require more GPU memory\n",
    "> - **Model Configuration**: Backbone architecture, epochs, and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6532aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b88b51",
   "metadata": {},
   "source": [
    "## Configuration \n",
    "\n",
    "Fill in all `<>` enclosed variables with relevant values under this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac063c70",
   "metadata": {},
   "source": [
    "### TAO FTMS Host & Credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIX ME - Configure for your TAO FTMS server \n",
    "host_url = \"<HOST_URL>\"\n",
    "ngc_key = \"<NGC_API_KEY>\"\n",
    "ngc_org_name = \"<NGC_ORG_NAME>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06351c4",
   "metadata": {},
   "source": [
    "### Cloud Storage Setup & Credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud bucket details to access datasets and store experiment results\n",
    "cloud_metadata = {}\n",
    "cloud_metadata[\"name\"] = \"tao_workspace\"  # A Representative name for this cloud info\n",
    "cloud_metadata[\"cloud_type\"] = \"aws\"  # If it's AWS, HuggingFace or Azure\n",
    "cloud_metadata[\"cloud_specific_details\"] = {}\n",
    "cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] =\"<BUCKET_REGION>\"  # Bucket region\n",
    "cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = \"<BUCKET_NAME>\"  # Bucket name\n",
    "# Access and Secret for AWS\n",
    "cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = \"<ACCESS_KEY>\"\n",
    "cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = \"<SECRET_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac7f7e",
   "metadata": {},
   "source": [
    "### Dataset Paths in Cloud Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d4e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust paths to point to datasets in your cloud storage. If using S3 Bucket do not include the bucket name in the path. \n",
    "train_dataset_path =  \"/<PATH_TO_DATASET_IN_CLOUD_STORAGE>/mvtec_ad_classification/train\"\n",
    "eval_dataset_path = \"/<PATH_TO_DATASET_IN_CLOUD_STORAGE>/mvtec_ad_classification/val\"\n",
    "test_dataset_path = \"/<PATH_TO_DATASET_IN_CLOUD_STORAGE>/mvtec_ad_classification/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ed303",
   "metadata": {},
   "source": [
    "### Model Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mae\"\n",
    "ds_type = \"image_classification\"\n",
    "ds_format = \"ssl\"\n",
    "num_classes = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cb008",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e51f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate NGC_PERSONAL_KEY\n",
    "data = json.dumps({\"ngc_org_name\": ngc_org_name,\n",
    "                   \"ngc_key\": ngc_key,\n",
    "                   \"enable_telemetry\": True})\n",
    "response = requests.post(f\"{host_url}/api/v1/login\", data=data)\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"token\" in response.json().keys()\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)\n",
    "\n",
    "# Set base URL\n",
    "base_url = f\"{host_url}/api/v1/orgs/{ngc_org_name}\"\n",
    "print(\"API Calls will be forwarded to\",base_url)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f387a",
   "metadata": {},
   "source": [
    "## Create cloud workspace\n",
    "This workspace will be the place where your datasets reside and results of TAO FTMS jobs will be pushed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151f5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cloud workspace\n",
    "data = json.dumps(cloud_metadata)\n",
    "\n",
    "endpoint = f\"{base_url}/workspaces\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert \"id\" in response.json().keys()\n",
    "workspace_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d7186",
   "metadata": {},
   "source": [
    "## Register datasets with FTMS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa0cf5",
   "metadata": {},
   "source": [
    "TAO FTMS requires datasets in your cloud storage to be registered to produce a unique ID that can be attached to training jobs. This step only needs to be done once and then you can use the dataset across any experiments that support the dataset format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204890db",
   "metadata": {},
   "source": [
    "### List Registered Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bc34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "datasets = response.json()[\"datasets\"]\n",
    "for rsp in datasets:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys\n",
    "    assert \"type\" in rsp_keys\n",
    "    assert \"format\" in rsp_keys\n",
    "    assert \"name\" in rsp_keys\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
    "for rsp in datasets:\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff81134",
   "metadata": {},
   "source": [
    "If you have already registered your datasets, then you can directly set their IDs in the following cell to avoid creating duplicate datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60fa4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_id = None \n",
    "eval_dataset_id = None \n",
    "test_dataset_id = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c00d5",
   "metadata": {},
   "source": [
    "### Train Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf726bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "if train_dataset_id is None: \n",
    "    train_dataset_metadata = {\"type\": ds_type,\n",
    "                              \"format\": ds_format,\n",
    "                              \"workspace\":workspace_id,\n",
    "                              \"cloud_file_path\": train_dataset_path,\n",
    "                              \"use_for\": [\"training\"],\n",
    "                              \"name\": \"mvtec_classification_train\"\n",
    "                              }\n",
    "    data = json.dumps(train_dataset_metadata)\n",
    "    \n",
    "    endpoint = f\"{base_url}/datasets\"\n",
    "    \n",
    "    response = requests.post(endpoint,data=data,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"id\" in response.json().keys()\n",
    "    \n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    train_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b436c",
   "metadata": {},
   "source": [
    "## Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create eval dataset\n",
    "if eval_dataset_id is None: \n",
    "    eval_dataset_metadata = {\"type\": ds_type,\n",
    "                             \"format\": ds_format,\n",
    "                             \"workspace\":workspace_id,\n",
    "                             \"cloud_file_path\": eval_dataset_path,\n",
    "                             \"use_for\": [\"evaluation\"],\n",
    "                             \"name\" : \"mvtec_classification_val\"\n",
    "                             }\n",
    "    data = json.dumps(eval_dataset_metadata)\n",
    "    \n",
    "    endpoint = f\"{base_url}/datasets\"\n",
    "    \n",
    "    response = requests.post(endpoint,data=data,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"id\" in response.json().keys()\n",
    "    \n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    eval_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cf901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bca73f",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing dataset for inference\n",
    "if test_dataset_id is None: \n",
    "    test_dataset_metadata = {\"type\": ds_type,\n",
    "                             \"format\":ds_format,\n",
    "                             \"workspace\":workspace_id,\n",
    "                             \"cloud_file_path\": test_dataset_path,\n",
    "                             \"use_for\": [\"testing\"],\n",
    "                             \"name\": \"mvtec_classification_test\"\n",
    "                             }\n",
    "    data = json.dumps(test_dataset_metadata)\n",
    "    \n",
    "    endpoint = f\"{base_url}/datasets\"\n",
    "    \n",
    "    response = requests.post(endpoint,data=data,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"id\" in response.json().keys()\n",
    "    \n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    test_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{test_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2cf62",
   "metadata": {},
   "source": [
    "## Create Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e2699",
   "metadata": {},
   "source": [
    "Before we can run any jobs such as training, evaluation, distillation or inference, we must create an experiment to setup the network architecture and associated datsets. Then we can chain several jobs together to create our trained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5879b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_key = \"tlt_encode\"\n",
    "checkpoint_choose_method = \"best_model\"\n",
    "data = json.dumps({\"network_arch\":model_name,\n",
    "                   \"encryption_key\":encode_key,\n",
    "                   \"checkpoint_choose_method\":checkpoint_choose_method,\n",
    "                   \"workspace\": workspace_id,\n",
    "                   \"train_datasets\":[train_dataset_id],\n",
    "                   \"eval_dataset\":eval_dataset_id,\n",
    "                   \"inference_dataset\":test_dataset_id,\n",
    "                   \"calibration_dataset\":train_dataset_id})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"id\" in response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "experiment_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53361a2e",
   "metadata": {},
   "source": [
    "When a job is submitted, we will receive a unique ID to reference back to it. We will store these IDs in the following ```job_map``` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ef749",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f7dc07",
   "metadata": {},
   "source": [
    "## SSL Pre-Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716b052",
   "metadata": {},
   "source": [
    "We will first start with self supervised learning using masked auto encoding on a ConvNext Tiny backbone. For this notebook, we will use the training set as an input for this stage. When adapting to your own datasets, it is recommended to have tens or hundreds of thousands of unlabelled images in your pre-training dataset to get measureable results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b58f554",
   "metadata": {},
   "source": [
    "### Retrieve default training spec "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7548410",
   "metadata": {},
   "source": [
    "Before launching a training a job, we can retrieve the default training spec for our network architecture to use as a starting point to configure the training parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eff25e",
   "metadata": {},
   "source": [
    "### Configure Training Spec \n",
    "\n",
    "Now we can customize the json spec object and set our dataset, training and model parameters. To train using SSL we will specify the stage as  ```pretrain```. No other changes are needed unless you are using a custom dataset or model architecture.\n",
    "\n",
    "Detailed information about the configuring the training spec and available hyper parameters are defined [here](https://docs.nvidia.com/tao/tao-toolkit/text/cv_finetuning/pytorch/self_supervised_learning/mae.html#creating-an-experiment-spec-file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64ea0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override any of the parameters listed in the previous cell as required\n",
    "specs[\"train\"][\"stage\"] = \"pretrain\" \n",
    "specs[\"train\"][\"num_gpus\"] = 1\n",
    "specs[\"train\"][\"num_epochs\"] = 10\n",
    "specs[\"train\"][\"checkpoint_interval\"] = 10 # must be less than or equal to num_epochs\n",
    "specs[\"dataset\"][\"batch_size\"] = 32\n",
    "specs[\"dataset\"][\"augmentation\"][\"min_scale\"] = 1.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"max_scale\"] = 1.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"color_jitter\"] = 0.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"auto_aug\"] = \"\" \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup\"] = 0\n",
    "specs[\"dataset\"][\"augmentation\"][\"cutmix\"] = 0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"cutmix_minmax\"] = None \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_prob\"] = 0.0\n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_switch_prob\"] = 0.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_mode\"] = \"batch\" \n",
    "specs[\"model\"][\"arch\"] = \"convnextv2_base\"\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64faad90",
   "metadata": {},
   "source": [
    "### Submit SSL Pre-Training Job \n",
    "\n",
    "With our training spec configured, we can now submit a training job. All jobs follow the same flow of retreiving the default spec, customizing it, then submitting the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d850dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "action = \"train\"\n",
    "data = json.dumps({\"parent_job_id\":None,\"action\":action,\"specs\":specs,\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"pretrain_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafe03a",
   "metadata": {},
   "source": [
    "After submitting the training job, an ID is returned that we can use to monitor the job progress. The following cell will continuously print the latest status until the job is complete. This notebook will track all of the job IDs in the ```job_map``` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c10fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = job_map[\"pretrain_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if \"error_desc\" in response.json().keys() and response.json()[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "        print(\"Job is being created\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272853f",
   "metadata": {},
   "source": [
    "If you need to cancel the job for any reason, you can uncomment and run the following cell. You can also configure the endpoint to end with ```:pause``` or ```:resume``` instead of ```:cancel``` to temporarily stop and start the job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa851dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_id = job_map[\"pretrain_\" + model_name]\n",
    "# endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:cancel\"\n",
    "\n",
    "# response = requests.post(endpoint, headers=headers)\n",
    "# print(response)\n",
    "# print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac867d4",
   "metadata": {},
   "source": [
    "If the job runs into any errors or if you want to check the job logs, you can uncomment and run the following cell to view the job logs. Alternatively, you can view the job logs in your cloud workspace under the path /results/<job_id>/microservices_log.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_id = job_map[\"pretrain_\" + model_name]\n",
    "# endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}/logs\"\n",
    "\n",
    "# response = requests.get(endpoint, headers=headers)\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c7fd7",
   "metadata": {},
   "source": [
    "## Classification Model Finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ef227",
   "metadata": {},
   "source": [
    "With the backbone pretrained, we can now do a finetuning stage to attach a classification task head and train the full model on classifying defects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24285614",
   "metadata": {},
   "source": [
    "### Retrieve default training spec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddc2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "# full_schema = response.json()\n",
    "# print(json.dumps(full_schema, indent=4)) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594aed4",
   "metadata": {},
   "source": [
    "### Configure Training Spec\n",
    "\n",
    "#### Understanding the Spec Schema Structure\n",
    "\n",
    "Before customizing the training spec, it's helpful to understand the available configuration options and their valid values. The `get_bounds_of_field` utility function helps you explore the schema structure and find valid parameter values if they are defined on the backend (for some fields it might not be defined).\n",
    "\n",
    "**How to use the schema exploration utility:**\n",
    "\n",
    "```python\n",
    "from get_bounds import get_bounds_of_field\n",
    "\n",
    "# Example: Get valid values for backbone type\n",
    "# Note the conversion from dictionary access notation to list notation:\n",
    "# From: [\"model\"][\"arch\"]\n",
    "# To:   [\"model\", \"arch\"]\n",
    "print(get_bounds_of_field(full_schema, [\"model\", \"arch\"]))\n",
    "```\n",
    "\n",
    "**Key differences in notation:**\n",
    "- **Dictionary access format**: `[\"model\"][\"arch\"]` - This is how you would access nested values in Python\n",
    "- **Schema path format**: `[\"model\", \"arch\"]` - This is the format expected by the `get_bounds_of_field` function\n",
    "\n",
    "---\n",
    "\n",
    "#### Schema Navigation Tips\n",
    "\n",
    "1. **Nested Structure**: The schema follows a hierarchical structure where each level represents a configuration category\n",
    "2. **Path Format**: Always use a list of strings `[\"level1\", \"level2\", \"level3\"]` when calling `get_bounds_of_field`\n",
    "3. **Validation**: This helps ensure you're using valid parameter values before submitting your training job\n",
    "4. **Documentation**: Use these explorations to understand what options are available for your specific model architecture\n",
    "\n",
    "\n",
    "No changes to the default spec are needed unless you are using a custom dataset format or want to modify the model architecture and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbe4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs[\"train\"][\"stage\"] = \"finetune\" \n",
    "specs[\"train\"][\"num_gpus\"] = 1\n",
    "specs[\"train\"][\"num_epochs\"] = 80\n",
    "specs[\"train\"][\"checkpoint_interval\"] = 20 # must be less than or equal to num_epochs\n",
    "specs[\"train\"][\"validation_interval\"] = 5 # must be less than or equal to num_epochs\n",
    "specs[\"train\"][\"optim\"][\"type\"] = \"AdamW\" \n",
    "specs[\"train\"][\"optim\"][\"lr\"] = 0.001 \n",
    "specs[\"train\"][\"optim\"][\"backbone_multiplier\"] = 1 \n",
    "specs[\"train\"][\"optim\"][\"momentum\"] = 0.9 \n",
    "specs[\"train\"][\"optim\"][\"weight_decay\"] = 0.0\n",
    "specs[\"train\"][\"optim\"][\"layer_decay\"] = 0.0\n",
    "specs[\"train\"][\"optim\"][\"lr_scheduler\"] = \"multistep\" \n",
    "specs[\"train\"][\"optim\"][\"milestones\"] = [10, 20] \n",
    "specs[\"train\"][\"optim\"][\"gamma\"] = 0.1 \n",
    "specs[\"train\"][\"optim\"][\"warmup_epochs\"] = 1 \n",
    "\n",
    "specs[\"dataset\"][\"batch_size\"] = 8\n",
    "specs[\"dataset\"][\"num_workers_per_gpu\"] = 8\n",
    "\n",
    "specs[\"dataset\"][\"augmentation\"][\"min_scale\"] = 1.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"max_scale\"] = 1.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"color_jitter\"] = 0.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"auto_aug\"] = \"\" \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup\"] = 0\n",
    "specs[\"dataset\"][\"augmentation\"][\"cutmix\"] = 0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"cutmix_minmax\"] = None \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_prob\"] = 0.0\n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_switch_prob\"] = 0.0 \n",
    "specs[\"dataset\"][\"augmentation\"][\"mixup_mode\"] = \"batch\" \n",
    "\n",
    "specs[\"model\"][\"arch\"] = \"convnextv2_base\"\n",
    "specs[\"model\"][\"num_classes\"] = 2\n",
    "\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8475018",
   "metadata": {},
   "source": [
    "### Submit Finetune Training Job "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd0524",
   "metadata": {},
   "source": [
    "To use the backbone from the pretraining stage, it needs to be set as the parent job. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a0607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"pretrain_\" + model_name]\n",
    "action = \"train\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":specs,})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"finetune_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8913445",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = job_map[\"finetune_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if \"error_desc\" in response.json().keys() and response.json()[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "        print(\"Job is being created\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95192092",
   "metadata": {},
   "source": [
    "## Evaluate Finetuned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a336aa12",
   "metadata": {},
   "source": [
    "### Receive default evaluation spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce60a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/evaluate/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37cf61",
   "metadata": {},
   "source": [
    "### Customize Evaluation Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce682665",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs[\"train\"][\"stage\"] = \"finetune\" \n",
    "\n",
    "specs[\"dataset\"][\"batch_size\"] = 8\n",
    "specs[\"dataset\"][\"num_workers_per_gpu\"] = 8\n",
    "\n",
    "specs[\"model\"][\"arch\"] = \"convnextv2_base\"\n",
    "specs[\"model\"][\"num_classes\"] = 2\n",
    "\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc709f98",
   "metadata": {},
   "source": [
    "### Submit Evaluation Job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"finetune_\" + model_name] #parent is now distillation job. This evaluation will use the distilled model. \n",
    "action = \"evaluate\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":specs,\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"evaluate_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2dc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "job_id = job_map[\"evaluate_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e88d248",
   "metadata": {},
   "source": [
    "## TRT Engine Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a862dd",
   "metadata": {},
   "source": [
    "Now that we have a finetuned model, it can be exported to ONNX format then turned into an optimzed TensorRT engine for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800b549",
   "metadata": {},
   "source": [
    "### Export Model to ONNX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87711735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/export/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1b3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs[\"train\"][\"stage\"] = \"finetune\" \n",
    "specs[\"model\"][\"arch\"] = \"convnextv2_base\"\n",
    "specs[\"model\"][\"num_classes\"] = 2\n",
    "specs[\"export\"][\"input_channel\"] = 3 \n",
    "specs[\"export\"][\"input_width\"] = 224\n",
    "specs[\"export\"][\"input_height\"] = 224 \n",
    "specs[\"export\"][\"batch_size\"] = -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced7f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"finetune_\" + model_name] #parent is now distillation job. This will export the distilled model.  \n",
    "action = \"export\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":specs,\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"export_finetuned_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "job_id = job_map[\"export_finetuned_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f151e",
   "metadata": {},
   "source": [
    "### Convert ONNX to TRT Engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a0e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/gen_trt_engine/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "specs = response.json()[\"default\"]\n",
    "print(json.dumps(specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8d8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs[\"train\"][\"stage\"] = \"finetune\" \n",
    "specs[\"model\"][\"arch\"] = \"convnextv2_base\"\n",
    "specs[\"model\"][\"num_classes\"] = 2\n",
    "specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"FP16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map[\"export_finetuned_\" + model_name]\n",
    "action = \"gen_trt_engine\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":specs,\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"model_gen_trt_engine_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "job_id = job_map['model_gen_trt_engine_' + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally run this section to delete the datasets and experiment results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete experiment <a class=\"anchor\" id=\"head-23\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete train dataset <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete val dataset <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete test dataset <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{test_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
