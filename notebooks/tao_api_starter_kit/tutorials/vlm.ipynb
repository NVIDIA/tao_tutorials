{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba4b47d",
   "metadata": {},
   "source": [
    "# VLM Finetuning Microservices Workflow with TAO \n",
    "\n",
    "[NVIDIA TAO](https://docs.nvidia.com/tao/tao-toolkit/text/overview.html) is a framework for customizing and optimizing vision-related models, to achieve higher accuracy and better performance. In TAO 6.25.10 release, we introduce VLM into our Finetuning Microservices (FTMS). This allows customers to finetune pre-trained VLMs like **Cosmos Reason**, with video/image-text data at scale.\n",
    "\n",
    "This Notebook will go over the steps to **finetune [Cosmos Reason](https://huggingface.co/nvidia/Cosmos-Reason1-7B) with [TAO FTMS](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_overview.html)**. And how to achieve higher accuracy with **AutoML**. \n",
    "\n",
    "\n",
    "For details on example fine-tuning use cases, please check out our two fine-tuning cookbooks for Cosmos Reason: [Reason for Visual Q&A in ITS](https://nvidia-cosmos.github.io/cosmos-cookbook/recipes/post_training/reason1/intelligent-transportation/post_training.html) and [Reason for Warehouse Safety](https://nvidia-cosmos.github.io/cosmos-cookbook/recipes/post_training/reason1/spatial-ai-warehouse/post_training.html). \n",
    "\n",
    "![Finetuning Workflow](../example_images/finetuning_workflow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9c806",
   "metadata": {},
   "source": [
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [TAO FTMS Prerequisites](#head-1)\n",
    "3. [Dataset Preparation for VLM Fine-tuning](#head-3)\n",
    "4. [Experiments](#head-4)\n",
    "5. [AutoML Configuration](#head-4-4) \n",
    "5. [Launch Fine-Tuning](#head-5)\n",
    "6. [Model Evaluate](#head-6)\n",
    "7. [Finish Experiment and Cleanup](#head-7)\n",
    "8. [Model Deployment](#head-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a0e4d",
   "metadata": {},
   "source": [
    "## 1. Prerequisites <a class=\"anchor\" id=\"head-1\"></a>\n",
    "\n",
    "### 1.1 TAO API service\n",
    "\n",
    "The TAO API is a cloud service for end‑to‑end model development. With a few calls you can import cloud datasets, pull pretrained models and default specs from the Nvidia Cloud Registry (NGC), train, evaluate, optimize, and export models for edge/cloud deployment— all on GPU‑powered, multi‑node clusters.\n",
    "\n",
    "To get started with TAO APIs:\n",
    "\n",
    "**Hardware and Software Minimum Requirements:**\n",
    "\n",
    "- Minimum 8x A100 GPUs with at least 80 GiB GPU memory.\n",
    "- OS: Ubuntu 22.04+\n",
    "- Drivers: 570+\n",
    "- CUDA: 12.8+\n",
    "- Python: 3.12+\n",
    "\n",
    "**Setup TAO APIs**\n",
    "\n",
    "- Follow [TAO API deployment steps](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#deployment-steps) 1-8\n",
    "- After successfully installing these steps, you will have a server setup with Kubernetes (K8s) and TAO APIs\n",
    "\n",
    "### 1.2 Set Required Parameters\n",
    "\n",
    "Before running this notebook, ensure you have the following information:\n",
    "\n",
    "1. **Host URL:** The host URL is the external access point to a Kubernetes service, constructed using the node’s IP address and the service’s exposed NodePort. Example: http://<ip_address>:<port_number>\n",
    "1. **NGC Key:** Your NGC (NVIDIA GPU Cloud) API key.\n",
    "1. **Huggingface token:** Huggingface token obtained from [here](https://huggingface.co/settings/tokens).\n",
    "1. **NGC Organization Name:** The name of your NGC organization.\n",
    "1. **Cloud Storage Details:** Set your cloud storage details (e.g., bucket name, region).\n",
    "1. **Datasets Path:** The path of datasets relative to the cloud storage bucket.\n",
    "\n",
    "Replace the **FIXME** placeholders in the code cells below with the appropriate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1c322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"cosmos-rl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ed163",
   "metadata": {},
   "source": [
    "#### Configure AutoML Parameters\n",
    "\n",
    "[AutoML documentation](https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#getting-started)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoML Configuration\n",
    "automl_algorithm = \"bayesian\"\n",
    "automl_max_recommendations = 5  # Number of AutoML experiments to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f74845a",
   "metadata": {},
   "source": [
    "#### 1.2.2 Set API service's host information\n",
    "\n",
    "The steps in 1.1 will install a k8 server and TAO APIs, and once that is installed, you will need a host_url to call the APIs running on the current host.\n",
    "To access the host_url: \n",
    "\n",
    "In the host machine, node ip_address and port number can be obtained as follows,\n",
    "- **ip_address**: hostname -i\n",
    "- **port_number**: kubectl get service ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port number is 32080 for K8s deployment and 8090 for docker-compose deployment\n",
    "# IP address is the IP address of the host machine for K8s deployment and localhost for docker-compose deployment\n",
    "host_url = \"http://<ip_address>:<port_number>\" # FIXME1. eg: https://10.137.149.22:32080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070b142c",
   "metadata": {},
   "source": [
    "#### 1.2.3 Set NGC Personal key for authentication and NGC org to access API services\n",
    "\n",
    "- **ngc_key**: [How to access NGC key](https://docs.nvidia.com/ai-enterprise/deployment/spark-rapids-accelerator/latest/appendix-ngc.html#ngc-api-key)\n",
    "- **ngc_org_name**: [How to access NGC org Name](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html#accessing-ngc-org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dbe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_key = \"<ngc_personal_key>\" # FIXME2. Make sure to add NGC Personal key\n",
    "hf_token = \"<huggingface_token>\" # FIXME3. Add your Huggingface token - needed so that Huggingface doesn't rate limit you.\n",
    "ngc_org_name = \"nvstaging\" # FIXME4. Add your NGC ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c5e46",
   "metadata": {},
   "source": [
    "## 2. Login to the host <a class=\"anchor\" id=\"head-2\"></a>\n",
    "The JWT (JSON Web Token) is a secure authentication mechanism used by the TAO Finetuning Microservices. When you authenticate with your NGC credentials, the API returns this token, which is then used for all subsequent API calls. This token has a limited lifetime and represents your authenticated session.\n",
    "\n",
    "The following cell ensures you are able to access the service and generate a JWT Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b64810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate NGC_PERSONAL_KEY\n",
    "data = json.dumps({\"ngc_org_name\": ngc_org_name,\n",
    "                   \"ngc_key\": ngc_key})\n",
    "response = requests.post(f\"{host_url}/api/v1/login\", data=data)\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)\n",
    "\n",
    "# Set base URL\n",
    "base_url = f\"{host_url}/api/v1/orgs/{ngc_org_name}\"\n",
    "print(\"API Calls will be forwarded to\",base_url)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87981f8",
   "metadata": {},
   "source": [
    "### 2.1 Create cloud workspace\n",
    "This creates a workspace that links your TAO Finetuning Microservices session to your cloud storage. The API will use these credentials to:\n",
    "\n",
    "- Pull datasets from your bucket\n",
    "- Store training results and checkpoints\n",
    "- Upload evaluation results\n",
    "\n",
    "If you want to have different workspaces for datasets and experiments, duplicate the workspace creation part and adjust the metadata accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME5 Cloud bucket details to access datasets and store experiment results\n",
    "cloud_metadata = {\n",
    "    \"name\": \"tao_workspace\",\n",
    "    \"cloud_type\": \"aws\",\n",
    "    \"cloud_specific_details\": {\n",
    "        \"cloud_region\": \"us-west-1\",\n",
    "        \"cloud_bucket_name\": \"\",\n",
    "        \"access_key\": \"\",\n",
    "        \"secret_key\": \"\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc71920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps(cloud_metadata)\n",
    "\n",
    "endpoint = f\"{base_url}/workspaces\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "workspace_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16132bee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62ca9b61",
   "metadata": {},
   "source": [
    "## 3.1 Dataset Preparation <a class=\"anchor\" id=\"head-3\"></a>\n",
    "\n",
    "For Cosmos-RL finetuning, we expect the directory tree to follow this structure:\n",
    "\n",
    "```\n",
    "<any folder in cloud bucket>/\n",
    "├── images.tar.gz\n",
    "├── annotations.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f83100",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "For this experiment, we will demonstrate on the [Physical AI Spatial Intelligence Warehouse dataset](https://huggingface.co/datasets/nvidia/PhysicalAI-Spatial-Intelligence-Warehouse/tree/main). This is a completely synthetic dataset of a warehouse with 95K images along with around 500k annotations : Q&A pairs with related meta information in LLaVA format for VLM training.  Tasks included distance, counting, multiple-choice grounding, and spatial relation reasoning.\n",
    "\n",
    "Below example shows the RGB frame, depth map, annotated regions, the corresponding question, and sample answers.\n",
    "The distribution of question types demonstrated the diversity of reasoning skills required across tasks.\n",
    "\n",
    "<img src=\"assets/data_overview.png\" width=\"960\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Sample JSON Entry\n",
    "\n",
    "Specifically, the annotation contains several additional attributes compared to general [LLaVa format](https://github.com/haotian-liu/LLaVA/blob/main/docs/Finetune_Custom_Data.md):\n",
    "\n",
    "- **normalized_answer** field for quantitative evaluation with accuracy and error metrics between ground-truth and predicted answer.\n",
    "- **freeform_answer** field, which is the original answer from 'gpt'.\n",
    "- **rle** denotes the corresponding masks per object in pycoco format.\n",
    "- **category** denotes the question category. The categories are left_right, multi_choice_question(mcq), distance, and count.\n",
    "\n",
    "Here's an example of the annotation format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": \"9d17ba0ab1df403db91877fe220e4658\",\n",
    "    \"image\": \"000190.png\",\n",
    "    \"conversations\": [\n",
    "      {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"<image>\\nCould you measure the distance between the pallet <mask> and the pallet <mask>?\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": \"The pallet [Region 0] is 6.36 meters from the pallet [Region 1].\"\n",
    "      }\n",
    "    ],\n",
    "    \"rle\": [\n",
    "      {\n",
    "      \"size\": [\n",
    "          1080,\n",
    "          1920\n",
    "      ],\n",
    "      \"counts\": \"bngl081MYQ19010ON2jMDmROa0ol01_RO2^m0`0PRODkm0o0bQOUO[n0U2N2M3N2N2N3L3N2N1N1WO_L]SO\"\n",
    "      },\n",
    "      {\n",
    "      \"size\": [\n",
    "          1080,\n",
    "          1920\n",
    "      ],\n",
    "      \"counts\": \"^PmU1j1no000000000000000000001O0000000000001O0000000000001O0000000000001O0000000000\"\n",
    "      }\n",
    "    ],\n",
    "    \"category\": \"distance\",\n",
    "    \"normalized_answer\": \"6.36\",\n",
    "    \"freeform_answer\": \"The pallet [Region 0] is 6.36 meters from the pallet [Region 1].\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238803fe",
   "metadata": {},
   "source": [
    "Follow the data pre-processing scripts [here](https://github.com/nvidia-cosmos/cosmos-cookbook/blob/main/docs/recipes/post_training/reason1/spatial-ai-warehouse/post_training.md#data-preprocessing) and then transfer the processed data onto your cloud storage for both your train and evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME6: Set paths relative to cloud bucket\n",
    "train_dataset_path =  \"/data/cosmos_rl_sdg_20k_train\" # example train data is at workspace_dir/data/\n",
    "eval_dataset_path = \"/data/cosmos_rl_sdg_20k_val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f6255",
   "metadata": {},
   "source": [
    "### 3.2 Set dataset formats\n",
    "\n",
    "The dataset format parameters define how your data is structured:\n",
    "- `ds_type = \"vlm\"`: Indicates this is a Vision-Language Model dataset\n",
    "- `ds_format = \"llava\"`: Uses the default format expected by Cosmos-RL\n",
    "\n",
    "The \"default\" format for VLM datasets typically includes:\n",
    "- Video files or image sequences\n",
    "- Text annotations/captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_type = \"vlm\"\n",
    "ds_format = \"llava\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5091257",
   "metadata": {},
   "source": [
    "### 3.3 Create and pull train dataset\n",
    "\n",
    "Add all the training dataset metadata to *datasets* api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f009559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "train_dataset_metadata = {\"type\": ds_type,\n",
    "                          \"format\": ds_format,\n",
    "                          \"workspace\":workspace_id,\n",
    "                          \"cloud_file_path\": train_dataset_path,\n",
    "                          \"use_for\": [\"training\"]\n",
    "                          }\n",
    "\n",
    "data = json.dumps(train_dataset_metadata)\n",
    "\n",
    "endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "train_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314fe24",
   "metadata": {},
   "source": [
    "Below cell checks the download progress till the dataset pull is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9898233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898823b",
   "metadata": {},
   "source": [
    "### 3.4 Create and pull evaluation dataset\n",
    "\n",
    "Similar to training data, add eval dataset metadata as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bdb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset\n",
    "eval_dataset_metadata = {\"type\": ds_type,\n",
    "                          \"format\": ds_format,\n",
    "                          \"workspace\":workspace_id,\n",
    "                          \"cloud_file_path\": eval_dataset_path,\n",
    "                          \"use_for\": [\"evaluation\"]\n",
    "                          }\n",
    "\n",
    "data = json.dumps(eval_dataset_metadata)\n",
    "\n",
    "endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "eval_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29bf87",
   "metadata": {},
   "source": [
    "Below cell checks the download progress till the dataset pull is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283cc7c",
   "metadata": {},
   "source": [
    "##### 3.5 List the created datasets <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c985fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "print(response)\n",
    "\n",
    "datasets = response.json()[\"datasets\"]\n",
    "for rsp in datasets:\n",
    "    rsp_keys = rsp.keys()\n",
    "\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
    "for rsp in datasets:\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65bf881",
   "metadata": {},
   "source": [
    "## 4. Experiments <a class=\"anchor\" id=\"head-4\"></a>\n",
    "\n",
    "In the TAO finetuning microservices, experiments are used for workflow management with the following key features:\n",
    "- **Workflow Chaining:** Chain multiple model actions together with defined dependencies\n",
    "- **Dependency Management:** Create structured workflows with clear dependencies between actions\n",
    "- **Metadata Configuration:** Each experiment can incorporate various metadata:\n",
    "    - Docker environment variables\n",
    "    - Cloud workspace assignment for storing model action results\n",
    "    - Pretrained model to be used in the workflow\n",
    "    - Datasets that are to be used in the workflow\n",
    "\n",
    "### 4.1 Create experiment for VLM workflow\n",
    "\n",
    "Define the experiment arguments\n",
    "\n",
    "- network_arch\n",
    "- workspace id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a14aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\"network_arch\":model_name,\n",
    "                   \"workspace\": workspace_id})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "experiment_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f1991",
   "metadata": {},
   "source": [
    "### 4.2 List experiments\n",
    "\n",
    "Validate that the experiment is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13728f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments\"\n",
    "params = {\"network_arch\": \"cosmos-rl\"}\n",
    "response = requests.get(endpoint, params=params, headers=headers)\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"model id\\t\\t\\t     network architecture\")\n",
    "for rsp in response.json()[\"experiments\"]:\n",
    "    rsp_keys = rsp.keys()\n",
    "    print(rsp[\"name\"], rsp[\"id\"],rsp[\"network_arch\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a9b8a",
   "metadata": {},
   "source": [
    "### 4.3 Assign train, eval datasets\n",
    "\n",
    "Set dataset configuration for training and evaluation.\n",
    "\n",
    "- Set the docker env variable: we are using HF token to pull the evalution dataset from HF.\n",
    "- Define train_datasets and eval_datasets from above train and eval data ids (check section 3.3 and 3.4)\n",
    "- add dataset_information to *experiments id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d68f10d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docker_env_vars = {\"HF_TOKEN\": hf_token}\n",
    "dataset_information = {\"train_datasets\":[train_dataset_id],\n",
    "                       \"eval_dataset\": eval_dataset_id,\n",
    "                       \"docker_env_vars\": docker_env_vars\n",
    "                       }\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f219f39",
   "metadata": {},
   "source": [
    "#### 4.4 Update Experiment with AutoML Paramaters <a class=\"anchor\" id=\"head-4-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087a17c",
   "metadata": {},
   "source": [
    "##### 4.4.1 View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"automl_default_parameters\" in response.json().keys()\n",
    "automl_params = response.json()[\"automl_default_parameters\"]\n",
    "print(json.dumps(automl_params, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2727c54b",
   "metadata": {},
   "source": [
    "#### AutoML Parameters Configuration\n",
    "\n",
    "The `automl_params` list retrieved above contains the **default AutoML hyperparameters** that have been carefully chosen for this model architecture.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "- ✅ **Recommended**: Use the default parameters as-is — they are handpicked and validated for optimal performance\n",
    "- 🔧 **Customizable**: You can add, modify, or remove parameters based on your specific requirements\n",
    "- ⚠️ **Important**: Any modifications to this list will directly affect the AutoML experiment behavior\n",
    "\n",
    "Ignore the lora parameters, as the fine-tuning mode being used in the tutorial is full SFT.\n",
    "\n",
    "1. **`custom.vision.fps`**\n",
    "   - Video sampling rate in frames per second for vision-language models. Higher FPS captures more temporal information but increases memory usage.\n",
    "   - Valid range: 1-3\n",
    "\n",
    "2. **`train.epoch`**\n",
    "   - Total number of training epochs (complete passes through the dataset).\n",
    "   - Valid range: 10-20\n",
    "\n",
    "3. **`train.optm_name`**\n",
    "   - Optimizer algorithm: 'AdamW' (Adam with decoupled weight decay, recommended) or 'Adam' (original).\n",
    "   - Valid options: AdamW, Adam\n",
    "\n",
    "4. **`train.optm_warmup_epochs`**\n",
    "   - Number of epochs for linear learning rate warmup, from 0 to `optm_lr`. Helps stabilize training (recommended: epochs/10).\n",
    "   - Valid range: 0-inf\n",
    "\n",
    "5. **`train.optm_betas`**\n",
    "   - Beta coefficients for Adam/AdamW: [beta1, beta2] for exponential moving averages of gradient and squared gradient.\n",
    "   - Default: [0.9, 0.999]\n",
    "\n",
    "6. **`train.optm_lr`**\n",
    "   - Peak learning rate for optimizer. Actual LR follows warmup and cosine decay schedule.\n",
    "   - Valid range: 0-inf\n",
    "   - Default: 1e-06\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "The final `automl_params` configuration (after any modifications) will be used to launch the AutoML training experiments in the subsequent cells.\n",
    "\n",
    "The below cell will list all the parameters that are used during training, which you can add to the `automl_params` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(nested_dict, parent_key='', sep='.'):\n",
    "    items = []\n",
    "    for key, value in nested_dict.items():\n",
    "        new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n",
    "        if isinstance(value, dict):\n",
    "            items.extend(flatten_dict(value, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, value))\n",
    "    return dict(items)\n",
    "\n",
    "param = flatten_dict(response.json()[\"default\"])\n",
    "for k, v in param.items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e87fee",
   "metadata": {},
   "source": [
    "##### Update the experiment metadata with automl parameters to run experiments on <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56dc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_information = {\n",
    "    \"automl_enabled\": True,\n",
    "    \"automl_algorithm\": automl_algorithm,\n",
    "    \"automl_max_recommendations\": automl_max_recommendations,\n",
    "    \"automl_hyperparameters\": str(automl_params)\n",
    "}\n",
    "data = json.dumps({\"metric\":\"kpi\", \"automl_settings\": automl_information})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, headers=headers, data=data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(json.dumps(response.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de4bfc",
   "metadata": {},
   "source": [
    "## 5. Launch Fine-tuning <a class=\"anchor\" id=\"head-5\"></a>\n",
    "\n",
    "For all **Actions**:\n",
    "1. Get default spec schema and derive the default values\n",
    "2. Modify defaults if needed\n",
    "3. Post spec dictionary to the service\n",
    "4. Run model action\n",
    "5. Monitor job using retrieve\n",
    "6. Download results using job download endpoint (if needed)\n",
    "\n",
    "**Note** Here Actions stand for TAO Apis for: *train/eval/infer/..*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443d574",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bc9fc",
   "metadata": {},
   "source": [
    "### 5.1 Get default spec schema\n",
    "\n",
    "List all the possible configuration needed for finetuning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a423a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema \n",
    "train_specs = response.json()[\"default\"]\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad3616",
   "metadata": {},
   "source": [
    "### 5.2 Customize train model configuration\n",
    "\n",
    "Override any of the configration for example update the batch size for training or num of gpus etc.\n",
    "- `dp_shard_size` is the number of GPUs to be used for training\n",
    "- For OOM issues\n",
    "  - Try reducing the following\n",
    "    - `dataloader_num_workers`\n",
    "    - `dataloader_prefetch_factor`\n",
    "    - `mini_batch`\n",
    "    - `total_pixels`\n",
    "    - `fps`\n",
    "    - `train_batch_per_replica`\n",
    "    - `model_max_length`\n",
    "  - Disable\n",
    "    - `enable_dataset_cache`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b8fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_specs[\"train\"][\"epoch\"] = 1\n",
    "train_specs[\"train\"][\"ckpt\"][\"save_freq_in_epoch\"] = 1\n",
    "train_specs[\"validation\"][\"freq_in_epoch\"] = 1\n",
    "\n",
    "train_specs[\"train\"][\"ckpt\"][\"save_mode\"] = \"sync\"\n",
    "\n",
    "train_specs[\"train\"][\"train_policy\"] = {\n",
    "    \"dataset\":{\n",
    "        \"name\":\"sdg\",\n",
    "        \"test_size\":1,\n",
    "    },\n",
    "    \"type\":\"sft\",\n",
    "    \"enable_dataset_cache\":True,\n",
    "    \"dataloader_num_workers\":8,\n",
    "    \"dataloader_prefetch_factor\":8,\n",
    "    \"conversation_column_name\":\"conversations\",\n",
    "    \"mini_batch\":4,\n",
    "}\n",
    "\n",
    "if \"max_pixels\" in train_specs[\"custom\"][\"vision\"]:\n",
    "    del train_specs[\"custom\"][\"vision\"][\"max_pixels\"]\n",
    "train_specs[\"custom\"][\"vision\"][\"total_pixels\"] = 3136000\n",
    "train_specs[\"custom\"][\"vision\"][\"fps\"] = 1.0\n",
    "\n",
    "train_specs[\"policy\"][\"parallelism\"][\"dp_shard_size\"] = 8\n",
    "\n",
    "train_specs[\"train\"][\"train_batch_per_replica\"] = 32\n",
    "train_specs[\"policy\"][\"model_max_length\"] = 8192\n",
    "train_specs[\"custom\"][\"dataset\"][\"system_prompt\"] = \"Answer the questions.\"\n",
    "\n",
    "if \"lora\" in train_specs[\"policy\"]:\n",
    "    del train_specs[\"policy\"][\"lora\"]\n",
    "\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1f90f",
   "metadata": {},
   "source": [
    "### 5.3 Run *train* Action \n",
    "\n",
    "Run *train* action with the configurations defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818062af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action = \"train\"\n",
    "train_request_body = {\n",
    "    \"parent_job_id\":None,\n",
    "    \"action\":action,\n",
    "    \"specs\":train_specs}\n",
    "data = json.dumps(train_request_body)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"train\"] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003b849",
   "metadata": {},
   "source": [
    "### 5.4 Monitor Job Status\n",
    "\n",
    "The cell below will continuously monitor your training job and display real-time progress updates. This monitoring loop will automatically refresh until the job completes, fails, or is manually stopped.\n",
    "\n",
    "#### Expected Training Times\n",
    "\n",
    "- **Baseline**: Each experiment running for **1 epoch** takes approximately **55 minutes on 8x A100 GPUs**\n",
    "- **Scaling**: Training time scales linearly with the number of epochs\n",
    "  - 5 epochs ≈ 4.5 hours\n",
    "  - 10 epochs ≈ 9 hours\n",
    "  - 20 epochs ≈ 18 hours\n",
    "\n",
    "#### Job Metadata Information\n",
    "\n",
    "The job status response provides comprehensive information about your AutoML training:\n",
    "\n",
    "- **Individual Experiment Details**:\n",
    "  - Unique `job_id` for each AutoML experiment\n",
    "  - Current hyperparameter configuration being tested\n",
    "  - Per-experiment metrics and status\n",
    "  \n",
    "- **AutoML Brain Summary**:\n",
    "  - Number of experiments remaining in the AutoML search\n",
    "  - Estimated Time to Completion (ETA)\n",
    "  - Current best metric value across all experiments\n",
    "  - Recommendation progress and performance trends\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Note:</b> To stop the training job at any time, refer to the instructions in the next cell below.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afefbe4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_id = job_map[\"train\"]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if \"error_desc\" in response.json().keys() and response.json()[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "        print(\"Job is being created\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa20e1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### To Stop the finetuning Job\n",
    "1. Stop code cell in step 5.4 (the cell right before this cell) manually\n",
    "2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab86a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# job_id = job_map[\"train\"]\n",
    "# endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:pause\"\n",
    "\n",
    "# response = requests.post(endpoint, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7140dfa1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Resume Finetuning job\n",
    "\n",
    "Uncomment the below snippet if you want to resume an already stopped finetuning job and then run code cell in step **5.3 Monitor job status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919d91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# job_id = job_map[\"train\"]\n",
    "# endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:resume\"\n",
    "\n",
    "# data = json.dumps({\"parent_job_id\":None, \"specs\":train_specs})\n",
    "# response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "# print(response)\n",
    "# print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1c760",
   "metadata": {},
   "source": [
    "## 6. Evaluate <a class=\"anchor\" id=\"head-6\"></a>\n",
    "\n",
    "Once the model is finetuned, we start evaluation. The model used in evaluation will be as per the predefined checkpoint chosen method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfeb4dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/evaluate/schema\"\n",
    "\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "evaluate_specs = response.json()[\"default\"][\"evaluate\"]\n",
    "print(json.dumps(evaluate_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a191f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate_specs[\"vision\"][\"fps\"] = 1.0\n",
    "evaluate_specs[\"vision\"][\"total_pixels\"] = 3136000\n",
    "print(json.dumps(evaluate_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a812f3",
   "metadata": {},
   "source": [
    "### 6.1 Run *evaluate* action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dd268",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"train\"]\n",
    "action = \"evaluate\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":evaluate_specs})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"evaluate\"] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64142328",
   "metadata": {},
   "source": [
    "#### Monitor job status by repeatedly running this cell. Stop the cell when you are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80642472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_id = job_map[\"evaluate\"]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dd180",
   "metadata": {},
   "source": [
    "## 7. Finish Experiment and Cleanup <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188da86",
   "metadata": {},
   "source": [
    "### 7.1 Delete dataset\n",
    "#### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fd9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e0063",
   "metadata": {},
   "source": [
    "#### Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb18680",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971ba05",
   "metadata": {},
   "source": [
    "## 8. Model Deployment <a class=\"anchor\" id=\"head-8\"></a>\n",
    "\n",
    "To deploy a post-trained checkpoint, refer to the [Model Deployment session in Cosmos Cookbook](https://nvidia-cosmos.github.io/cosmos-cookbook/recipes/post_training/reason1/intelligent-transportation/post_training.html#model-deployment). It has instructions on deploying with NIM and NVIDIA VSS blueprint, plus how to perform FP8 quantization. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
