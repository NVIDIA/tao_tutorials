{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### TAO remote client - Purpose built models\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Pulling datasets from cloud\n",
    "- Running dataset convert (for specific models)\n",
    "- Getting a PTM from NGC\n",
    "- Model Actions\n",
    "    - Train (Normal/AutoML)\n",
    "    - Evaluate\n",
    "    - Prune, retrain (for specific models)\n",
    "    - Export\n",
    "    - TAO-Deploy (for specific models)\n",
    "    - Inference on TAO\n",
    "    - Inference on TAO, TRT\n",
    "    - Delete experiments/dataset\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Install TAO remote client ](#head-1)\n",
    "1. [FIXME's](#head-2)\n",
    "1. [Login](#head-3)\n",
    "1. [Create a cloud workspace](#head-2)\n",
    "1. [Set dataset formats](#head-4)\n",
    "1. [Create and pull train dataset](#head-5)\n",
    "1. [Create and pull val dataset](#head-6)\n",
    "1. [Create and pull test dataset](#head-7)\n",
    "1. [List the created datasets](#head-8)\n",
    "1. [Train Dataset convert action](#head-9) (for specific models)\n",
    "1. [Val dataset convert action](#head-10) (for specific models)\n",
    "1. [Create experiment (via create-job)](#head-11)\n",
    "1. [List experiments](#head-12)\n",
    "1. [Assign train, eval datasets](#head-13)\n",
    "1. [Assign PTM](#head-14)\n",
    "1. [Set AutoML related configurations](#head-15)\n",
    "1. [Train](#head-16)\n",
    "1. [View hyperparameters that are enabled by default](#head-16.1)\n",
    "1. [Evaluate](#head-17)\n",
    "1. [Optimize: Prune, retrain and evaluate](#head-18) (for specific models)\n",
    "1. [Export](#head-19)\n",
    "1. [TRT Engine generation using TAO-Deploy](#head-20) (for specific models)\n",
    "1. [TAO inference](#head-21)\n",
    "1. [TRT inference](#head-22) (for specific models)\n",
    "1. [Delete experiment](#head-23)\n",
    "1. [Delete dataset](#head-24)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TAO remote client <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this step IF you have already installed the TAO-Client wheel.\n",
    "! pip3 install nvidia-tao-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the version of the TAO-Client\n",
    "! tao --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python packages required for notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore variable in case of jupyter session restart and resume execution where it left off\n",
    "%store -r model_name\n",
    "%store -r automl_enabled\n",
    "%store -r automl_algorithm\n",
    "%store -r workspace_id\n",
    "%store -r train_dataset_id\n",
    "%store -r test_dataset_id\n",
    "%store -r test_dataset_id\n",
    "%store -r experiment_id\n",
    "%store -r job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "namespace = 'default'\n",
    "job_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPLICIT_EVAL_DATASET_MODELS = [\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"visual_changenet_classify\"]\n",
    "EXPLICIT_TEST_DATASET_MODELS = [\"optical_inspection\", \"visual_changenet_classify\"]\n",
    "TRAIN_REUSE_FOR_EVAL_TEST_MODELS = [\"sparse4d\"]\n",
    "TRAIN_DATASET_CONVERT_MODELS = [\"bevfusion\", \"ocrnet\", \"pointpillars\", \"sparse4d\"]\n",
    "EVAL_DATASET_CONVERT_MODELS = [\"ocrnet\"]\n",
    "PRUNEABLE_MODELS = [\"ocdnet\", \"ocrnet\", \"pointpillars\"]\n",
    "UN_EXPORTABLE_MODELS = [\"bevfusion\"]\n",
    "TAO_DEPLOY_MODELS = [\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet_classify\", \"visual_changenet_segment\", \"centerpose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To see the dataset folder structure required for the models supported in this notebook, visit the notebooks under dataset_prepare like for [this notebook](../dataset_prepare/purpose_built_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME's  <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "\n",
    "    1.1 Assign model type for action_recognition/pose_classification in FIXME 1.1\n",
    "\n",
    "    1.2 Assign model input type for action_recognition in FIXME 1.2\n",
    "1. (Optional) Enable AutoML if needed in FIXME 2\n",
    "1. (Optional) Choose between bayesian and hyperband automl_algorithm in FIXME 3 (If automl was enabled in FIXME2)\n",
    "1. Assign path of datasets relative to the bucket in FIXME 4\n",
    "1. Assign the ip_address and port_number in FIXME 5 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "1. Assign the ngc_key variable in FIXME 6\n",
    "1. Assign the ngc_org_name variable in FIXME 7\n",
    "1. Assign a workdir in FIXME 8 for log file download\n",
    "1. Set cloud storage details in FIXME 9\n",
    "1. Database backup/restore archive filename in FIXME 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a purpose built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. action_recognition - https://docs.nvidia.com/tao/tao-toolkit/text/action_recognition_net.html\n",
    "# 2. bevfusion - https://docs.nvidia.com/tao/tao-toolkit/text/bevfusion/index.html\n",
    "# 2. ml_recog - https://docs.nvidia.com/tao/tao-toolkit/text/ml_recog/index.html\n",
    "# 3. ocdnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocdnet/index.html\n",
    "# 4. ocrnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocrnet/index.html\n",
    "# 5. optical_inspection - https://docs.nvidia.com/tao/tao-toolkit/text/optical_inspection/index.html\n",
    "# 6. pose_classification - https://docs.nvidia.com/tao/tao-toolkit/text/pose_classification/index.html\n",
    "# 7. pointpillars - https://docs.nvidia.com/tao/tao-toolkit/text/point_cloud/pointpillars.html\n",
    "# 8. re_identification - https://docs.nvidia.com/tao/tao-toolkit/text/re_identification/index.html\n",
    "# 9. sparse4d - https://docs.nvidia.com/tao/tao-toolkit/text/sparse4d/index.html\n",
    "# 10. centerpose - https://docs.nvidia.com/tao/tao-toolkit/text/centerpose/index.html\n",
    "# 11. visual_changenet_classify - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
    "# 12. visual_changenet_segment - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
    "\n",
    "# FIXME 1 (Add the model name from the above mentioned list)\n",
    "os.environ[\"TAO_MODEL_NAME\"] = model_name = os.environ.get(\"TAO_MODEL_NAME\", \"ocrnet\")\n",
    "%store model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name in (\"action_recognition\",\"pose_classification\"):\n",
    "    # FIXME1.1 - model_type - string\n",
    "        # action_recognition: rgb/of/joint;\n",
    "        # pose_classification: kinetics/nvidia\n",
    "    model_type = \"rgb\" # FIXME1.1 action_recognition: rgb/of/joint; pose_classification: kinetics/nvidia\n",
    "\n",
    "    if model_name == \"action_recognition\":\n",
    "        if model_type not in (\"rgb\",\"of\",\"joint\"):\n",
    "            raise Exception(\"Choose one of rgb/of/joint for action recognition model_type\")\n",
    "    elif model_name == \"pose_classification\":\n",
    "        if model_type not in (\"kinetics\",\"nvidia\"):\n",
    "            raise Exception(\"Choose one of kinetics/nvidia for pose classification model_type\")\n",
    "\n",
    "    if model_name == \"action_recognition\":\n",
    "        model_input_type = \"3d\" # FIXME1.2 3d/2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toggle AutoML params\n",
    "[AutoML documentation](https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 2: Set to True if you want to run automl for the model chosen in the previous cell\n",
    "automl_enabled = os.environ.get(\"TAO_AUTOML_ENABLED\", \"False\").lower() == \"true\"\n",
    "os.environ[\"TAO_AUTOML_ENABLED\"] = str(automl_enabled)\n",
    "# FIXME 3: One of bayesian/hyperband\n",
    "os.environ[\"TAO_AUTOML_ALGORITHM\"] = automl_algorithm = os.environ.get(\"TAO_AUTOML_ALGORITHM\", \"bayesian\")\n",
    "\n",
    "%store automl_enabled\n",
    "%store automl_algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions used across the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to parse logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tail(model_name_cli, job_id):\n",
    "\tstatus = None\n",
    "\twhile True:\n",
    "\t\ttime.sleep(10)\n",
    "\t\tclear_output(wait=True)\n",
    "\t\tresponse = subprocess.getoutput(f\"tao {model_name_cli} get-job-metadata --job-id {job_id}\")\n",
    "\t\tresponse = json.loads(response)\n",
    "\t\tif response and \"status\" in response.keys() and response.get(\"status\") in (\"Done\", \"Error\", \"Canceled\", \"Paused\"):\n",
    "\t\t\tprint(json.dumps(response.get(\"job_details\", {}), indent=4))\n",
    "\t\t\tstatus = response.get(\"status\")\n",
    "\t\t\tassert status == \"Done\", f\"Status is not Done, it is {status}\"\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tlogs = subprocess.getoutput(f\"tao {model_name_cli} get-job-logs --job-id {job_id}\")\n",
    "\t\tif not logs:\n",
    "\t\t\tcontinue\n",
    "\t\tlog_content_lines = logs.split(\"\\n\")        \n",
    "\t\tfor line in log_content_lines:\n",
    "\t\t\tprint(line.strip())\n",
    "\t\t\tif line.strip() == \"Error EOF\":\n",
    "\t\t\t\tstatus = \"Error\"\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif line.strip() == \"Done EOF\":\n",
    "\t\t\t\tstatus = \"Done\"\n",
    "\t\t\t\tbreak\n",
    "\t\tif status is not None:\n",
    "\t\t\tbreak\n",
    "\treturn status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to load login details from saved config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tao_credentials_from_config():\n",
    "    \"\"\"Load TAO credentials from ~/.tao/config and set as environment variables\"\"\"\n",
    "    from configparser import ConfigParser\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    \n",
    "    config_path = Path.home() / '.tao' / 'config'\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        print(f\"Warning: Config file not found at {config_path}\")\n",
    "        print(\"Please run 'tao login' first\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        parser = ConfigParser()\n",
    "        parser.read(config_path)\n",
    "        \n",
    "        # Read from [CURRENT] section\n",
    "        if parser.has_section('CURRENT'):\n",
    "            section = parser['CURRENT']\n",
    "        else:\n",
    "            print(\"Warning: No [CURRENT] section found in config file\")\n",
    "            return False\n",
    "        \n",
    "        # Set environment variables\n",
    "        if 'tao_base_url' in section:\n",
    "            os.environ['TAO_BASE_URL'] = section['tao_base_url']\n",
    "            print(f\"✓ TAO_BASE_URL set to: {section['tao_base_url']}\")\n",
    "        \n",
    "        if 'tao_org' in section:\n",
    "            os.environ['TAO_ORG'] = section['tao_org']\n",
    "            print(f\"✓ TAO_ORG set to: {section['tao_org']}\")\n",
    "        \n",
    "        if 'tao_token' in section:\n",
    "            os.environ['TAO_TOKEN'] = section['tao_token']\n",
    "            print(f\"✓ TAO_TOKEN set (expires: check token if auth fails)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading config file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set API service's host information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 4: Set TAO API environment variables\n",
    "\n",
    "# Set to your TAO API endpoint\n",
    "os.environ[\"TAO_BASE_URL\"] = os.environ.get(\"TAO_BASE_URL\", \"https://your_tao_ip_address:port/api/v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set NGC Personal key for authentication and NGC org to access API services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NGC_KEY\"] = ngc_key = os.environ.get(\"NGC_KEY\", \"your_ngc_key\")  # FIXME6 example: (Add NGC Personal key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NGC_ORG\"] = ngc_org_name = os.environ.get(\"NGC_ORG\", \"nvstaging\")  # FIXME7 your NGC ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "! tao login --ngc-org-name {ngc_org_name} --ngc-key {ngc_key} --enable-telemetry\n",
    "\n",
    "# Load credentials when this cell runs\n",
    "load_tao_credentials_from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    " One of the keys of the response json are to be used as platform_id when you run each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
    "# # response = json.loads(subprocess.getoutput(f'tao get-gpu-types'))\n",
    "# print((json.dumps(response, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloud workspace\n",
    "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
    "\n",
    "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 7: Dataset Cloud bucket details to download dataset or push job artifacts for jobs\n",
    "\n",
    "cloud_metadata = {}\n",
    "\n",
    "# A Representative name for this cloud info\n",
    "os.environ[\"TAO_WORKSPACE_NAME\"] = cloud_metadata[\"name\"] = os.environ.get(\"TAO_WORKSPACE_NAME\", \"AWS workspace info\")\n",
    "\n",
    "# Cloud specific details. Below is assuming AWS.\n",
    "cloud_metadata[\"cloud_specific_details\"] = {}\n",
    "\n",
    " # Whether it is AWS, HuggingFace or Azure\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_TYPE\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_TYPE\", \"aws\")\n",
    "\n",
    "# Bucket region\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_REGION\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_REGION\", \"us-west-1\")\n",
    "\n",
    "# Bucket name\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\", \"bucket_name\")\n",
    "\n",
    "# Access and Secret keys\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\", \"access_key\")\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_SECRET_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_SECRET_KEY\", \"secret_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_id = subprocess.getoutput(f\"tao {model_name} create-workspace --name 'AWS Workspace' --cloud-type {cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"]} --cloud-specific-details '{json.dumps(cloud_metadata[\"cloud_specific_details\"])}'\")\n",
    "print(workspace_id)\n",
    "%store workspace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Optional: Restore database with a mongodump file saved in workspace dump/archive/{backup_filename}\n",
    "# backup_file_name = \"mongodump.tar.gz\" # FIXME 10\n",
    "# response = subprocess.getoutput(f\"tao {model_name} restore-workspace --workspace-id {workspace_id} --backup_file_name {backup_file_name}\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset path (path within cloud bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 8 : Set paths relative to cloud bucket\n",
    "os.environ[\"TAO_TRAIN_DATASET_PATH\"] = train_dataset_path =  os.environ.get(\"TAO_TRAIN_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_train\")\n",
    "os.environ[\"TAO_EVAL_DATASET_PATH\"] = eval_dataset_path = os.environ.get(\"TAO_EVAL_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_val\")   # ocdnet, ocrnet, optical_inspection, visual_changenet_classify\n",
    "os.environ[\"TAO_TEST_DATASET_PATH\"] = test_dataset_path = os.environ.get(\"TAO_TEST_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_test\")  # optical_inspection, visual_changenet_classify\n",
    "train_dataset_id = None\n",
    "eval_dataset_id = None\n",
    "test_dataset_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset formats <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"sparse4d\":\n",
    "    ds_type = model_name\n",
    "    ds_format = \"ovpkl\"\n",
    "else:\n",
    "    ds_type = model_name\n",
    "    ds_format = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull train dataset <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_id = subprocess.getoutput(f\"tao {model_name} create-dataset --dataset-type {ds_type} --dataset-format {ds_format}  --workspace-id {workspace_id} --cloud-file-path {train_dataset_path} --use-for '{json.dumps(['training'])}'\")\n",
    "print(train_dataset_id)\n",
    "if model_name in TRAIN_REUSE_FOR_EVAL_TEST_MODELS:\n",
    "    eval_dataset_id = train_dataset_id\n",
    "    test_dataset_id = train_dataset_id\n",
    "    %store test_dataset_id\n",
    "%store train_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = subprocess.getoutput(f\"tao {model_name} get-dataset-metadata --dataset-id {train_dataset_id} \")\n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "    except Exception as e:\n",
    "        print(response)\n",
    "        raise e\n",
    "    print(json.dumps(response, sort_keys=True, indent=4))\n",
    "    if response.get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "# # try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     train_dataset_id = remove_corrupted_images_workflow(workspace_id, train_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull val dataset <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
    "    eval_dataset_id = subprocess.getoutput(f\"tao {model_name} create-dataset --dataset-type {ds_type} --dataset-format {ds_format} --workspace-id {workspace_id} --cloud-file-path {eval_dataset_path} --use-for '{json.dumps(['evaluation'])}'\")\n",
    "    print(eval_dataset_id)\n",
    "    %store eval_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = subprocess.getoutput(f\"tao {model_name} get-dataset-metadata --dataset-id {eval_dataset_id} \")\n",
    "        try:\n",
    "            response = json.loads(response)\n",
    "        except Exception as e:\n",
    "            print(response)\n",
    "            raise e\n",
    "        print(json.dumps(response, sort_keys=True, indent=4))\n",
    "        if response.get(\"status\") == \"invalid_pull\":\n",
    "            raise ValueError(\"Dataset pull failed\")\n",
    "        if response.get(\"status\") == \"pull_complete\":\n",
    "            break\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "# # try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     test_dataset_id = remove_corrupted_images_workflow(workspace_id, test_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull test dataset <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
    "    ds_type = model_name\n",
    "    ds_format = \"default\"\n",
    "\n",
    "    test_dataset_id = subprocess.getoutput(f\"tao {model_name} create-dataset --dataset-type {ds_type} --dataset-format {ds_format} --cloud-file-path {test_dataset_path} --workspace-id {workspace_id} --use-for '{json.dumps(['testing'])}'\")\n",
    "    print(test_dataset_id)\n",
    "    %store test_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = subprocess.getoutput(f\"tao {model_name} get-dataset-metadata --dataset-id {test_dataset_id} \")\n",
    "        try:\n",
    "            response = json.loads(response)\n",
    "        except Exception as e:\n",
    "            print(response)\n",
    "            raise e\n",
    "        print(json.dumps(response, sort_keys=True, indent=4))\n",
    "        if response.get(\"status\") == \"invalid_pull\":\n",
    "            raise ValueError(\"Dataset pull failed\")\n",
    "        if response.get(\"status\") == \"pull_complete\":\n",
    "            break\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "# # try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     test_dataset_id = remove_corrupted_images_workflow(workspace_id, test_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message = subprocess.getoutput(f\"tao {model_name} list-datasets\")\n",
    "message = json.loads(message)\n",
    "for rsp in message:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys\n",
    "    assert \"type\" in rsp_keys\n",
    "    assert \"format\" in rsp_keys\n",
    "    assert \"name\" in rsp_keys\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset convert Action <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default train dataset specs\n",
    "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
    "   train_ds_convert_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action dataset_convert\")\n",
    "   train_ds_convert_specs_schema = json.loads(train_ds_convert_specs_response)\n",
    "   train_ds_convert_specs = train_ds_convert_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(train_ds_convert_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize train dataset specs\n",
    "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
    "    if model_name == \"sparse4d\":\n",
    "        train_ds_convert_specs[\"data\"][\"input_format\"] = \"AICity\"\n",
    "        train_ds_convert_specs[\"data\"][\"output_format\"] = \"OVPKL\"\n",
    "        train_ds_convert_specs[\"aicity\"][\"num_frames\"] = 90\n",
    "    print(json.dumps(train_ds_convert_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind dataset --dataset-id {train_dataset_id} --action dataset_convert --specs '{json.dumps(train_ds_convert_specs)}'\")\n",
    "    job_map[\"train_convert_\" + model_name] = job_id\n",
    "    print(job_id)\n",
    "    %store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
    "    job_id = job_map[\"train_convert_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Dataset convert Action <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default val dataset specs\n",
    "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
    "   eval_ds_convert_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action dataset_convert\")\n",
    "   eval_ds_convert_specs_schema = json.loads(eval_ds_convert_specs_response)\n",
    "   eval_ds_convert_specs = eval_ds_convert_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(eval_ds_convert_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize val dataset specs\n",
    "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
    "    print(json.dumps(eval_ds_convert_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
    "    train_convert_job_id = job_map[\"train_convert_\" + model_name]\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind dataset --dataset-id {eval_dataset_id} --action dataset_convert --parent-job-id {train_convert_job_id} --specs '{json.dumps(eval_ds_convert_specs)}'\")\n",
    "    job_map[\"eval_convert_\" + model_name] = job_id\n",
    "    print(job_id)\n",
    "    %store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
    "    job_id = job_map[\"eval_convert_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-14\"></a>\n",
    "\n",
    "Search for PTM on NGC for the Segmentation model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List base experiments (PTMs) using TAO SDK  \n",
    "filter_params = {\"network_arch\": model_name}\n",
    "message = subprocess.getoutput(f\"tao {model_name} list-base-experiments --filter-params '{json.dumps(filter_params)}'\")\n",
    "message = json.loads(message)\n",
    "# Store base experiments list for reuse\n",
    "base_experiments = message\n",
    "\n",
    "print(f\" Available base experiments (PTMs) for {model_name}:\")\n",
    "print(\"name\\t\\t\\t     model id\\t\\t\\t     network architecture\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for exp in base_experiments:\n",
    "    exp_name = exp.get(\"name\", \"N/A\")\n",
    "    exp_id = exp.get(\"id\", \"N/A\")\n",
    "    exp_arch = exp.get(\"network_arch\", \"N/A\")\n",
    "    print(f\"{exp_name}\\t{exp_id}\\t{exp_arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different purpose built models versions\n",
    "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
    "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
    "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
    "pretrained_map = {\"action_recognition\":\"actionrecognitionnet:trainable_rgb_3d\",\n",
    "                  \"bevfusion\": \"bevfusion:bevfusion_1.0\",\n",
    "                  \"ml_recog\": \"retail_object_recognition:trainable_v1.0\",\n",
    "                  \"ocdnet\": \"ocdnet:trainable_resnet18_v1.0\",\n",
    "                  \"ocrnet\": \"nvidia/tao/ocrnet:trainable_v1.0\",\n",
    "                  \"optical_inspection\": \"optical_inspection:trainable_v1.0\",\n",
    "                  \"pointpillars\":\"pointpillarnet:trainable_v1.0\",\n",
    "                  \"pose_classification\":\"poseclassificationnet:trainable_v1.0\",\n",
    "                  \"re_identification\":\"reidentificationnet_transformer:swin_tiny_256_1\",\n",
    "                  \"sparse4d\": \"sparse4d:resnet_101\",\n",
    "                  \"visual_changenet_classify\": \"visual_changenet_classification:visual_changenet_nvpcb_trainable_v1.0\",\n",
    "                  \"visual_changenet_segment\": \"visual_changenet_segmentation_levircd:visual_changenet_levircd_trainable_v1.0\",\n",
    "                  \"centerpose\": \"pretrained_fan_classification_nvimagenet:fan_small_hybrid_nvimagenet\"}\n",
    "\n",
    "if model_name == \"action_recognition\":\n",
    "    if model_type == \"of\":\n",
    "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v2.0\"\n",
    "    elif model_type == \"joint\":\n",
    "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v1.0,actionrecognitionnet:trainable_v2.0\"\n",
    "\n",
    "no_ptm_models = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model using TAO SDK\n",
    "selected_ptm_id = None\n",
    "if model_name not in no_ptm_models:\n",
    "\n",
    "    # Search for PTM with given NGC path\n",
    "    for exp in base_experiments:\n",
    "        ngc_path = exp.get(\"ngc_path\", \"\")\n",
    "        if ngc_path.endswith(pretrained_map[model_name]):\n",
    "            selected_ptm_id = exp.get(\"id\")\n",
    "            print(\" Selected PTM metadata:\")\n",
    "            print(json.dumps(exp, indent=4))\n",
    "            break\n",
    "\n",
    "    if not selected_ptm_id:\n",
    "        print(f\" PTM with NGC path ending in '{pretrained_map[model_name]}' not found!\")\n",
    "\n",
    "if model_name not in no_ptm_models and selected_ptm_id:\n",
    "    print(f\" PTM ID {selected_ptm_id} will be used as base_experiment_id in job creation\")\n",
    "else:\n",
    "    print(\" No PTM will be used (training from scratch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # View default automl params enabled\n",
    "    automl_params = subprocess.getoutput(f\"tao {model_name} get-automl-defaults\")\n",
    "    print(automl_params)\n",
    "    automl_params = json.loads(automl_params)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set AutoML related configurations <a class=\"anchor\" id=\"head-16.1\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters:\n",
    "\n",
    "[ActionRecognitionNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/action_recognition/action_recognition%20-%20train.csv), \n",
    "[MetricLearningRecognition](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ml_recog/ml_recog%20-%20train.csv), \n",
    "[OCDNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocdnet/ocdnet%20-%20train.csv), \n",
    "[OCRNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocrnet/ocrnet%20-%20train.csv), \n",
    "[OpticalInspection](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/optical_inspection/optical_inspection%20-%20train.csv), \n",
    "[Pointpillars](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pointpillars/pointpillars%20-%20train.csv), \n",
    "[PoseClassificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pose_classification/pose_classification%20-%20train.csv), \n",
    "[ReIdentificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/re_identification/re_identification%20-%20train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set encryption key (CLI notebooks typically use this default)\n",
    "encode_key = \"tlt_encode\"\n",
    "\n",
    "# Prepare AutoML configuration if enabled (matching SDK approach)\n",
    "automl_information = None\n",
    "\n",
    "if automl_enabled:\n",
    "    # Choose any metric that is present in the kpi dictionary present in the model's status.json\n",
    "    metric = \"kpi\"\n",
    "    \n",
    "    automl_information = {\n",
    "        \"automl_enabled\": True,\n",
    "        \"automl_algorithm\": automl_algorithm,\n",
    "        \"automl_max_recommendations\": 20,  # Only for bayesian\n",
    "        \"automl_R\": 27,  # Only for hyperband\n",
    "        \"automl_nu\": 3,  # Only for hyperband\n",
    "        \"epoch_multiplier\": 1,  # Only for hyperband\n",
    "        \"override_automl_disabled_params\": False,\n",
    "        \"automl_hyperparameters\": str(automl_params),\n",
    "        \"metric\": metric\n",
    "    }\n",
    "    \n",
    "    print(\" AutoML configuration prepared for job creation:\")\n",
    "    print(json.dumps(automl_information, sort_keys=True, indent=4))\n",
    "else:\n",
    "    print(\" AutoML is disabled - training will use standard approach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Provide train specs <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default train model specs\n",
    "train_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action train\")\n",
    "train_specs_schema = json.loads(train_specs_response)\n",
    "train_specs = train_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(train_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "train_specs[\"train\"][\"num_epochs\"] = 30\n",
    "train_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
    "train_specs[\"train\"][\"validation_interval\"] = 10\n",
    "train_specs[\"train\"][\"num_gpus\"] = 1\n",
    "if model_name == \"action_recognition\":\n",
    "    train_specs[\"model\"][\"model_type\"] = model_type\n",
    "    train_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 2\n",
    "    train_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"centerpose\":\n",
    "    train_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 4\n",
    "elif model_name == \"ocdnet\":\n",
    "    train_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
    "elif model_name == \"ocrnet\":\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 16\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        train_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        train_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        train_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        train_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        train_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        train_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    train_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "    train_specs[\"dataset\"][\"num_workers\"] = 4 #Modify the num_workers according to your hardware setup\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 16 #Modify the batch_size according to your hardware setup\n",
    "elif model_name == \"sparse4d\":\n",
    "    train_specs[\"dataset\"][\"sequences\"][\"split_num\"] = 90\n",
    "    train_specs[\"dataset\"][\"train_dataset\"][\"sequences_split_num\"] = 90\n",
    "print(json.dumps(train_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Run train <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "ds_convert_parent = \"\"\n",
    "if model_name == \"ocrnet\":\n",
    "    val_convert_job_id = job_map[\"eval_convert_\" + model_name]\n",
    "    ds_convert_parent = f\"--parent_job_id {val_convert_job_id}\"\n",
    "elif model_name in (\"ocrnet\", \"pointpillars\"):\n",
    "    train_convert_job_id = job_map[\"train_convert_\" + model_name]\n",
    "    ds_convert_parent = f\"--parent_job_id {train_convert_job_id}\"\n",
    "\n",
    "if not eval_dataset_id:\n",
    "    eval_dataset_id = train_dataset_id\n",
    "\n",
    "automl_settings = json.dumps(automl_information) if automl_information else 'null'    \n",
    "\n",
    "train_datasets_json = json.dumps([train_dataset_id])\n",
    "job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action train --name {model_name}_training_job --encryption-key {encode_key} --workspace-id {workspace_id} --base-experiment-ids {selected_ptm_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --inference-dataset {eval_dataset_id} --calibration-dataset {train_dataset_id} --specs '{json.dumps(train_specs)}' --automl-settings '{automl_settings}'\")\n",
    "job_map[\"train_\" + model_name] = job_id\n",
    "print(job_id)\n",
    "%store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor job status\n",
    "job_id = job_map[\"train_\" + model_name]\n",
    "if automl_enabled:    \n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = subprocess.getoutput(f\"tao {model_name} get-job-metadata --job-id {job_id}\")\n",
    "        response = json.loads(response)\n",
    "        job_details = response.get(\"job_details\", {})\n",
    "        if \"error_desc\" in response.keys() and response[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "            print(\"Job is being created\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        print(json.dumps(job_details, sort_keys=True, indent=4))\n",
    "        assert \"status\" in response.keys() and response.get(\"status\") != \"Error\"\n",
    "        if response.get(\"status\") in [\"Done\",\"Error\"]:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "else:\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To Stop an AutoML JOB\n",
    "#    1. Stop the 'Monitor job status' cell (the cell right before this cell) manually\n",
    "#    2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if automl_enabled:\n",
    "#     job_id = job_map[\"train_\" + model_name]\n",
    "#     job_id = subprocess.getoutput(f\"tao {model_name} pause-job --job-id {job_id}\")\n",
    "#     job_map[\"canceled_\" + model_name] = job_id\n",
    "#     print(job_id)\n",
    "#     %store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Resume AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status' cell above (4th cell above from this cell)\n",
    "# if automl_enabled:\n",
    "#     job_id = job_map[\"train_\" + model_name]\n",
    "#     job_id = subprocess.getoutput(f\"tao {model_name} resume-job --job-id {job_id} --specs '{json.dumps(train_specs)}' {ds_convert_parent}\")\n",
    "#     job_map[\"resumed_\" + model_name] = job_id\n",
    "#     print(job_id)\n",
    "#     %store job_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit the method of choosing checkpoint from list of train checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model handler parameters\n",
    "job_id = job_map[\"train_\" + model_name]\n",
    "model_parameters = subprocess.getoutput(f\"tao {model_name} get-job-metadata --job-id {job_id}\")\n",
    "model_parameters = json.loads(model_parameters)\n",
    "update_checkpoint_choosing = {}\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = model_parameters[\"checkpoint_choose_method\"]\n",
    "update_checkpoint_choosing[\"checkpoint_epoch_number\"] = model_parameters[\"checkpoint_epoch_number\"]\n",
    "print(json.dumps(update_checkpoint_choosing, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint method configuration\n",
    "# Checkpoint selection is handled per-job, not per-experiment\n",
    "# You can configure this when creating export/inference jobs if needed\n",
    "\n",
    "# Example: Change checkpoint selection method for future jobs\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = \"latest_model\"  # Choose between best_model/latest_model/from_epoch_number\n",
    "# Note: If from_epoch_number is chosen, you would specify the epoch in job creation specs\n",
    "\n",
    "print(\"Checkpoint selection configuration updated:\")\n",
    "print(f\"Method: {update_checkpoint_choosing['checkpoint_choose_method']}\")\n",
    "print(\"This will be applied to future job creations\")\n",
    "print(json.dumps(update_checkpoint_choosing, sort_keys=True, indent=4))\n",
    "\n",
    "json_update_data = json.dumps(update_checkpoint_choosing)\n",
    "updated_job_data = subprocess.getoutput(f\"tao {model_name} update-job --job-id {job_id} --update-data '{json_update_data}'\")\n",
    "print(\"\\n Updated job data:\")\n",
    "print(json.dumps(json.loads(updated_job_data), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push model to private ngc team registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = f\"TAO {model_name}\"  # Display name for the model to be published on the model card\n",
    "description = f\"Train {model_name}\"  # Short description for the model to be published on the model card\n",
    "team = \"tao\"  # Team within org for the model to be published to\n",
    "\n",
    "job_id = job_map[\"train_\" + model_name]\n",
    "message = subprocess.getoutput(f\"tao {model_name} publish-model --job-id {job_id} --display-name='{display_name}' --description='{description}' --team {team}\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove model from private ngc team registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message = subprocess.getoutput(f\"tao {model_name} remove-published-model --job-id {job_id} --team {team}\")\n",
    "# print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate <a class=\"anchor\" id=\"head-17\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide evaluate specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default evaluate model specs\n",
    "eval_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action evaluate\")\n",
    "eval_specs_schema = json.loads(eval_specs_response)\n",
    "eval_specs = eval_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(eval_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize evaluate model specs\n",
    "if model_name == \"action_recognition\":\n",
    "    eval_specs[\"model\"][\"model_type\"] = model_type\n",
    "    eval_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    eval_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        eval_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        eval_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        eval_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        eval_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        eval_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        eval_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    eval_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == 'visual_changenet_segment':\n",
    "    eval_specs[\"task\"] = 'segment'\n",
    "elif model_name == 'visual_changenet_classify':\n",
    "    eval_specs[\"task\"] = 'classify'\n",
    "    eval_specs[\"train\"][\"classify\"][\"loss\"] = \"contrastive\"\n",
    "elif model_name == \"centerpose\":\n",
    "    eval_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "print(json.dumps(eval_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "parent = job_map[\"train_\" + model_name]\n",
    "train_datasets_json = json.dumps([train_dataset_id])\n",
    "test_dataset_str = f\"--inference-dataset {test_dataset_id}\" if test_dataset_id else \"\"\n",
    "job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action evaluate --name {model_name}_evaluation_job --encryption-key {encode_key} --workspace-id {workspace_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} {test_dataset_str} --parent-job-id {parent} --specs '{json.dumps(eval_specs)}'\")\n",
    "job_map[\"eval_\" + model_name] = job_id\n",
    "print(job_id)\n",
    "%store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "job_id = job_map[\"eval_\" + model_name]\n",
    "status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune, Retrain and Evaluation <a class=\"anchor\" id=\"head-18\"></a>\n",
    "\n",
    "- We optimize the trained model by pruning and retraining in the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default prune model specs\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "   prune_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action prune\")\n",
    "   prune_specs_schema = json.loads(prune_specs_response)\n",
    "   prune_specs = prune_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(prune_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes to prune specs if neccessary\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    print(json.dumps(prune_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "    train_datasets_json = json.dumps([train_dataset_id])\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action prune --name {model_name}_prune_job --encryption-key {encode_key} --workspace-id {workspace_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --parent-job-id {parent} --specs '{json.dumps(prune_specs)}'\")\n",
    "    job_map[\"prune_\" + model_name] = job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of pruning job (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    job_id = job_map[\"prune_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default retrain model specs\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "   retrain_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action retrain\")\n",
    "   retrain_specs_schema = json.loads(retrain_specs_response)\n",
    "   retrain_specs = retrain_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(retrain_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    retrain_specs[\"train\"][\"num_epochs\"] = 30\n",
    "    retrain_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
    "    retrain_specs[\"train\"][\"validation_interval\"] = 10\n",
    "    retrain_specs[\"train\"][\"num_gpus\"] = 1\n",
    "    if model_name == \"ocdnet\":\n",
    "        retrain_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
    "    elif model_name == \"ocrnet\":\n",
    "        retrain_specs[\"dataset\"][\"batch_size\"] = 16\n",
    "    print(json.dumps(retrain_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    parent = job_map[\"prune_\" + model_name]\n",
    "    # Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "    train_datasets_json = json.dumps([train_dataset_id])\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action retrain --name {model_name}_training_job --encryption-key {encode_key} --workspace-id {workspace_id} --parent-job-id {parent} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --specs '{json.dumps(train_specs)}'\")\n",
    "    job_map[\"retrain_\" + model_name] = job_id\n",
    "    print(job_id)\n",
    "    %store job_map    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status of retrain job (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    job_id = job_map[\"retrain_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate after retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default evaluate model specs\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "   eval_retrain_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action evaluate\")\n",
    "   eval_retrain_specs_schema = json.loads(eval_retrain_specs_response)\n",
    "   eval_retrain_specs = eval_retrain_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(eval_retrain_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize evaluate model specs if necessary\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    print(json.dumps(eval_retrain_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    parent = job_map[\"retrain_\" + model_name]\n",
    "    train_datasets_json = json.dumps([train_dataset_id])\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action evaluate --name {model_name}_evaluation_job --encryption-key {encode_key} --workspace-id {workspace_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --parent-job-id {parent} --specs '{json.dumps(eval_retrain_specs)}'\")\n",
    "    job_map[\"eval2_\" + model_name] = job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in PRUNEABLE_MODELS:\n",
    "    job_id = job_map[\"eval2_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Provide Export specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in UN_EXPORTABLE_MODELS:\n",
    "    # Default export model specs\n",
    "   export_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action export\")\n",
    "   export_specs_schema = json.loads(export_specs_response)\n",
    "   export_specs = export_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(export_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize export model specs\n",
    "if model_name == \"action_recognition\":\n",
    "    export_specs[\"model\"][\"model_type\"] = model_type\n",
    "    export_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    export_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        export_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        export_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        export_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        export_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        export_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        export_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    export_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == 'visual_changenet_segment':\n",
    "    export_specs[\"export\"][\"input_height\"] = 224 \n",
    "    export_specs[\"export\"][\"input_width\"] = 224 \n",
    "    export_specs[\"task\"] = 'segment'\n",
    "elif model_name == 'visual_changenet_classify':\n",
    "    export_specs[\"export\"][\"input_height\"] = 896 \n",
    "    export_specs[\"export\"][\"input_width\"] = 224\n",
    "    export_specs[\"task\"] = 'classify'\n",
    "if model_name not in UN_EXPORTABLE_MODELS:\n",
    "    print(json.dumps(export_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in UN_EXPORTABLE_MODELS:\n",
    "    # Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "    train_datasets_json = json.dumps([train_dataset_id])\n",
    "    test_dataset_str = f\"--inference-dataset {test_dataset_id}\" if test_dataset_id else \"\"\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action export --name {model_name}_export_job --encryption-key {encode_key} --workspace-id {workspace_id} --parent-job-id {parent} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} {test_dataset_str} --specs '{json.dumps(export_specs)}'\")\n",
    "    job_map[\"export_\" + model_name] = job_id\n",
    "    print(job_id)\n",
    "    %store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in UN_EXPORTABLE_MODELS:\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    job_id = job_map[\"export_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT Engine generation using TAO-Deploy <a class=\"anchor\" id=\"head-20\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide trt engine generation specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default gen_trt_engine model specs\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "   tao_deploy_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action gen_trt_engine\")\n",
    "   tao_deploy_specs_schema = json.loads(tao_deploy_specs_response)\n",
    "   tao_deploy_specs = tao_deploy_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(tao_deploy_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize convert model specs\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    # Make changes to the specs dictionary if required here\n",
    "    if model_name in (\"ml_recog\", \"ocdnet\"):\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"INT8\"\n",
    "    elif model_name in (\"ocrnet\", \"optical_inspection\"):\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"   \n",
    "    elif model_name == 'visual_changenet_classify':\n",
    "        tao_deploy_specs[\"task\"] = 'classify'\n",
    "    elif model_name == 'visual_changenet_segment':\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
    "        tao_deploy_specs[\"task\"] = 'segment' \n",
    "    print(json.dumps(tao_deploy_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TRT engine generation using TAO-Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    parent = job_map[\"export_\" + model_name]\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action gen_trt_engine --name {model_name}_gen_trt_engine_job --encryption-key {encode_key} --workspace-id {workspace_id} --calibration-dataset {train_dataset_id} --parent-job-id {parent} --specs '{json.dumps(tao_deploy_specs)}'\")\n",
    "    job_map[\"gen_trt_engine_\" + model_name] = job_id\n",
    "    print(job_id)\n",
    "    %store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    job_id = job_map[\"gen_trt_engine_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAO inference <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide TAO inference specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "tao_inference_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action inference\")\n",
    "tao_inference_specs_schema = json.loads(tao_inference_specs_response)\n",
    "tao_inference_specs = tao_inference_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(tao_inference_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TAO inference specs\n",
    "if model_name == \"action_recognition\":\n",
    "    tao_inference_specs[\"model\"][\"model_type\"] = model_type\n",
    "    tao_inference_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    tao_inference_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    tao_inference_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == 'visual_changenet_classify':\n",
    "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"classify\"]['batch_size'] \n",
    "    tao_inference_specs[\"task\"] = 'classify'\n",
    "elif model_name == 'visual_changenet_segment':\n",
    "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"segment\"]['batch_size'] \n",
    "    tao_inference_specs[\"task\"] = 'segment'\n",
    "elif model_name == \"centerpose\":\n",
    "    tao_inference_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "print(json.dumps(tao_inference_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TAO inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "inference_dataset = test_dataset_id\n",
    "if not inference_dataset:\n",
    "    inference_dataset = eval_dataset_id\n",
    "if not inference_dataset:\n",
    "    inference_dataset = train_dataset_id\n",
    "train_datasets_json = json.dumps([train_dataset_id])\n",
    "\n",
    "parent = job_map[\"train_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action inference --name {model_name}_inference_job --encryption-key {encode_key} --workspace-id {workspace_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --inference-dataset {inference_dataset} --parent-job-id {parent} --specs '{json.dumps(tao_inference_specs)}'\")\n",
    "job_map[\"tao_inference_\" + model_name] = job_id\n",
    "print(job_id)\n",
    "%store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "job_id = job_map[\"tao_inference_\" + model_name]\n",
    "status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT inference <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide TRT inference specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "   trt_inference_specs_response = subprocess.getoutput(f\"tao {model_name} get-job-schema --action inference\")\n",
    "   trt_inference_specs_schema = json.loads(trt_inference_specs_response)\n",
    "   trt_inference_specs = trt_inference_specs_schema.get(\"default\", {})\n",
    "   print(json.dumps(trt_inference_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TRT inference specs\n",
    "# Change any spec if you wish\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    if model_name == 'visual_changenet_classify':\n",
    "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"classify\"]['batch_size']\n",
    "        trt_inference_specs[\"task\"] = 'classify'\n",
    "    elif model_name == 'visual_changenet_segment':\n",
    "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"segment\"]['batch_size']\n",
    "        trt_inference_specs[\"task\"] = 'segment'\n",
    "    print(json.dumps(trt_inference_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TRT inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    parent = job_map[\"gen_trt_engine_\" + model_name]\n",
    "    inference_dataset = test_dataset_id\n",
    "    if not inference_dataset:\n",
    "        inference_dataset = eval_dataset_id\n",
    "    if not inference_dataset:\n",
    "        inference_dataset = train_dataset_id\n",
    "    train_datasets_json = json.dumps([train_dataset_id])\n",
    "    job_id = subprocess.getoutput(f\"tao {model_name} create-job --kind experiment --action inference --name {model_name}_inference_job --encryption-key {encode_key} --workspace-id {workspace_id} --train-datasets '{train_datasets_json}' --eval-dataset {eval_dataset_id} --inference-dataset {inference_dataset} --parent-job-id {parent} --specs '{json.dumps(trt_inference_specs)}'\")\n",
    "    job_map[\"trt_inference_\" + model_name] = job_id \n",
    "    print(job_id)\n",
    "%store job_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name in TAO_DEPLOY_MODELS:\n",
    "    job_id = job_map[\"trt_inference_\" + model_name]\n",
    "    status = my_tail(model_name, job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Backup database with a mongodump file saved in workspace dump/archive/{backup_filename}\n",
    "# backup_file_name = \"mongodump.tar.gz\" # FIXME 10\n",
    "# subprocess.getoutput(f\"tao {model_name} backup-workspace --workspace-id {workspace_id} --backup_file_name {backup_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete jobs <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Deleting all created jobs...\")\n",
    "\n",
    "jobs_to_delete = []\n",
    "for job_key, job_id in job_map.items():\n",
    "    try:\n",
    "        delete_response = subprocess.getoutput(f\"tao {model_name} delete-job --job-id {job_id} --confirm\")\n",
    "        print(f\"Deleted job: {job_key}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting job {job_key}: {e}\")\n",
    "\n",
    "print(f\"\\n Job cleanup completed! Processed {len(jobs_to_delete)} jobs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tao {model_name} delete-dataset --dataset-id {train_dataset_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
    "    ! tao {model_name} delete-dataset --dataset-id {eval_dataset_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
    "    ! tao {model_name} delete-dataset --dataset-id {test_dataset_id}"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
