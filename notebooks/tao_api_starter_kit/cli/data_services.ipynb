{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAO remote client - Data-Services\n",
    "### The workflow in a nutshell\n",
    "TAO Data Services include 4 key pipelines:\n",
    "1. Offline data augmentation using DALI\n",
    "2. Auto labeling using TAO Mask Auto-labeler (MAL)\n",
    "3. Annotation conversion\n",
    "4. Groundtruth analytics\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
    "\n",
    "* Convert KITTI dataset to COCO format\n",
    "* Run auto-labeling to generate pseudo masks for KITTI bounding boxes\n",
    "* Apply data augmentation to the KITTI dataset with bounding boxe refinement\n",
    "* Run data analytics to collect useful statistics on the original and augmented KITTI dataset\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Create a cloud workspace](#head-2)\n",
    "1. [Convert KITTI data to COCO format](#head-1)\n",
    "1. [Generate pseudo-masks with the auto-labeler](#head-2)\n",
    "1. [Apply data augmentation](#head-3)\n",
    "1. [Perform data analytics](#head-4)\n",
    "1. [Perform data validation](#head-5)\n",
    "\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TAO remote client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SKIP this step IF you have already installed the TAO-Client wheel.\n",
    "! pip3 install nvidia-tao-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # View the version of the TAO-Client\n",
    "! tao --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore variable in case of jupyter session restart and resume execution where it left off\n",
    "%store -r workspace_id\n",
    "%store -r kitti_dataset_id\n",
    "%store -r coco_dataset_id\n",
    "%store -r coco_mask_dataset_id\n",
    "%store -r convert_job_id\n",
    "%store -r auto_labeling_job_id\n",
    "%store -r coco_mask_augmented_dataset_id\n",
    "%store -r analyze_job_id\n",
    "%store -r validate_annotations_job_id\n",
    "%store -r validate_images_job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "namespace = 'default'\n",
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions used across the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to parse logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tail(model_name_cli, job_id):\n",
    "\tstatus = None\n",
    "\twhile True:\n",
    "\t\ttime.sleep(10)\n",
    "\t\tclear_output(wait=True)\n",
    "\t\tresponse = subprocess.getoutput(f\"tao {model_name_cli} get-job-metadata --job-id {job_id}\")\n",
    "\t\tresponse = json.loads(response)\n",
    "\t\tif response and \"status\" in response.keys() and response.get(\"status\") in (\"Done\", \"Error\", \"Canceled\", \"Paused\"):\n",
    "\t\t\tprint(json.dumps(response.get(\"job_details\", {}), indent=4))\n",
    "\t\t\tstatus = response.get(\"status\")\n",
    "\t\t\tassert status == \"Done\", f\"Status is not Done, it is {status}\"\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tlogs = subprocess.getoutput(f\"tao {model_name_cli} get-job-logs --job-id {job_id}\")\n",
    "\t\tif not logs:\n",
    "\t\t\tcontinue\n",
    "\t\tlog_content_lines = logs.split(\"\\n\")        \n",
    "\t\tfor line in log_content_lines:\n",
    "\t\t\tprint(line.strip())\n",
    "\t\t\tif line.strip() == \"Error EOF\":\n",
    "\t\t\t\tstatus = \"Error\"\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif line.strip() == \"Done EOF\":\n",
    "\t\t\t\tstatus = \"Done\"\n",
    "\t\t\t\tbreak\n",
    "\t\tif status is not None:\n",
    "\t\t\tbreak\n",
    "\treturn status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to load login details from saved config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tao_credentials_from_config():\n",
    "    \"\"\"Load TAO credentials from ~/.tao/config and set as environment variables\"\"\"\n",
    "    from configparser import ConfigParser\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    \n",
    "    config_path = Path.home() / '.tao' / 'config'\n",
    "    \n",
    "    if not config_path.exists():\n",
    "        print(f\"Warning: Config file not found at {config_path}\")\n",
    "        print(\"Please run 'tao login' first\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        parser = ConfigParser()\n",
    "        parser.read(config_path)\n",
    "        \n",
    "        # Read from [CURRENT] section\n",
    "        if parser.has_section('CURRENT'):\n",
    "            section = parser['CURRENT']\n",
    "        else:\n",
    "            print(\"Warning: No [CURRENT] section found in config file\")\n",
    "            return False\n",
    "        \n",
    "        # Set environment variables\n",
    "        if 'tao_base_url' in section:\n",
    "            os.environ['TAO_BASE_URL'] = section['tao_base_url']\n",
    "            print(f\"✓ TAO_BASE_URL set to: {section['tao_base_url']}\")\n",
    "        \n",
    "        if 'tao_org' in section:\n",
    "            os.environ['TAO_ORG'] = section['tao_org']\n",
    "            print(f\"✓ TAO_ORG set to: {section['tao_org']}\")\n",
    "        \n",
    "        if 'tao_token' in section:\n",
    "            os.environ['TAO_TOKEN'] = section['tao_token']\n",
    "            print(f\"✓ TAO_TOKEN set (expires: check token if auth fails)\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading config file: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME's <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    "1. Assign a workdir in FIXME 1\n",
    "1. Assign the ip_address and port_number in FIXME 2 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "1. Assign the ngc_key variable in FIXME 3\n",
    "1. Assign the ngc_org_name variable in FIXME 4\n",
    "1. Set cloud storage details in FIXME 5\n",
    "1. Assign path of kitti dataset relative to the bucket in FIXME 6\n",
    "1. Database backup/restore archive filename in FIXME 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set API service's host information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 4: Set TAO API environment variables\n",
    "\n",
    "# Set to your TAO API endpoint\n",
    "os.environ[\"TAO_BASE_URL\"] = os.environ.get(\"TAO_BASE_URL\", \"https://your_tao_ip_address:port/api/v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set NGC Personal key for authentication and NGC org to access API services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NGC_KEY\"] = ngc_key = os.environ.get(\"NGC_KEY\", \"your_ngc_key\")  # FIXME6 example: (Add NGC Personal key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NGC_ORG\"] = ngc_org_name = os.environ.get(\"NGC_ORG\", \"nvstaging\")  # FIXME7 your NGC ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "! tao login --ngc-org-name {ngc_org_name} --ngc-key {ngc_key} --enable-telemetry\n",
    "\n",
    "# Load credentials when this cell runs\n",
    "load_tao_credentials_from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    " One of the keys of the response json are to be used as platform_id when you run each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
    "# # response = json.loads(subprocess.getoutput(f'tao get-gpu-types'))\n",
    "# print((json.dumps(response, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloud workspace\n",
    "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
    "\n",
    "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME 7: Dataset Cloud bucket details to download dataset or push job artifacts for jobs\n",
    "\n",
    "cloud_metadata = {}\n",
    "\n",
    "# A Representative name for this cloud info\n",
    "os.environ[\"TAO_WORKSPACE_NAME\"] = cloud_metadata[\"name\"] = os.environ.get(\"TAO_WORKSPACE_NAME\", \"AWS workspace info\")\n",
    "\n",
    "# Cloud specific details. Below is assuming AWS.\n",
    "cloud_metadata[\"cloud_specific_details\"] = {}\n",
    "\n",
    " # Whether it is AWS, HuggingFace or Azure\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_TYPE\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_TYPE\", \"aws\")\n",
    "\n",
    "# Bucket region\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_REGION\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_REGION\", \"us-west-1\")\n",
    "\n",
    "# Bucket name\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\", \"bucket_name\")\n",
    "\n",
    "# Access and Secret keys\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\", \"access_key\")\n",
    "os.environ[\"TAO_WORKSPACE_CLOUD_SECRET_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_SECRET_KEY\", \"secret_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_id = subprocess.getoutput(f\"tao annotations create-workspace --name 'AWS Workspace' --cloud-type {cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"]} --cloud-specific-details '{json.dumps(cloud_metadata[\"cloud_specific_details\"])}'\")\n",
    "print(workspace_id)\n",
    "%store workspace_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Optional: Restore database with a mongodump file saved in workspace dump/archive/{backup_filename}\n",
    "# backup_file_name = \"mongodump.tar.gz\" # FIXME 7\n",
    "# response = subprocess.getoutput(f\"tao annotations restore-workspace --workspace-id {workspace_id} --backup_file_name {backup_file_name}\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Convert KITTI data to COCO format <a class=\"anchor\" id=\"head-1\"></a>\n",
    "We would first convert the dataset from KITTI to COCO formats.\n",
    "\n",
    "### Define the task and action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset\n",
    "We support both KITTI and COCO data formats\n",
    "\n",
    "KITTI dataset follow the directory structure displayed below:\n",
    "```\n",
    "$DATA_DIR/dataset\n",
    " images\n",
    "   image_name_1.jpg\n",
    "   image_name_2.jpg\n",
    "| ...\n",
    " labels\n",
    " image_name_1.txt\n",
    " image_name_2.txt\n",
    " ...\n",
    "```\n",
    "\n",
    "And COCO dataset follow the directory structure displayed below:\n",
    "```\n",
    "$DATA_DIR/dataset\n",
    " images\n",
    "   image_name_1.jpg\n",
    "   image_name_2.jpg\n",
    "| ...\n",
    " annotations.json\n",
    "```\n",
    "For this notebook, we will be using the KITTI object detection dataset for this example. To find more details, please visit [here](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a kitti Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME5 : Set path relative to cloud bucket\n",
    "os.environ[\"TAO_KITTI_DATASET_PATH\"] = kitti_dataset_path = os.environ.get(\"TAO_KITTI_DATASET_PATH\", \"/data/tao_od_synthetic_subset_train_convert_cleaned/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "kitti_dataset_id = subprocess.getoutput(f\"tao annotations create-dataset --dataset-type object_detection --dataset-format kitti --workspace-id {workspace_id} --cloud-file-path {kitti_dataset_path} --use-for '{json.dumps(['testing'])}'\")\n",
    "print(kitti_dataset_id)\n",
    "%store kitti_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = subprocess.getoutput(f\"tao annotations get-dataset-metadata --dataset-id {kitti_dataset_id} \")\n",
    "    try:\n",
    "        response = json.loads(response)\n",
    "    except Exception as e:\n",
    "        print(response)\n",
    "        raise e\n",
    "    print(json.dumps(response, sort_keys=True, indent=4))\n",
    "    if response.get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset format conversion action \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "annotation_conversion_specs_response = subprocess.getoutput(f\"tao annotations get-job-schema --action annotation_format_convert\")\n",
    "annotation_conversion_specs_schema = json.loads(annotation_conversion_specs_response)\n",
    "annotation_conversion_specs = annotation_conversion_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(annotation_conversion_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specs\n",
    "annotation_conversion_specs[\"data\"][\"input_format\"] = \"KITTI\"\n",
    "annotation_conversion_specs[\"data\"][\"output_format\"] = \"COCO\"\n",
    "print(json.dumps(annotation_conversion_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run action \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "coco_dataset_id = kitti_dataset_id\n",
    "convert_job_id = subprocess.getoutput(f\"tao annotations create-job --kind dataset --dataset-id {kitti_dataset_id} --action annotation_format_convert --specs '{json.dumps(annotation_conversion_specs)}'\")\n",
    "print(convert_job_id)\n",
    "%store coco_dataset_id\n",
    "%store convert_job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"annotations\", convert_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the action is completed the format of dataset will be converted to coco from kitti\n",
    "print(subprocess.getoutput(f\"tao annotations get-dataset-metadata --dataset-id {kitti_dataset_id} \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate pseudo-masks with the auto-labeler <a class=\"anchor\" id=\"head-2\"></a>\n",
    "Here we will use a pretrained MAL model to generate pseudo-masks for the converted KITTI data. \n",
    "\n",
    "### Define the task and action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a coco Dataset - If you already have data in coco detection format(without masks) and skipped step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataset\n",
    "# coco_dataset_id = subprocess.getoutput(f\"tao annotations create-dataset --dataset-type object_detection --dataset-format coco --workspace-id {workspace_id} --cloud-file-path {coco_dataset_path} --use-for '{json.dumps(['testing'])}'\")\n",
    "# print(coco_dataset_id)\n",
    "# %store coco_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check progress\n",
    "# while True:\n",
    "#     clear_output(wait=True)\n",
    "#     response = subprocess.getoutput(f\"tao annotations get-dataset-metadata --dataset-id {coco_dataset_id} \")\n",
    "#     try:\n",
    "#         response = json.loads(response)\n",
    "#     except Exception as e:\n",
    "#         print(response)\n",
    "#         raise e\n",
    "#     print(json.dumps(response, sort_keys=True, indent=4))\n",
    "#     if response.get(\"status\") == \"invalid_pull\":\n",
    "#         raise ValueError(\"Dataset pull failed\")\n",
    "#     if response.get(\"status\") == \"pull_complete\":\n",
    "#         break\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List base experiments (PTMs) using TAO SDK  \n",
    "filter_params = {\"network_arch\": \"auto_label\"}\n",
    "message = subprocess.getoutput(f\"tao auto_label list-base-experiments --filter-params '{json.dumps(filter_params)}'\")\n",
    "message = json.loads(message)\n",
    "# Store base experiments list for reuse\n",
    "base_experiments = message\n",
    "\n",
    "print(f\" Available base experiments (PTMs) for auto_label:\")\n",
    "print(\"name\\t\\t\\t     model id\\t\\t\\t     network architecture\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for exp in base_experiments:\n",
    "    exp_name = exp.get(\"name\", \"N/A\")\n",
    "    exp_id = exp.get(\"id\", \"N/A\")\n",
    "    exp_arch = exp.get(\"network_arch\", \"N/A\")\n",
    "    print(f\"{exp_name}\\t{exp_id}\\t{exp_arch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_map = {\"auto_label\" : \"mask_auto_label:trainable_v1.1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained model using TAO SDK\n",
    "selected_ptm_id = None\n",
    "\n",
    "# Search for PTM with given NGC path\n",
    "for exp in base_experiments:\n",
    "    ngc_path = exp.get(\"ngc_path\", \"\")\n",
    "    if ngc_path.endswith(pretrained_map[\"auto_label\"]):\n",
    "        selected_ptm_id = exp.get(\"id\")\n",
    "        print(\" Selected PTM metadata:\")\n",
    "        print(json.dumps(exp, indent=4))\n",
    "        break\n",
    "\n",
    "if not selected_ptm_id:\n",
    "    print(f\" PTM with NGC path ending in '{pretrained_map['auto_label']}' not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if selected_ptm_id:\n",
    "    print(f\"PTM ID {selected_ptm_id} will be used as base_experiment_id in job creation\")\n",
    "    update_data = json.dumps({\"base_experiment_ids\": [selected_ptm_id]})\n",
    "    updated_dataset = subprocess.getoutput(f\"tao auto_label update-dataset --dataset-id {coco_dataset_id} --update-data '{update_data}'\")\n",
    "    print(updated_dataset)\n",
    "else:\n",
    "    raise ValueError(\"No PTM found, Auto-Labeling cant' be performed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto labeling action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "auto_label_generate_specs_response = subprocess.getoutput(f\"tao auto_label get-job-schema --action auto_label\")\n",
    "print(auto_label_generate_specs_response)\n",
    "auto_label_generate_specs_schema = json.loads(auto_label_generate_specs_response)\n",
    "auto_label_generate_specs = auto_label_generate_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(auto_label_generate_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specs\n",
    "auto_label_generate_specs[\"gpu_ids\"] = [0]\n",
    "print(json.dumps(auto_label_generate_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "coco_mask_dataset_id = kitti_dataset_id\n",
    "parent = convert_job_id\n",
    "auto_labeling_job_id = subprocess.getoutput(f\"tao auto_label create-job --kind dataset --dataset-id {coco_dataset_id} --parent-job-id {parent} --action auto_label --specs '{json.dumps(auto_label_generate_specs)}'\")\n",
    "print(auto_labeling_job_id)\n",
    "%store auto_labeling_job_id\n",
    "%store coco_mask_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"auto_label\", auto_labeling_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply data augmentation <a class=\"anchor\" id=\"head-3\"></a>\n",
    "In this section, we run offline augmentation with the original dataset. During the augmentation process, we can use the pseudo-masks generated from the last step to refine the distorted or rotated bounding boxes.\n",
    "\n",
    "### Define the task and action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a coco mask Dataset - If you already have data in coco segmentation format and skipped step 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataset\n",
    "# coco_mask_dataset_id = subprocess.getoutput(f\"tao annotations create-dataset --dataset-type object_detection --dataset-format coco  --workspace-id {workspace_id} --cloud-file-path {coco_mask_dataset_path} --use-for '{json.dumps(['testing'])}'\")\n",
    "# print(coco_mask_dataset_id)\n",
    "# %store coco_mask_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check progress\n",
    "# while True:\n",
    "#     clear_output(wait=True)\n",
    "#     response = subprocess.getoutput(f\"tao annotations get-dataset-metadata --dataset-id {coco_mask_dataset_id} \")\n",
    "#     try:\n",
    "#         response = json.loads(response)\n",
    "#     except Exception as e:\n",
    "#         print(response)\n",
    "#         raise e\n",
    "#     print(json.dumps(response, sort_keys=True, indent=4))\n",
    "#     if response.get(\"status\") == \"invalid_pull\":\n",
    "#         raise ValueError(\"Dataset pull failed\")\n",
    "#     if response.get(\"status\") == \"pull_complete\":\n",
    "#         break\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run data augmentation action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "augmentation_generate_specs_response = subprocess.getoutput(f\"tao augmentation get-job-schema --action augment\")\n",
    "augmentation_generate_specs_schema = json.loads(augmentation_generate_specs_response)\n",
    "augmentation_generate_specs = augmentation_generate_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(augmentation_generate_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change any spec key if required\n",
    "print(json.dumps(augmentation_generate_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "parent = auto_labeling_job_id\n",
    "coco_mask_augmented_dataset_id = subprocess.getoutput(f\"tao augmentation create-job --kind dataset --dataset-id {coco_mask_dataset_id} --action augment --parent-job-id {parent} --specs '{json.dumps(augmentation_generate_specs)}'\")\n",
    "print(coco_mask_augmented_dataset_id)\n",
    "%store coco_mask_augmented_dataset_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"augmentation\", coco_mask_augmented_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After the augment action you'll get a new dataset\n",
    "print(subprocess.getoutput(f\"tao augmentation get-dataset-metadata --dataset-id {coco_mask_augmented_dataset_id} \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform data analytics  <a class=\"anchor\" id=\"head-4\"></a>\n",
    "Next, we perform analytics with the KITTI dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data analytics annotation analytics action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "analytics_analyze_specs_response = subprocess.getoutput(f\"tao analytics get-job-schema --action analyze\")\n",
    "analytics_analyze_specs_schema = json.loads(analytics_analyze_specs_response)\n",
    "analytics_analyze_specs = analytics_analyze_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(analytics_analyze_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specs\n",
    "analytics_analyze_specs[\"data\"][\"input_format\"] = \"COCO\"\n",
    "print(json.dumps(analytics_analyze_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "parent = convert_job_id\n",
    "analyze_job_id = subprocess.getoutput(f\"tao analytics create-job --kind dataset --dataset-id {coco_dataset_id} --action analyze --parent-job-id {parent} --specs '{json.dumps(analytics_analyze_specs)}'\")\n",
    "print(analyze_job_id)\n",
    "%store analyze_job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"analytics\", analyze_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform data validation  <a class=\"anchor\" id=\"head-5\"></a>\n",
    "Next, we perform validate the annotations and images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data annotation validation action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "validate_annotations_specs_response = subprocess.getoutput(f\"tao analytics get-job-schema --action validate_annotations\")\n",
    "validate_annotations_specs_schema = json.loads(validate_annotations_specs_response)\n",
    "validate_annotations_specs = validate_annotations_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(validate_annotations_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specs\n",
    "validate_annotations_specs[\"data\"][\"input_format\"] = \"COCO\"\n",
    "print(json.dumps(validate_annotations_specs, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "parent = convert_job_id\n",
    "validate_annotations_job_id = subprocess.getoutput(f\"tao analytics create-job --kind dataset --dataset-id {coco_dataset_id} --action validate_annotations --parent-job-id {parent} --specs '{json.dumps(validate_annotations_specs)}'\")\n",
    "print(validate_annotations_job_id)\n",
    "%store validate_annotations_job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"analytics\", validate_annotations_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Data image validation action - removes corrupted images and creates a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default model specs\n",
    "validate_images_specs_response = subprocess.getoutput(f\"tao image get-job-schema --action validate_images\")\n",
    "validate_images_specs_schema = json.loads(validate_images_specs_response)\n",
    "validate_images_specs = validate_images_specs_schema.get(\"default\", {})\n",
    "print(json.dumps(validate_images_specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make changes to the specs if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add --platform_id uuid for NVCF backend, where the uuid is a key from output of tao gpu-types\n",
    "# Run action\n",
    "validate_images_job_id = subprocess.getoutput(f\"tao image create-job --kind dataset --dataset-id {kitti_dataset_id} --action validate_images --specs '{json.dumps(validate_images_specs)}'\")\n",
    "print(validate_images_job_id)\n",
    "%store validate_images_job_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(\"image\", validate_images_job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: Backup database with a mongodump file saved in workspace dump/archive/{backup_filename}\n",
    "# backup_file_name = \"mongodump.tar.gz\" # FIXME 7\n",
    "# subprocess.getoutput(f\"tao image backup-workspace --workspace-id {workspace_id} --backup_file_name {backup_file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete original kitti dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao image delete-dataset --dataset-id {kitti_dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete coco augment dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao image delete-dataset --dataset-id {coco_mask_augmented_dataset_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
