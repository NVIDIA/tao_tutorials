{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSL MAE Dataset Formatting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the MVTec anormaly detection (mvtec-ad) dataset in the format compatible with TAO FTMS to Pretrain and Finetune an SSL MAE model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Dataset\n",
    "\n",
    "To get started, go to https://www.mvtec.com/company/research/datasets/mvtec-ad, agree to the license terms and click \"Download The Whole Dataset\". \n",
    "\n",
    "Place the downloaded file ```mvtec_anomaly_detection.tar.xz``` in the same folder as this notebook then run all cells. \n",
    "\n",
    "Once complete, upload the output dataset folder  ```mvtec_ad_classification``` to your cloud storage. You can then follow the [ssl_mae_pretrain_finetune.ipynb](https://github.com/NVIDIA/tao_tutorials/tree/main/notebooks/tao_api_starter_kit/api/ssl_mae_pretrain_finetune.ipynb) notebook to learn how to pretrain and finetune an SSL MAE model with this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!test -f mvtec_anomaly_detection.tar.xz && echo \"✅ Dataset Found.\" || (echo \"❌ File 'mvtec_anomaly_detection.tar.xz' not found.\"; exit 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir mvtec_ad\n",
    "!tar -xf mvtec_anomaly_detection.tar.xz -C mvtec_ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the Dataset\n",
    "\n",
    "In this tutorial, we prepare `train/val/test` dataset for image classification. Image classification expects a directory of images with the following structure, where each class has its own directory with the class name - `good` and `defect` in this notebook. More TAO Dataset formats can be found [here](https://docs.nvidia.com/tao/tao-toolkit/text/data_annotation_format.html)\n",
    "```\n",
    "DATA_DIR\n",
    "├── images_train\n",
    "│   ├── good\n",
    "│   │   ├── image_name_1.jpg\n",
    "│   │   ├── ...\n",
    "|   |   ... \n",
    "│   └── defect\n",
    "│       ├── image_name_2.jpg\n",
    "│       ├── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"mvtec_ad\"\n",
    "output_dir = \"mvtec_ad_classification\"\n",
    "\n",
    "split_ratios = {\n",
    "    \"train\": 0.7,\n",
    "    \"val\": 0.15,\n",
    "    \"test\": 0.15\n",
    "}\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_images(root_dir):\n",
    "    \"\"\"Collect (image_path, label) pairs from mvtec dataset.\"\"\"\n",
    "    all_images = []\n",
    "    categories = [d for d in Path(root_dir).iterdir() if d.is_dir()]\n",
    "\n",
    "    for category in categories:\n",
    "        train_good_dir = category / 'train' / 'good'\n",
    "        test_dir = category / 'test'\n",
    "\n",
    "        if train_good_dir.exists():\n",
    "            all_images.extend((img_path, 'good') for img_path in train_good_dir.glob('*'))\n",
    "\n",
    "        if test_dir.exists():\n",
    "            for defect_type in test_dir.iterdir():\n",
    "                label = 'good' if defect_type.name == 'good' else 'defect'\n",
    "                all_images.extend((img_path, label) for img_path in defect_type.glob('*'))\n",
    "\n",
    "    return all_images\n",
    "\n",
    "def split_images(all_images):\n",
    "    \"\"\"Shuffle and split images into train/val/test sets.\"\"\"\n",
    "    random.shuffle(all_images)\n",
    "    n_total = len(all_images)\n",
    "    n_train = int(n_total * split_ratios[\"train\"])\n",
    "    n_val = int(n_total * split_ratios[\"val\"])\n",
    "\n",
    "    train_set = all_images[:n_train]\n",
    "    val_set = all_images[n_train:n_train + n_val]\n",
    "    test_set = all_images[n_train + n_val:]\n",
    "\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def copy_and_rename(images, subset):\n",
    "    \"\"\"Copy and rename images to the output folder.\"\"\"\n",
    "    for idx, (src_path, label) in tqdm(enumerate(images), total=len(images), desc=f\"Copying {subset}\"):\n",
    "        subset_dir = Path(output_dir) / subset / label\n",
    "        subset_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst_path = subset_dir / f\"{idx:05d}{src_path.suffix.lower()}\"\n",
    "        shutil.copy(src_path, dst_path)\n",
    "\n",
    "def count_images(output_dir):\n",
    "    \"\"\"Simple count of images without pandas.\"\"\"\n",
    "    counts = Counter()\n",
    "    for subset in ['train/images_train', 'val/images_val', 'test/images_test']:\n",
    "        subset_dir = Path(output_dir) / subset\n",
    "        if not subset_dir.exists():\n",
    "            continue\n",
    "        for label in ['good', 'defect']:\n",
    "            label_dir = subset_dir / label\n",
    "            if not label_dir.exists():\n",
    "                continue\n",
    "            num_files = len(list(label_dir.glob('*')))\n",
    "            counts[(subset, label)] = num_files\n",
    "\n",
    "    print(f\"{'Subset':<20} {'Label':<10} {'Count':<6}\")\n",
    "    print(\"-\" * 40)\n",
    "    for (subset, label), count in sorted(counts.items()):\n",
    "        print(f\"{subset:<20} {label:<10} {count:<6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "\n",
    "all_images = collect_images(source_dir)\n",
    "train_set, val_set, test_set = split_images(all_images)\n",
    "\n",
    "copy_and_rename(train_set, 'train/images_train')\n",
    "copy_and_rename(val_set, 'val/images_val')\n",
    "copy_and_rename(test_set, 'test/images_test')\n",
    "\n",
    "print(f\"Formatted dataset saved to '{Path(output_dir).resolve()}'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate dataset format\n",
    "def print_folder_structure(root_dir, indent=0):\n",
    "    root_name = os.path.basename(root_dir)\n",
    "    print(root_name)\n",
    "\n",
    "    for item in sorted(os.listdir(root_dir)):\n",
    "        item_path = os.path.join(root_dir, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(' ' * (indent + 2) + '├── ' + item)\n",
    "            for subitem in sorted(os.listdir(item_path)):\n",
    "                subitem_path = os.path.join(item_path, subitem)\n",
    "                if os.path.isdir(subitem_path):\n",
    "                    print(' ' * (indent + 4) + '├── ' + subitem)\n",
    "                    # Print just one file as example\n",
    "                    files = sorted(os.listdir(subitem_path))\n",
    "                    if files:\n",
    "                        print(' ' * (indent + 6) + '├── ' + files[0])\n",
    "                        print(' ' * (indent + 6) + '├── ...')\n",
    "\n",
    "print_folder_structure(f\"{output_dir}/train\")\n",
    "print_folder_structure(f\"{output_dir}/val\")\n",
    "print_folder_structure(f\"{output_dir}/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package dataset and Upload to Cloud\n",
    "\n",
    "FTMS requires each split of the dataset to be archived and compressed with names `images_train.tar.gz`, `images_val.tar.gz` or `images_test.tar.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C mvtec_ad_classification/test -zcf mvtec_ad_classification/test/images_test.tar.gz images_test\n",
    "!rm -rf mvtec_ad_classification/test/images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C mvtec_ad_classification/train -zcf mvtec_ad_classification/train/images_train.tar.gz images_train\n",
    "!rm -rf mvtec_ad_classification/train/images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C mvtec_ad_classification/val -zcf mvtec_ad_classification/val/images_val.tar.gz images_val\n",
    "!rm -rf mvtec_ad_classification/val/images_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Cloud Storage\n",
    "\n",
    "If using an AWS S3 bucket, you can use the following command to upload the formatted dataset through the [AWS CLI](https://aws.amazon.com/cli/): \n",
    "\n",
    "```aws s3 sync mvtec_ad_classification s3://bucket_name/datasets/mvtec_ad_classification```\n",
    "\n",
    "You should now have dataset paths in your cloud storage at \n",
    "\n",
    "- /bucket_name/datasets/mvtec_ad_classification/train\n",
    "- /bucket_name/datasets/mvtec_ad_classification/val\n",
    "- /bucket_name/datasets/mvtec_ad_classification/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
