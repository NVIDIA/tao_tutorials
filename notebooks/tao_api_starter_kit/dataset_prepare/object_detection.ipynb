{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "1. Choose between default and custom dataset in FIXME 2\n",
    "1. Assign path of DATA_DIR in FIXME 3\n",
    "1. Assign Cloud credentials in FIXME 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. deformable_detr - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/deformable_detr.html\n",
    "# 2. dino - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/dino.html\n",
    "# 3. efficientdet_tf2 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/efficientdet_tf2.html\n",
    "# 4. grounding_dino - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/grounding_dino.html\n",
    "# 5. rtdetr - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/rtdetr.html\n",
    "\n",
    "model_name = \"dino\" # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset source and structure <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using NVIDIA created `Synthetic Object detection data` based on KITTI dataset format in this notebook. To find more details about kitti format, please visit [here](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "$DATA_DIR/train\n",
    "├── images\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "$DATA_DIR/val\n",
    "├── images\n",
    "│   ├── image_name_5.jpg\n",
    "│   ├── image_name_6.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_5.txt\n",
    "    ├── image_name_6.txt\n",
    "    ├── ...\n",
    "```\n",
    "The file name should be same for images and labels folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_format = \"coco\"\n",
    "ds_type = \"object_detection\"\n",
    "if model_name == \"grounding_dino\":\n",
    "    ds_format = \"odvg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_be_used = \"default\" #FIXME2 #default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "DATA_DIR = model_name #FIXME3\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download and pre-processing <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    if model_name == \"grounding_dino\":\n",
    "        if not os.path.exists(f\"{DATA_DIR}/HardHatWorkers/raw\"):\n",
    "            !bash grounding_dino/download_hardhat.sh $DATA_DIR\n",
    "        assert(os.path.exists(f\"{DATA_DIR}/HardHatWorkers/raw\"))\n",
    "        \n",
    "        print(\"Converting coco to odvg\")\n",
    "        !python3 -m pip install --upgrade numpy pycocotools tqdm\n",
    "        from coco.coco_to_odvg import convert_coco_to_odvg\n",
    "        from coco.coco_to_contiguous import convert_coco_to_contiguous\n",
    "        !mkdir -p {DATA_DIR}/odvg/annotations\n",
    "        convert_coco_to_odvg(f\"{DATA_DIR}/HardHatWorkers/raw/train/annotations_without_background.json\", f\"{DATA_DIR}/odvg/annotations/\")\n",
    "        convert_coco_to_contiguous(f\"{DATA_DIR}/HardHatWorkers/raw/valid/annotations_without_background.json\", f\"{DATA_DIR}/odvg/annotations/\", use_all_categories=True)\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/odvg/annotations/annotations_without_background_odvg.jsonl\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/odvg/annotations/annotations_without_background_odvg_labelmap.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/odvg/annotations/annotations_without_background_remapped.json\"))\n",
    "    else:\n",
    "        !python3 -m pip install --upgrade awscli\n",
    "        !aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_train.tar.gz $DATA_DIR/\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/tao_od_synthetic_train.tar.gz\"))\n",
    "        !aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_val.tar.gz $DATA_DIR/\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/tao_od_synthetic_val.tar.gz\"))\n",
    "\n",
    "        print(\"Untarring file\")\n",
    "        os.makedirs(f\"{DATA_DIR}/train\", exist_ok=True)\n",
    "        !tar -xzf {DATA_DIR}/tao_od_synthetic_train.tar.gz -C {DATA_DIR}/train\n",
    "        os.makedirs(f\"{DATA_DIR}/val\", exist_ok=True)\n",
    "        !tar -xzf {DATA_DIR}/tao_od_synthetic_val.tar.gz -C {DATA_DIR}/val\n",
    "\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/train/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/train/labels\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/val/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/val/labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"grounding_dino\":\n",
    "    # Organize train dataset\n",
    "    !mkdir -p {DATA_DIR}/HardHatWorkers/raw/train/images {DATA_DIR}/cloud_folders/data/object_detection_gdino_train\n",
    "    !mv {DATA_DIR}/HardHatWorkers/raw/train/*.jpg {DATA_DIR}/HardHatWorkers/raw/train/images/\n",
    "    !tar -C {DATA_DIR}/HardHatWorkers/raw/train -czf \\\n",
    "        {DATA_DIR}/cloud_folders/data/object_detection_gdino_train/images.tar.gz images\n",
    "    !cp {DATA_DIR}/odvg/annotations/annotations_without_background_odvg.jsonl \\\n",
    "        {DATA_DIR}/cloud_folders/data/object_detection_gdino_train/annotations_odvg.jsonl\n",
    "    !cp {DATA_DIR}/odvg/annotations/annotations_without_background_odvg_labelmap.json \\\n",
    "        {DATA_DIR}/cloud_folders/data/object_detection_gdino_train/annotations_odvg_labelmap.json\n",
    "\n",
    "    # Organize val dataset\n",
    "    !mkdir -p {DATA_DIR}/HardHatWorkers/raw/valid/images {DATA_DIR}/cloud_folders/data/object_detection_gdino_val\n",
    "    !mv {DATA_DIR}/HardHatWorkers/raw/valid/*.jpg {DATA_DIR}/HardHatWorkers/raw/valid/images/\n",
    "    !tar -C {DATA_DIR}/HardHatWorkers/raw/valid -czf \\\n",
    "        {DATA_DIR}/cloud_folders/data/object_detection_gdino_val/images.tar.gz images\n",
    "    !cp {DATA_DIR}/odvg/annotations/annotations_without_background_remapped.json \\\n",
    "        {DATA_DIR}/cloud_folders/data/object_detection_gdino_val/annotations.json\n",
    "else:\n",
    "    !python3 -m pip install ujson opencv-python tqdm\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"train\")):\n",
    "        raise Exception(\"Train dataset not present\")\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"val\")):\n",
    "        raise Exception(\"Eval dataset not present\")\n",
    "\n",
    "    #kitti to coco conversion for efficientdet\n",
    "    if model_name == \"efficientdet_tf2\":\n",
    "        label_map_extension = \"yaml\"\n",
    "    else:\n",
    "        label_map_extension = \"txt\"\n",
    "    num_classes = subprocess.getoutput(f'python3 kitti/kitti_to_coco.py {DATA_DIR}/train/labels {DATA_DIR}/train {label_map_extension}')\n",
    "    subprocess.getoutput(f'python3 kitti/kitti_to_coco.py {DATA_DIR}/val/labels {DATA_DIR}/val {label_map_extension}')\n",
    "\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/annotations.json\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/label_map.{label_map_extension}\"))\n",
    "\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/annotations.json\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/label_map.{label_map_extension}\"))\n",
    "\n",
    "    if model_name == \"efficientdet_tf2\":\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/object_detection_tf2_train {DATA_DIR}/cloud_folders/data/object_detection_tf2_val\n",
    "        !tar -C {DATA_DIR}/train -czf {DATA_DIR}/cloud_folders/data/object_detection_tf2_train/images.tar.gz images\n",
    "        !tar -C {DATA_DIR}/val -czf {DATA_DIR}/cloud_folders/data/object_detection_tf2_val/images.tar.gz images\n",
    "        !cp {DATA_DIR}/train/annotations.json {DATA_DIR}/train/label_map.{label_map_extension} {DATA_DIR}/cloud_folders/data/object_detection_tf2_train\n",
    "        !cp {DATA_DIR}/val/annotations.json {DATA_DIR}/val/label_map.{label_map_extension} {DATA_DIR}/cloud_folders/data/object_detection_tf2_val\n",
    "    else:\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/object_detection_pyt_train {DATA_DIR}/cloud_folders/data/object_detection_pyt_val\n",
    "        !tar -C {DATA_DIR}/train -czf {DATA_DIR}/cloud_folders/data/object_detection_pyt_train/images.tar.gz images\n",
    "        !tar -C {DATA_DIR}/val -czf {DATA_DIR}/cloud_folders/data/object_detection_pyt_val/images.tar.gz images\n",
    "        !cp {DATA_DIR}/train/annotations.json {DATA_DIR}/train/label_map.{label_map_extension} {DATA_DIR}/cloud_folders/data/object_detection_pyt_train\n",
    "        !cp {DATA_DIR}/val/annotations.json {DATA_DIR}/val/label_map.{label_map_extension} {DATA_DIR}/cloud_folders/data/object_detection_pyt_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Upload the /data folder to your cloud storage and move on to running the API requests example notebooks\n",
    "When you do a ls of your bucket it should have /data folder and the subfolders we created above within in (object_detection_pyt_train, object_detection_pyt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade awscli\n",
    "ACCESS_KEY=FIXME4.1\n",
    "SECRET_KEY=FIXME4.2\n",
    "BUCKET_NAME=FIXME4.3\n",
    "if model_name == \"grounding_dino\":\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_gdino_train s3://{BUCKET_NAME}/data/object_detection_gdino_train/ --recursive\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_gdino_val s3://{BUCKET_NAME}/data/object_detection_gdino_val/ --recursive\n",
    "elif model_name == \"efficientdet_tf2\":\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_tf2_train s3://{BUCKET_NAME}/data/object_detection_tf2_train/ --recursive\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_tf2_val s3://{BUCKET_NAME}/data/object_detection_tf2_val/ --recursive\n",
    "else:\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_pyt_train s3://{BUCKET_NAME}/data/object_detection_pyt_train/ --recursive\n",
    "  !AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/object_detection_pyt_val s3://{BUCKET_NAME}/data/object_detection_pyt_val/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For EfficientdetTF2 use /data/object_detection_tf2_train instead of /data/object_detection_pyt_train, similartly for val as well\n",
    "# This will be the paths in your API/TAO-CLIENT Notebooks\n",
    "if model_name == \"grounding_dino\":\n",
    "  train_dataset_path = \"/data/object_detection_gdino_train\"\n",
    "  eval_dataset_path = \"/data/object_detection_gdino_val\"\n",
    "elif model_name == \"efficientdet_tf2\":\n",
    "  train_dataset_path = \"/data/object_detection_tf2_train\"\n",
    "  eval_dataset_path = \"/data/object_detection_tf2_val\"\n",
    "else:\n",
    "  train_dataset_path = \"/data/object_detection_pyt_train\"\n",
    "  eval_dataset_path = \"/data/object_detection_pyt_val\"\n",
    "  test_dataset_path = \"/data/object_detection_pyt_val\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
