{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foundational Model Finetuning dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this notebook, you will have datasets that can be used to train and optimize a foundational model as demonstrated in [this notebook](../dataset_prepare/foundational_model_finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Choose between default and custom dataset in FIXME 1 - default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "1. Assign path of DATA_DIR in FIXME 2\n",
    "1. Assign Cloud credentials in FIXME 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need download the ImageNet2012 dataset and format it into train/ val/ test folders. The train, val folders should be unzipped and placed in $DATA_DIR/imagenet.\n",
    "\n",
    "The Data can be Downloaded by following instructions here: \n",
    "[MMPretrain Imagenet Download Instructions](https://mmpretrain.readthedocs.io/en/latest/user_guides/dataset_prepare.html) \n",
    "\n",
    "Go to official [Download page](http://www.image-net.org/download-images). Find download links for ILSVRC2012 and download the following two files.\n",
    "\n",
    "* ILSVRC2012_img_train.tar (~138GB)\n",
    "\n",
    "    * For training untar the class folders into the `train` such that the train folder has 1000 folders corresponding to each class.\n",
    "\n",
    "* ILSVRC2012_img_val.tar (~6.3GB)\n",
    "    * For validation images: You need to move the images to respective class folders. You can use this script for the same [valprep](https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh).\n",
    "\n",
    "You can also use this shell script to perform the above 2 steps: [extract_ILSVRC script](https://github.com/pytorch/examples/blob/main/imagenet/extract_ILSVRC.sh).\n",
    "Example contents of the final train/ val folder looks like this:\n",
    "\n",
    "**./train**\n",
    "\n",
    "    n07693725\n",
    "    ...\n",
    "    n07614500\n",
    "\n",
    "**./val**\n",
    "\n",
    "    n07693725\n",
    "    ...\n",
    "    n07614500\n",
    "\n",
    "\n",
    "The above steps can also be performed by the following bash commands, if you have not downloaded the ImageNet 2012 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This Notebook example uses subset of 1000 classes (cats and dogs). If you are using your custom dataset other than ImageNet - Please update the `dataset.data` config with `classes` field that points to a file with class names. Please refer to documentation for more details on the classes text file. Update the `num_classes` under `model.head` accordingly. For reference: Please refer to the `train_cats_dogs.yaml` in specs of `clsasification_pyt` under parent directory which gives an example of fine-tuning on 2-classes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_be_used = \"default\" #FIXME1 \n",
    "DATA_DIR = \"/data/fm/nvdino_v2\" #FIXME2\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download and pre-processing <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    !wget https://www.dropbox.com/s/wml49yrtdo53mie/cats_dogs_dataset_reorg.zip?dl=0 -O $DATA_DIR/cats_dogs_dataset.zip\n",
    "    !unzip -qo $DATA_DIR/cats_dogs_dataset.zip -d $DATA_DIR/\n",
    "    !rm $DATA_DIR/cats_dogs_dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the dataset is downloaded\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/training_set/training_set\"), \"Training Dataset Not Found. Please check properly.\"\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/val_set/val_set\"), \"Val Dataset Not Found. Please check properly.\"\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/test_set/test_set\"), \"Test Dataset Not Found. Please check properly.\"\n",
    "assert len(os.listdir(f\"{DATA_DIR}/cats_dogs_dataset/training_set/training_set\")) == 2, \"Dataset validation failed. Sample dataset should have 2 classes.\"\n",
    "\n",
    "!mv $DATA_DIR/cats_dogs_dataset/training_set/training_set $DATA_DIR/cats_dogs_dataset/training_set/images_train\n",
    "!mv $DATA_DIR/cats_dogs_dataset/val_set/val_set $DATA_DIR/cats_dogs_dataset/val_set/images_val\n",
    "!mv $DATA_DIR/cats_dogs_dataset/test_set/test_set $DATA_DIR/cats_dogs_dataset/test_set/images_test\n",
    "\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/training_set/images_train\")\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/val_set/images_val\")\n",
    "assert os.path.exists(f\"{DATA_DIR}/cats_dogs_dataset/test_set/images_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tar files to upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $DATA_DIR/cloud_folders/data/nvdinov2_train $DATA_DIR/cloud_folders/data/nvdinov2_val $DATA_DIR/cloud_folders/data/nvdinov2_test\n",
    "\n",
    "!tar -C $DATA_DIR/cats_dogs_dataset/training_set -czf $DATA_DIR/cloud_folders/data/nvdinov2_train/images_train.tar.gz images_train\n",
    "!tar -C $DATA_DIR/cats_dogs_dataset/val_set -czf $DATA_DIR/cloud_folders/data/nvdinov2_val/images_val.tar.gz images_val\n",
    "!tar -C $DATA_DIR/cats_dogs_dataset/test_set -czf $DATA_DIR/cloud_folders/data/nvdinov2_test/images_test.tar.gz images_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Upload the /data folder to your cloud storage and move on to running the API requests example notebooks\n",
    "When you do a ls of your bucket it should have /data folder and the subfolders we created above within in (classification_train, classification_val, classification_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade awscli\n",
    "ACCESS_KEY=FIXME3.1\n",
    "SECRET_KEY=FIXME3.2\n",
    "BUCKET_NAME=FIXME3.3\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/nvdinov2_train s3://{BUCKET_NAME}/data/nvdinov2_train_tiny --recursive\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/nvdinov2_val s3://{BUCKET_NAME}/data/nvdinov2_val_tiny --recursive\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/nvdinov2_test s3://{BUCKET_NAME}/data/nvdinov2_test_tiny --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"/data/nvdinov2_train_cats_dogs\"\n",
    "eval_dataset_path = \"/data/nvdinov2_val_cats_dogs\"\n",
    "test_dataset_path = \"/data/nvdinov2_test_cats_dogs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
