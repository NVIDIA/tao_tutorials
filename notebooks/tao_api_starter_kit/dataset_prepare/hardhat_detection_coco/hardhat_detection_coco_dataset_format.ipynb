{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HardHat Detection Dataset Formatting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the [Safety Helmet Detection dataset from Kaggle](https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection) in COCO format to use with TAO FTMS to train detection models. This notebook is a pre-requisite for the [rtdetr_detection_distillation.ipynb](https://github.com/NVIDIA/tao_tutorials/tree/main/notebooks/tao_api_starter_kit/api/rtdetr_detection_distillation.ipynb) example notebook. \n",
    "\n",
    "To get started, run all cells in the notebook then upload the output folder ```hardhat_detection_coco``` to your cloud storage. The notebook will automatically download the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and format dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -L -o ./hard-hat-detection.zip https://www.kaggle.com/api/v1/datasets/download/andrewmvd/hard-hat-detection\n",
    "!unzip -q -d hard_hat_detection hard-hat-detection.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Train/Val/Test split. \n",
    "train_split = 0.7\n",
    "val_split = 0.15 \n",
    "test_split = 0.15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Config\n",
    "dataset_dir = \"./hard_hat_detection\"\n",
    "annotations_dir = os.path.join(dataset_dir, \"annotations\")\n",
    "images_dir = os.path.join(dataset_dir, \"images\")\n",
    "output_base_dir = \"./hard_hat_detection_coco\"\n",
    "\n",
    "splits = {\n",
    "    \"train\": train_split,\n",
    "    \"val\": val_split,\n",
    "    \"test\": test_split\n",
    "}\n",
    "\n",
    "categories = [\n",
    "    {\"id\": 1, \"name\": \"helmet\", \"supercategory\": \"helmet\"},\n",
    "    {\"id\": 2, \"name\": \"head\", \"supercategory\": \"head\"}\n",
    "]\n",
    "category_name_to_id = {cat[\"name\"]: cat[\"id\"] for cat in categories}\n",
    "\n",
    "# Gather and shuffle all annotation files\n",
    "xml_files = [f for f in os.listdir(annotations_dir) if f.endswith(\".xml\")]\n",
    "random.shuffle(xml_files)\n",
    "total = len(xml_files)\n",
    "\n",
    "# Calculate split sizes\n",
    "split_counts = {\n",
    "    \"train\": int(total * splits[\"train\"]),\n",
    "    \"val\": int(total * splits[\"val\"])\n",
    "}\n",
    "split_counts[\"test\"] = total - split_counts[\"train\"] - split_counts[\"val\"]\n",
    "\n",
    "# Assign files to splits\n",
    "split_files = {\n",
    "    \"train\": xml_files[:split_counts[\"train\"]],\n",
    "    \"val\": xml_files[split_counts[\"train\"]:split_counts[\"train\"] + split_counts[\"val\"]],\n",
    "    \"test\": xml_files[split_counts[\"train\"] + split_counts[\"val\"]:]\n",
    "}\n",
    "\n",
    "# Main processing function\n",
    "def process_split(split_name, file_list, starting_image_id=1, starting_ann_id=1):\n",
    "    image_id = starting_image_id\n",
    "    annotation_id = starting_ann_id\n",
    "    annotations = []\n",
    "    images = []\n",
    "\n",
    "    split_dir = os.path.join(output_base_dir, split_name)\n",
    "    images_output_dir = os.path.join(split_dir, \"images\")\n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "\n",
    "    for idx, xml_file in enumerate(tqdm(file_list, desc=f\"Processing {split_name}\")):\n",
    "        xml_path = os.path.join(annotations_dir, xml_file)\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        original_filename = root.find(\"filename\").text\n",
    "        source_img_path = os.path.join(images_dir, original_filename)\n",
    "        if not os.path.exists(source_img_path):\n",
    "            print(f\"⚠️ Missing image: {original_filename}\")\n",
    "            continue\n",
    "\n",
    "        width = int(root.find(\"size/width\").text)\n",
    "        height = int(root.find(\"size/height\").text)\n",
    "\n",
    "        # Create COCO-style 6-digit filenames\n",
    "        new_filename = f\"{idx:06d}.png\"\n",
    "        target_img_path = os.path.join(images_output_dir, new_filename)\n",
    "        shutil.copy2(source_img_path, target_img_path)\n",
    "\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": new_filename,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "        })\n",
    "\n",
    "        for obj in root.findall(\"object\"):\n",
    "            name = obj.find(\"name\").text\n",
    "            if name not in category_name_to_id:\n",
    "                continue\n",
    "            category_id = category_name_to_id[name]\n",
    "            bndbox = obj.find(\"bndbox\")\n",
    "            xmin = float(bndbox.find(\"xmin\").text)\n",
    "            ymin = float(bndbox.find(\"ymin\").text)\n",
    "            xmax = float(bndbox.find(\"xmax\").text)\n",
    "            ymax = float(bndbox.find(\"ymax\").text)\n",
    "            w = xmax - xmin\n",
    "            h = ymax - ymin\n",
    "            area = w * h\n",
    "\n",
    "            annotations.append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": category_id,\n",
    "                \"bbox\": [xmin, ymin, w, h],\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "        image_id += 1\n",
    "\n",
    "    # Save annotations JSON\n",
    "    coco_dict = {\n",
    "        \"images\": images,\n",
    "        \"annotations\": annotations,\n",
    "        \"categories\": categories\n",
    "    }\n",
    "    with open(os.path.join(split_dir, \"annotations.json\"), \"w\") as f:\n",
    "        json.dump(coco_dict, f, indent=4)\n",
    "\n",
    "    # Save label maps\n",
    "    with open(os.path.join(split_dir, \"label_map.txt\"), \"w\") as f:\n",
    "        f.write(\"helmet\\nhead\\n\")\n",
    "\n",
    "    with open(os.path.join(split_dir, \"label_map.yaml\"), \"w\") as f:\n",
    "        f.write(\"1: 'helmet'\\n2: 'head'\\n\")\n",
    "\n",
    "    print(f\"✅ Saved {split_name}: {len(images)} images and {len(annotations)} annotations.\")\n",
    "\n",
    "# Execute processing\n",
    "img_id = 1\n",
    "ann_id = 1\n",
    "for split, files in split_files.items():\n",
    "    process_split(split, files, img_id, ann_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C hard_hat_detection_coco/test -zcf hard_hat_detection_coco/test/images.tar.gz images\n",
    "!rm -rf hard_hat_detection_coco/test/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C hard_hat_detection_coco/train -zcf hard_hat_detection_coco/train/images.tar.gz images\n",
    "!rm -rf hard_hat_detection_coco/train/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -C hard_hat_detection_coco/val -zcf hard_hat_detection_coco/val/images.tar.gz images\n",
    "!rm -rf hard_hat_detection_coco/val/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Cloud Storage\n",
    "\n",
    "If using an AWS S3 bucket, you can use the following command to upload the formatted dataset through the [AWS CLI](https://aws.amazon.com/cli/): \n",
    "\n",
    "```aws s3 sync hard_hat_detection_coco s3://bucket_name/datasets/hard_hat_detection_coco```\n",
    "\n",
    "You should now have dataset paths in your cloud storage at \n",
    "\n",
    "- /bucket_name/datasets/hard_hat_detection_coco/train\n",
    "- /bucket_name/datasets/hard_hat_detection_coco/val\n",
    "- /bucket_name/datasets/hard_hat_detection_coco/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
