{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Labeling dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Choose between default and custom dataset in FIXME 1\n",
    "1. Assign path of DATA_DIR in FIXME 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mal\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset source and structure <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `COCO dataset`. `download_coco.sh` script from dataset prepare will be used to download and unzip the coco2017 dataset from [here](https://cocodataset.org/#download)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "DATA_DIR\n",
    "├── annotations.json\n",
    "├── images\n",
    "    ├── image_name_1.jpg\n",
    "    ├── image_name_2.jpg\n",
    "    ├── ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_to_be_used = \"default\" #FIXME1 #default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "DATA_DIR = model_name #FIXME2\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    !bash coco/download_coco.sh $DATA_DIR\n",
    "    # Remove existing data\n",
    "    !rm -rf $DATA_DIR/train2017/images\n",
    "    !rm -rf $DATA_DIR/val2017/images\n",
    "    # Rearrange data in the required format\n",
    "    !mkdir -p $DATA_DIR/train2017/\n",
    "    !mkdir -p $DATA_DIR/val2017/\n",
    "    !mv $DATA_DIR/raw-data/train2017 $DATA_DIR/train2017/images\n",
    "    !mv $DATA_DIR/raw-data/annotations/instances_train2017.json $DATA_DIR/train2017/annotations.json\n",
    "    !mv $DATA_DIR/raw-data/val2017 $DATA_DIR/val2017/images\n",
    "    !mv $DATA_DIR/raw-data/annotations/instances_val2017.json $DATA_DIR/val2017/annotations.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the downloaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ ! -d $DATA_DIR/train2017/images ]; then echo 'Images folder not found'; else echo 'Found images folder';fi\n",
    "!if [ ! -f $DATA_DIR/train2017/annotations.json ]; then echo 'annotations file not found'; else echo 'Found annotations file';fi\n",
    "!if [ ! -d $DATA_DIR/val2017/images ]; then echo 'Images folder not found'; else echo 'Found images folder';fi\n",
    "!if [ ! -f $DATA_DIR/val2017/annotations.json ]; then echo 'annotations file not found'; else echo 'Found annotations file';fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a subset of images from COCO dataset\n",
    "# comment out if you need full dataset\n",
    "!python3 mask_grounding_dino/extract_subset.py $DATA_DIR/train2017/images $DATA_DIR/train2017/annotations.json $DATA_DIR/train2017_subset 100\n",
    "!python3 mask_grounding_dino/extract_subset.py $DATA_DIR/val2017/images $DATA_DIR/val2017/annotations.json $DATA_DIR/val2017_subset true 5\n",
    "assert (os.path.exists(f\"{DATA_DIR}/train2017_subset/images\"))\n",
    "assert (os.path.exists(f\"{DATA_DIR}/train2017_subset/annotations.json\"))\n",
    "assert (os.path.exists(f\"{DATA_DIR}/val2017_subset/images\"))\n",
    "assert (os.path.exists(f\"{DATA_DIR}/val2017_subset/annotations.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $DATA_DIR/cloud_folders/data/train\n",
    "!mkdir -p $DATA_DIR/cloud_folders/data/val\n",
    "\n",
    "!tar -C $DATA_DIR/train2017_subset -czf $DATA_DIR/cloud_folders/data/train/images.tar.gz images\n",
    "!tar -C $DATA_DIR/val2017_subset -czf $DATA_DIR/cloud_folders/data/val/images.tar.gz images\n",
    "!cp $DATA_DIR/train2017_subset/annotations.json $DATA_DIR/cloud_folders/data/train/annotations.json\n",
    "!cp $DATA_DIR/val2017_subset/annotations.json $DATA_DIR/cloud_folders/data/val/annotations.json\n",
    "!cp coco_panoptic/labelmap.json $DATA_DIR/cloud_folders/data/train/label_map.json\n",
    "!cp coco_panoptic/labelmap.json $DATA_DIR/cloud_folders/data/val/label_map.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Upload the tar files to your cloud storage and move on to running the API requests example notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade awscli\n",
    "ACCESS_KEY=FIXME4.1\n",
    "SECRET_KEY=FIXME4.2\n",
    "BUCKET_NAME=FIXME4.3\n",
    "\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp $DATA_DIR/cloud_folders/data/train s3://{BUCKET_NAME}/data/auto_label_train --recursive\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp $DATA_DIR/cloud_folders/data/val s3://{BUCKET_NAME}/data/auto_label_val --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the paths in your API/TAO-CLIENT Notebooks\n",
    "train_dataset_path = f\"/data/auto_label_train\"\n",
    "eval_dataset_path = f\"/data/auto_label_val\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
