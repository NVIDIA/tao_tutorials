{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "1. Choose between default and custom dataset in FIXME 2\n",
    "1. Assign path of DATA_DIR in FIXME 3\n",
    "1. Assign Cloud credentials in FIXME 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. segformer - https://docs.nvidia.com/tao/tao-toolkit/text/semantic_segmentation/segformer.html\n",
    "# 2. mask2former - https://docs.nvidia.com/tao/tao-toolkit/text/cv_finetuning/pytorch/instance_segmentation/mask2former.html\n",
    "# 3. mask_grounding_dino - https://docs.nvidia.com/tao/tao-toolkit/text/cv_finetuning/pytorch/instance_segmentation/mask_grounding_dino.html\n",
    "\n",
    "model_name = \"mask_grounding_dino\" # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example dataset source and structure <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semantic Segmentation:**\n",
    "We will be using the `ISBI Challenge: Segmentation of neuronal structures in EM stacks dataset` for the binary segmentation tutorial (Unet and Segformer). Please access the open source repo [here](https://github.com/alexklibisz/isbi-2012/tree/master/data) to download the data. The data is in .tif format. Copy the train-labels.tif, train-volume.tif, test-volume.tif files to `DATA_DIR`.\n",
    "\n",
    "**Instance Segmentation:**\n",
    "We will be using the `COCO dataset` (A subset in this notebook) for `Mask Grounding Dino` model. The following script will download COCO dataset automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "DATA_DIR\n",
    "├── images\n",
    "│   ├── test\n",
    "│   │   ├── image_0.png\n",
    "│   │   ├── image_1.png\n",
    "|   |   ├── ...\n",
    "│   ├── train\n",
    "│   │   ├── image_2.png\n",
    "│   │   ├── image_3.png\n",
    "|   |   ├── ...\n",
    "│   └── val\n",
    "│       ├── image_4.png\n",
    "│       ├── image_5.png\n",
    "|       ├── ...\n",
    "├── masks\n",
    "    ├── train\n",
    "    │   ├── image_2.png\n",
    "    │   ├── image_3.png\n",
    "    |   ├── ...\n",
    "    └── val\n",
    "        ├── image_4.png\n",
    "        ├── image_5.png\n",
    "        ├── ...\n",
    "\n",
    "```\n",
    "The filename should match for images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dataset_to_be_used = \"default\" #FIXME2 #default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "DATA_DIR = f'/data/{model_name}' #FIXME3\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download and pre-processing <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Verify the downloaded dataset\n",
    "if dataset_to_be_used == \"default\":\n",
    "    if model_name == \"mask_grounding_dino\":\n",
    "        if not os.path.exists(f\"{DATA_DIR}/raw-data\"):\n",
    "            !bash coco/download_coco.sh $DATA_DIR\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data\"))\n",
    "\n",
    "        # extract a subset of images from COCO dataset\n",
    "        # comment out if you need full dataset\n",
    "        !python3 mask_grounding_dino/extract_subset.py $DATA_DIR/raw-data/train2017 $DATA_DIR/raw-data/annotations/instances_train2017.json $DATA_DIR/raw-data/train2017_subset 100\n",
    "        !python3 mask_grounding_dino/extract_subset.py $DATA_DIR/raw-data/val2017 $DATA_DIR/raw-data/annotations/instances_val2017.json $DATA_DIR/raw-data/val2017_subset true 5\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/instances_train2017.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/instances_val2017.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/label_map.json\"))\n",
    "\n",
    "        # Convert coco to odvg and contiguous format\n",
    "        RESULTS_DIR = f\"{DATA_DIR}/odvg/annotations\"\n",
    "        !mkdir -p $RESULTS_DIR\n",
    "        !python3 -m pip install numpy pycocotools tqdm\n",
    "        from coco.coco_to_odvg import convert_coco_to_odvg\n",
    "        convert_coco_to_odvg(f\"{DATA_DIR}/raw-data/train2017_subset/instances_train2017.json\", RESULTS_DIR)\n",
    "        assert (os.path.exists(f\"{RESULTS_DIR}/instances_train2017_odvg.jsonl\"))\n",
    "        assert (os.path.exists(f\"{RESULTS_DIR}/instances_train2017_odvg_labelmap.json\"))\n",
    "    elif model_name == \"mask2former\":\n",
    "        if not os.path.exists(f\"{DATA_DIR}/raw-data\"):\n",
    "            !bash coco_panoptic/download_coco.sh $DATA_DIR\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data\"))\n",
    "\n",
    "        # extract a subset of images from COCO dataset\n",
    "        # comment out if you need full dataset\n",
    "        !python3 coco_panoptic/extract_subset.py $DATA_DIR/raw-data/train2017 $DATA_DIR/raw-data/panoptic_train2017 $DATA_DIR/raw-data/annotations/instances_train2017.json $DATA_DIR/raw-data/annotations/panoptic_train2017.json $DATA_DIR/raw-data/train2017_subset 100\n",
    "        !python3 coco_panoptic/extract_subset.py $DATA_DIR/raw-data/val2017 $DATA_DIR/raw-data/panoptic_val2017 $DATA_DIR/raw-data/annotations/instances_val2017.json $DATA_DIR/raw-data/annotations/panoptic_val2017.json $DATA_DIR/raw-data/val2017_subset 5\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/masks\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/instances_train2017.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/train2017_subset/panoptic_train2017.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/images\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/masks\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/instances_val2017.json\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/raw-data/val2017_subset/panoptic_val2017.json\"))\n",
    "\n",
    "    else:\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/train-volume.tif\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/train-labels.tif\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/test-volume.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    if model_name == \"mask_grounding_dino\":\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/train\n",
    "        !tar -C {DATA_DIR}/raw-data/train2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/images.tar.gz images\n",
    "        !cp {DATA_DIR}/odvg/annotations/instances_train2017_odvg.jsonl \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/annotations_odvg.jsonl\n",
    "        !cp {DATA_DIR}/odvg/annotations/instances_train2017_odvg_labelmap.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/annotations_odvg_labelmap.json\n",
    "\n",
    "        # Organize val dataset\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/val\n",
    "        !tar -C {DATA_DIR}/raw-data/val2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/images.tar.gz images\n",
    "        !cp {DATA_DIR}/raw-data/val2017_subset/instances_val2017.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/annotations.json\n",
    "        !cp {DATA_DIR}/raw-data/val2017_subset/label_map.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/label_map.json\n",
    "\n",
    "    elif model_name == \"mask2former\":\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/train\n",
    "        !mkdir -p {DATA_DIR}/cloud_folders/data/val\n",
    "\n",
    "        !tar -C {DATA_DIR}/raw-data/train2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/images.tar.gz images\n",
    "        !tar -C {DATA_DIR}/raw-data/train2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/images_panoptic.tar.gz masks\n",
    "        !cp {DATA_DIR}/raw-data/train2017_subset/instances_train2017.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/annotations.json\n",
    "        !cp {DATA_DIR}/raw-data/train2017_subset/panoptic_train2017.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/annotations_panoptic.json\n",
    "        !cp coco_panoptic/labelmap.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/train/label_map_panoptic.json\n",
    "        \n",
    "        !tar -C {DATA_DIR}/raw-data/val2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/images.tar.gz images\n",
    "        !tar -C {DATA_DIR}/raw-data/val2017_subset -czf \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/images_panoptic.tar.gz masks\n",
    "        !cp {DATA_DIR}/raw-data/val2017_subset/instances_val2017.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/annotations.json\n",
    "        !cp {DATA_DIR}/raw-data/val2017_subset/panoptic_val2017.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/annotations_panoptic.json\n",
    "        !cp coco_panoptic/labelmap.json \\\n",
    "            {DATA_DIR}/cloud_folders/data/val/label_map_panoptic.json\n",
    "\n",
    "    else:\n",
    "        !python3 -m pip install Pillow opencv-python numpy\n",
    "        # create images and masks from the tif files\n",
    "        !bash unet/prepare_data.sh $DATA_DIR\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/images/train\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/images/val\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/images/test\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/masks/train\"))\n",
    "        assert (os.path.exists(f\"{DATA_DIR}/masks/val\"))\n",
    "\n",
    "        !mkdir -p $DATA_DIR/cloud_folders/data/train/images\n",
    "        !mkdir -p $DATA_DIR/cloud_folders/data/train/masks\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/train/images/train.tar.gz train\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/train/images/val.tar.gz val\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/train/images/test.tar.gz test\n",
    "        !tar -C {DATA_DIR}/masks -czf $DATA_DIR/cloud_folders/data/train/masks/train.tar.gz train\n",
    "        !tar -C {DATA_DIR}/masks -czf $DATA_DIR/cloud_folders/data/train/masks/val.tar.gz val\n",
    "\n",
    "        !mkdir -p $DATA_DIR/cloud_folders/data/val/images\n",
    "        !mkdir -p $DATA_DIR/cloud_folders/data/val/masks\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/val/images/train.tar.gz train\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/val/images/val.tar.gz val\n",
    "        !tar -C {DATA_DIR}/images -czf $DATA_DIR/cloud_folders/data/val/images/test.tar.gz test\n",
    "        !tar -C {DATA_DIR}/masks -czf $DATA_DIR/cloud_folders/data/val/masks/train.tar.gz train\n",
    "        !tar -C {DATA_DIR}/masks -czf $DATA_DIR/cloud_folders/data/val/masks/val.tar.gz val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final step: Upload the /data folder to your cloud storage and move on to running the API requests example notebooks\n",
    "When you do a ls of your bucket it should have /data folder and the subfolders we created above within in (object_detection_pyt_train, object_detection_pyt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade awscli\n",
    "ACCESS_KEY=FIXME4.1\n",
    "SECRET_KEY=FIXME4.2\n",
    "BUCKET_NAME=FIXME4.3\n",
    "\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/train s3://{BUCKET_NAME}/data/segmentation_{model_name}_train --recursive\n",
    "!AWS_ACCESS_KEY_ID={ACCESS_KEY} AWS_SECRET_ACCESS_KEY={SECRET_KEY} aws s3 cp {DATA_DIR}/cloud_folders/data/val s3://{BUCKET_NAME}/data/segmentation_{model_name}_val --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be the paths in your API/TAO-CLIENT Notebooks\n",
    "train_dataset_path = f\"/data/segmentation_{model_name}_train\"\n",
    "eval_dataset_path = f\"/data/segmentation_{model_name}_val\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
