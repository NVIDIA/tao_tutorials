{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### TAO remote client - Object Detection\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "### Sample prediction for an Object Detection model\n",
    "<img align=\"center\" src=\"../example_images/sample_object_detection.jpg\" width=\"960\">\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Creating a dataset\n",
    "- Upload kitti dataset to the service\n",
    "- Running dataset convert\n",
    "- Getting a PTM from NGC\n",
    "- Model Actions\n",
    "    - Train (Normal/AutoML)\n",
    "    - Evaluate\n",
    "    - Prune, retrain\n",
    "    - Export\n",
    "    - Tao-Deploy\n",
    "    - Inference on TAO\n",
    "    - Inference on TRT\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [Install TAO remote client ](#head-1)\n",
    "1. [Set the remote service base URL](#head-2)\n",
    "1. [Access the shared volume](#head-3)\n",
    "1. [Create the datasets](#head-4)\n",
    "1. [List datasets](#head-5)\n",
    "1. [Provide and customize dataset convert specs](#head-6)\n",
    "1. [Run dataset convert](#head-7)\n",
    "1. [Create a model experiment](#head-8)\n",
    "1. [Find pretrained model](#head-9)\n",
    "1. [Customize model metadata](#head-10)\n",
    "1. [View hyperparameters that are enabled for AutoML by default](#head-11)\n",
    "1. [Set AutoML related configurations](#head-12)\n",
    "1. [Provide train specs](#head-13)\n",
    "1. [Run train](#head-14)\n",
    "1. [View checkpoint files](#head-15)\n",
    "1. [Provide evaluate specs](#head-16)\n",
    "1. [Run evaluate](#head-17)\n",
    "1. [Provide prune specs](#head-18)\n",
    "1. [Run prune](#head-19)\n",
    "1. [Provide retrain specs](#head-20)\n",
    "1. [Run retrain](#head-21)\n",
    "1. [Run evaluate on retrain](#head-21-1)\n",
    "1. [Provide export specs](#head-22)\n",
    "1. [Run export](#head-23)\n",
    "1. [Provide trt engine generation specs](#head-26)\n",
    "1. [Run TRT Engine generation using TAO-Deploy](#head-27)\n",
    "1. [Provide TAO inference specs](#head-28)\n",
    "1. [Run TAO inference](#head-29)\n",
    "1. [Provide TRT inference specs](#head-30)\n",
    "1. [Run TRT inference](#head-31)\n",
    "1. [Delete experiment](#head-32)\n",
    "1. [Delete datasets](#head-33)\n",
    "1. [Unmount shared volume](#head-34)\n",
    "1. [Uninstall TAO Remote Client](#head-35)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "namespace = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "1. Assign a workdir in FIXME 2\n",
    "1. Assign the ip_address and port_number in FIXME 3 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "1. Assign the ngc_api_key variable in FIXME 4\n",
    "1. (Optional) Enable AutoML if needed in FIXME 5\n",
    "1. (Optional) Choose between Bayesian and Hyperband automl_algorithm in FIXME 6 (If automl was enabled in FIXME5)\n",
    "1. Choose to download jobs or not in FIXME 7\n",
    "1. Choose between default and custom dataset in FIXME 8\n",
    "1. Assign path of DATA_DIR in FIXME 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Available models (#FIXME 1):\n",
    "# 1. deformable-detr - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/detectnet_v2.html\n",
    "# 2. detectnet-v2 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/detectnet_v2.html\n",
    "# 3. dino - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/dino.html\n",
    "# 4. dssd - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/ssd.html\n",
    "# 5. efficientdet-tf1 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/efficientdet_tf1.html\n",
    "# 6. efficientdet-tf2 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/efficientdet_tf2.html\n",
    "# 7. faster-rcnn - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/fasterrcnn.html\n",
    "# 8. retinanet - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/retinanet.html\n",
    "# 9. ssd - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/ssd.html\n",
    "# 10. yolo-v3 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v3.html\n",
    "# 11. yolo-v4 - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4.html\n",
    "# 12. yolo-v4-tiny - https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/yolo_v4_tiny.html\n",
    "\n",
    "model_name = \"detectnet-v2\" # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Install TAO remote client <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SKIP this step IF you have already installed the TAO-Client wheel.\n",
    "! pip3 install nvidia-tao-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the version of the TAO-Client\n",
    "! tao-client --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Set the remote service base URL and Token <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the node_addr and port number\n",
    "workdir = \"workdir_object_detection\" # FIXME2\n",
    "host_url = \"http://<ip_address>:<port_number>\" # FIXME3 example: https://10.137.149.22:32334\n",
    "# In host machine, node ip_address and port number can be obtained as follows,\n",
    "# ip_address: hostname -i\n",
    "# port_number: kubectl get service ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'\n",
    "\n",
    "ngc_api_key = \"<ngc_api_key>\" # FIXME4 example: (Add NGC API key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automl_enabled = False # FIXME5 set to True if you want to run automl for the model chosen in the previous cell\n",
    "automl_algorithm = \"Bayesian\" # FIXME6 example: Bayesian/HyperBand\n",
    "# FIXME7 Defaulted to False as downloading jobs from service to your machine takes time\n",
    "# Set to True if you want to download jobs where examples have been provided like for train, export, inference.\n",
    "download_jobs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%env BASE_URL={host_url}/{namespace}/api/v1\n",
    "\n",
    "# Exchange NGC_API_KEY for JWT\n",
    "print(subprocess.getoutput(f\"tao-client login --ngc-api-key {ngc_api_key}\"))\n",
    "identity = json.loads(subprocess.getoutput(f\"tao-client login --ngc-api-key {ngc_api_key}\"))\n",
    "\n",
    "%env USER={identity['user_id']}\n",
    "%env TOKEN={identity['token']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating workdir\n",
    "workdir = os.path.abspath(workdir)\n",
    "if not os.path.isdir(workdir):\n",
    "    os.makedirs(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse logs <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_tail(model_name_cli, id, job_id, job_type, workdir):\n",
    "\tstatus = None\n",
    "\twhile True:\n",
    "\t\ttime.sleep(10)\n",
    "\t\tclear_output(wait=True)\n",
    "\t\tlog_file_path = subprocess.getoutput(f\"tao-client {model_name_cli} get-log-file --id {id} --job {job_id} --job_type {job_type} --workdir {workdir}\")\n",
    "\t\tif not os.path.exists(log_file_path):\n",
    "\t\t\tcontinue\n",
    "\t\twith open(log_file_path, 'rb') as log_file:\n",
    "\t\t\tlog_contents = log_file.read()\n",
    "\t\tlog_content_lines = log_contents.decode(\"utf-8\").split(\"\\n\")        \n",
    "\t\tfor line in log_content_lines:\n",
    "\t\t\tprint(line.strip())\n",
    "\t\t\tif line.strip() == \"Error EOF\":\n",
    "\t\t\t\tstatus = \"Error\"\n",
    "\t\t\t\tbreak\n",
    "\t\t\telif line.strip() == \"Done EOF\":\n",
    "\t\t\t\tstatus = \"Done\"\n",
    "\t\t\t\tbreak\n",
    "\t\tif status is not None:\n",
    "\t\t\tbreak\n",
    "\treturn status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split tar files <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "def split_tar_file(input_tar_path, output_dir, max_split_size=1.5*1024*1024*1024):\n",
    "\tos.makedirs(output_dir, exist_ok=True)\n",
    "\t\n",
    "\twith tarfile.open(input_tar_path, 'r') as original_tar:\n",
    "\t\tmembers = original_tar.getmembers()\n",
    "\t\tcurrent_split_size = 0\n",
    "\t\tcurrent_split_number = 0\n",
    "\t\tcurrent_split_name = os.path.join(output_dir, f'smaller_file_{current_split_number}.tar')\n",
    "\t\t\n",
    "\t\twith tarfile.open(current_split_name, 'w') as split_tar:\n",
    "\t\t\tfor member in members:\n",
    "\t\t\t\tif current_split_size + member.size <= max_split_size:\n",
    "\t\t\t\t\tsplit_tar.addfile(member, original_tar.extractfile(member))\n",
    "\t\t\t\t\tcurrent_split_size += member.size\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tsplit_tar.close()\n",
    "\t\t\t\t\tcurrent_split_number += 1\n",
    "\t\t\t\t\tcurrent_split_name = os.path.join(output_dir, f'smaller_file_{current_split_number}.tar')\n",
    "\t\t\t\t\tcurrent_split_size = 0\n",
    "\t\t\t\t\tsplit_tar = tarfile.open(current_split_name, 'w')  # Open a new split tar archive\n",
    "\t\t\t\t\tsplit_tar.addfile(member, original_tar.extractfile(member))\n",
    "\t\t\t\t\tcurrent_split_size += member.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset type, format <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "We will be using the kitti object detection dataset for this example. To find more details, please visit [here](http://www.cvlibs.net/datasets/kitti/eval_object.php?obj_benchmark=2d). One can request the images from [here](http://www.cvlibs.net/download.php?file=data_object_image_2.zip), and the training labels from [here](http://www.cvlibs.net/download.php?file=data_object_label_2.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using custom dataset; it should follow this dataset structure**\n",
    "```\n",
    "$DATA_DIR/train\n",
    "├── images\n",
    "│   ├── image_name_1.jpg\n",
    "│   ├── image_name_2.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_1.txt\n",
    "    ├── image_name_2.txt\n",
    "    ├── ...\n",
    "$DATA_DIR/val\n",
    "├── images\n",
    "│   ├── image_name_5.jpg\n",
    "│   ├── image_name_6.jpg\n",
    "|   ├── ...\n",
    "└── labels\n",
    "    ├── image_name_5.txt\n",
    "    ├── image_name_6.txt\n",
    "    ├── ...\n",
    "```\n",
    "The file name should be same for images and labels folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_format = \"kitti\"\n",
    "if model_name in (\"efficientdet-tf1\", \"efficientdet-tf2\", \"deformable-detr\", \"dino\"):\n",
    "    ds_format = \"coco\"\n",
    "ds_type = \"object_detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_to_be_used = \"default\" #FIXME8 #default/custom; default for the dataset used in this tutorial notebook; custom for a different dataset\n",
    "DATA_DIR = model_name # FIXME9\n",
    "os.environ['DATA_DIR']= DATA_DIR\n",
    "!mkdir -p $DATA_DIR\n",
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset download and pre-processing <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if dataset_to_be_used == \"default\":\n",
    "    !python3 -m pip install --upgrade awscli\n",
    "    !aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_train.tar.gz $DATA_DIR/\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/tao_od_synthetic_train.tar.gz\"))\n",
    "    !aws s3 cp --no-sign-request s3://tao-object-detection-synthetic-dataset/tao_od_synthetic_val.tar.gz $DATA_DIR/\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/tao_od_synthetic_val.tar.gz\"))\n",
    "\n",
    "    print(\"Untarring file\")\n",
    "    os.makedirs(f\"{DATA_DIR}/train\", exist_ok=True)\n",
    "    !tar -xzf {DATA_DIR}/tao_od_synthetic_train.tar.gz -C {DATA_DIR}/train\n",
    "    os.makedirs(f\"{DATA_DIR}/val\", exist_ok=True)\n",
    "    !tar -xzf {DATA_DIR}/tao_od_synthetic_val.tar.gz -C {DATA_DIR}/val\n",
    "\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/labels\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/labels\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ds_format == \"coco\":\n",
    "    !python3 -m pip install ujson opencv-python tqdm\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"train\")):\n",
    "        raise Exception(\"Train dataset not present\")\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, \"val\")):\n",
    "        raise Exception(\"Eval dataset not present\")\n",
    "    \n",
    "    #kitti to coco conversion for efficientdet\n",
    "    if model_name == \"efficientdet-tf2\":\n",
    "        label_map_extension = \"yaml\"\n",
    "    else:\n",
    "        label_map_extension = \"txt\"\n",
    "    num_classes = subprocess.getoutput(f\"python3 ../dataset_prepare/kitti/kitti_to_coco.py {DATA_DIR}/train/labels {DATA_DIR}/train {label_map_extension}\")\n",
    "    subprocess.getoutput(f\"python3 ../dataset_prepare/kitti/kitti_to_coco.py {DATA_DIR}/val/labels {DATA_DIR}/val {label_map_extension}\")\n",
    "\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/annotations.json\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/train/label_map.{label_map_extension}\"))\n",
    "\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/images\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/annotations.json\"))\n",
    "    assert (os.path.exists(f\"{DATA_DIR}/val/label_map.{label_map_extension}\"))\n",
    "\n",
    "    !tar -C {DATA_DIR}/train -czf {DATA_DIR}/tao_od_synthetic_train.tar.gz images annotations.json label_map.{label_map_extension}\n",
    "    !tar -C {DATA_DIR}/val -czf {DATA_DIR}/tao_od_synthetic_val.tar.gz images annotations.json label_map.{label_map_extension}\n",
    "else:\n",
    "    if dataset_to_be_used == \"custom\":\n",
    "        !tar -C $DATA_DIR/train -czf $DATA_DIR/tao_od_synthetic_train.tar.gz images labels\n",
    "        !tar -C $DATA_DIR/val -czf $DATA_DIR/tao_od_synthetic_val.tar.gz images labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset path <a class=\"anchor\" id=\"head-1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_path =  f\"{DATA_DIR}/tao_od_synthetic_train.tar.gz\"\n",
    "eval_dataset_path = f\"{DATA_DIR}/tao_od_synthetic_val.tar.gz\"\n",
    "test_dataset_path = f\"{DATA_DIR}/tao_od_synthetic_val.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and upload train dataset <a class=\"anchor\" id=\"head-1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type object_detection --dataset_format {ds_format}\")\n",
    "print(train_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.path.abspath(train_dataset_path)), model_name, \"train\")\n",
    "split_tar_file(train_dataset_path, output_dir)\n",
    "for idx, tar_dataset_path in enumerate(os.listdir(output_dir)):\n",
    "    print(f\"Uploading {idx+1}/{len(os.listdir(output_dir))} tar split\")\n",
    "    upload_train_dataset_message = subprocess.getoutput(f\"tao-client {model_name} dataset-upload --id {train_dataset_id} --path {os.path.join(output_dir,tar_dataset_path)}\")\n",
    "    print(upload_train_dataset_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and upload val dataset <a class=\"anchor\" id=\"head-1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type object_detection --dataset_format {ds_format}\")\n",
    "print(eval_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.path.abspath(eval_dataset_path)), model_name, \"val\")\n",
    "split_tar_file(eval_dataset_path, output_dir)\n",
    "for idx, tar_dataset_path in enumerate(os.listdir(output_dir)):\n",
    "    print(f\"Uploading {idx+1}/{len(os.listdir(output_dir))} tar split\")\n",
    "    upload_val_dataset_message = subprocess.getoutput(f\"tao-client {model_name} dataset-upload --id {eval_dataset_id} --path {os.path.join(output_dir,tar_dataset_path)}\")\n",
    "    print(upload_val_dataset_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and upload test dataset <a class=\"anchor\" id=\"head-1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset_id = subprocess.getoutput(f\"tao-client {model_name} dataset-create --dataset_type object_detection --dataset_format raw\")\n",
    "print(test_dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.path.dirname(os.path.abspath(test_dataset_path)), model_name, \"test\")\n",
    "split_tar_file(test_dataset_path, output_dir)\n",
    "for idx, tar_dataset_path in enumerate(os.listdir(output_dir)):\n",
    "    print(f\"Uploading {idx+1}/{len(os.listdir(output_dir))} tar split\")\n",
    "    upload_test_dataset_message = subprocess.getoutput(f\"tao-client {model_name} dataset-upload --id {test_dataset_id} --path {os.path.join(output_dir,tar_dataset_path)}\")\n",
    "    print(upload_test_dataset_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "message = subprocess.getoutput(f\"tao-client {model_name} list-artifacts --job_type dataset\")\n",
    "message = ast.literal_eval(message)\n",
    "for rsp in message:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys\n",
    "    assert \"type\" in rsp_keys\n",
    "    assert \"format\" in rsp_keys\n",
    "    assert \"name\" in rsp_keys\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset convert Action <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose dataset convert action\n",
    "convert_action = \"no_convert\"\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    if model_name in (\"dssd\", \"ssd\", \"retinanet\"):\n",
    "        convert_action = \"convert_and_index\"\n",
    "    elif \"efficientdet\" in model_name:\n",
    "        convert_action = \"convert_\" + model_name.replace(\"-\",\"_\")\n",
    "    else:\n",
    "        convert_action = \"convert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default train dataset specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --action {convert_action} --id {train_dataset_id} --job_type dataset\")\n",
    "    specs = json.loads(specs)\n",
    "    print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize train dataset specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # Apply changes\n",
    "    if \"efficientdet\" in model_name:\n",
    "        specs[\"dataset_convert\"][\"num_shards\"] = 256\n",
    "        specs[\"dataset_convert\"][\"tag\"] = \"train\"\n",
    "    else:\n",
    "        specs[\"kitti_config\"][\"image_extension\"] = \".jpg\" #Change to png if your entire dataset is of png format\n",
    "\n",
    "    if convert_action == \"convert_and_index\": # This can be applied for \"convert\" action also for networks like dnv2, yolo's, frcnn etc but not mandatory; for convert_and_index action it is mandatory\n",
    "        #Map your classes to a superclass like mapping pedestrian to person or just the same name\n",
    "        #Mention the classes in the dataset and their mapping\n",
    "        specs[\"target_class_mapping\"] = [{\"key\":\"cone\",\"value\":\"cone\"},\n",
    "                                 {\"key\":\"cart\",\"value\":\"cart\"},\n",
    "                                 {\"key\":\"fire_extinguisher\",\"value\":\"fire_extinguisher\"},\n",
    "                                 {\"key\":\"forklift\",\"value\":\"forklift\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {train_dataset_id} --action {convert_action} --job_type dataset --specs '{json.dumps(specs)}'\")\n",
    "    print(modified_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --id {train_dataset_id}  --action {convert_action} --job_type dataset\")\n",
    "    job_map[\"train_convert_\" + convert_action] = job_id\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    status = my_tail(model_name, train_dataset_id, job_id, \"dataset\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Dataset convert Action <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default eval dataset specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --action {convert_action} --id {eval_dataset_id} --job_type dataset\")\n",
    "    specs = json.loads(specs)\n",
    "    print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize eval dataset specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # Apply changes\n",
    "    if \"efficientdet\" in model_name:\n",
    "        specs[\"dataset_convert\"][\"num_shards\"] = 256\n",
    "        specs[\"dataset_convert\"][\"tag\"] = \"val\"\n",
    "    else:\n",
    "        specs[\"kitti_config\"][\"image_extension\"] = \".jpg\" #Change to png if your entire dataset is of png format\n",
    "\n",
    "    if convert_action == \"convert_and_index\": # This can be applied for \"convert\" action also for networks like dnv2, yolo's, frcnn etc but not mandatory; for convert_and_index action it is mandatory\n",
    "        #Map your classes to a superclass like mapping pedestrian to person or just the same name\n",
    "        #Mention the classes in the dataset and their mapping\n",
    "        specs[\"target_class_mapping\"] = [{\"key\":\"cone\",\"value\":\"cone\"},\n",
    "                                 {\"key\":\"cart\",\"value\":\"cart\"},\n",
    "                                 {\"key\":\"fire_extinguisher\",\"value\":\"fire_extinguisher\"},\n",
    "                                 {\"key\":\"forklift\",\"value\":\"forklift\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {eval_dataset_id} --action {convert_action} --job_type dataset --specs '{json.dumps(specs)}'\")\n",
    "    print(modified_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    train_convert_job_id = job_map[\"train_convert_\" + convert_action]\n",
    "    job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --id {eval_dataset_id}  --action {convert_action} --job_type dataset  --job {train_convert_job_id} --parent_job_type dataset --parent_id {train_dataset_id}\")\n",
    "    job_map[\"eval_convert_\" + convert_action] = job_id\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    status = my_tail(model_name, eval_dataset_id, job_id, \"dataset\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Create model <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_arch = model_name.replace(\"-\",\"_\")\n",
    "model_id = subprocess.getoutput(f\"tao-client {model_name} model-create --network_arch {network_arch} --encryption_key tlt_encode \")\n",
    "print(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docker_env_vars = {} # Update any variables to be included while triggering Docker run-time like MLOPs variables \n",
    "dataset_information = {\"train_datasets\":[train_dataset_id],\n",
    "                       \"eval_dataset\":eval_dataset_id,\n",
    "                       \"inference_dataset\":test_dataset_id,\n",
    "                       \"calibration_dataset\":train_dataset_id,\n",
    "                       \"docker_env_vars\": docker_env_vars}\n",
    "patched_model = subprocess.getoutput(f\"tao-client {model_name} patch-artifact-metadata --id {model_id} --job_type model --update_info '{json.dumps(dataset_information)}' \")\n",
    "print(patched_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List models <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all pretrained models for the chosen network architecture\n",
    "message = subprocess.getoutput(f\"tao-client {model_name} list-artifacts --job_type model\")\n",
    "message = ast.literal_eval(message)\n",
    "for rsp in message:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"network_arch\" in rsp_keys\n",
    "    if rsp[\"network_arch\"] == network_arch:\n",
    "        if \"encryption_key\" not in rsp.keys():\n",
    "            assert \"name\" in rsp_keys and \"version\" in rsp_keys and \"ngc_path\" in rsp_keys and \"additional_id_info\" in rsp_keys\n",
    "            print(f'PTM Name: {rsp[\"name\"]}; PTM version: {rsp[\"version\"]}; NGC PATH: {rsp[\"ngc_path\"]}; Additional info: {rsp[\"additional_id_info\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-7\"></a>\n",
    "\n",
    "Search for PTM on NGC for the Object Detection model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different object detection models versions\n",
    "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
    "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
    "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
    "pretrained_map = {\"detectnet_v2\" : \"detectnet_v2:resnet18\",\n",
    "                  \"deformable_detr\": \"pretrained_deformable_detr_nvimagenet:resnet50\",\n",
    "                  \"dino\": \"pretrained_dino_nvimagenet:resnet50\",\n",
    "                  \"dssd\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"efficientdet_tf1\" : \"pretrained_efficientdet:efficientnet_b0\",\n",
    "                  \"efficientdet_tf2\" : \"pretrained_efficientdet_tf2:efficientnet_b0\",\n",
    "                  \"faster_rcnn\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"retinanet\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"ssd\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v3\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4\" : \"pretrained_object_detection:resnet18\",\n",
    "                  \"yolo_v4_tiny\": \"pretrained_object_detection:cspdarknet_tiny\"}\n",
    "no_ptm_models = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if network_arch not in no_ptm_models:\n",
    "    message = subprocess.getoutput(f\"tao-client {model_name} list-artifacts --job_type model\")\n",
    "    message = ast.literal_eval(message)\n",
    "    ptm = []\n",
    "    for rsp in message:\n",
    "        rsp_keys = rsp.keys()\n",
    "        assert \"network_arch\" in rsp_keys and \"ngc_path\" in rsp_keys\n",
    "        if rsp[\"network_arch\"] == network_arch and rsp[\"ngc_path\"].endswith(pretrained_map[network_arch]):\n",
    "            assert \"id\" in rsp_keys\n",
    "            ptm_id = rsp[\"id\"]\n",
    "            ptm = [ptm_id]\n",
    "            print(\"Metadata for model with requested NGC Path\")\n",
    "            print(rsp)\n",
    "            break\n",
    "    print(ptm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if network_arch not in no_ptm_models:\n",
    "    ptm_information = {\"ptm\":ptm}\n",
    "    patched_model = subprocess.getoutput(f\"tao-client {model_name} patch-artifact-metadata --id {model_id} --job_type model --update_info '{json.dumps(ptm_information)}' \")\n",
    "    print(patched_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # View default automl specs enabled\n",
    "    ! tao-client {model_name} model-automl-defaults --id {model_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Set AutoML related configurations <a class=\"anchor\" id=\"head-12\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters: \n",
    "\n",
    "[DetectNet_V2](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/detectnet_v2/detectnet_v2%20-%20train.csv), \n",
    "[Deformable Detr](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/deformable_detr/deformable_detr%20-%20train.csv), \n",
    "[DINO](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/dino/dino%20-%20train.csv), \n",
    "[DSSD](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/dssd/dsssd%20-%20train.csv), \n",
    "[EfficientDet TF1](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/efficientdet_tf1/efficientdet_tf1%20-%20train.csv), \n",
    "[EfficientDet TF2](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/efficientdet_tf2/efficientdet_tf2%20-%20train.csv), \n",
    "[FasterRCNN](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/faster_rcnn/faster_rcnn%20-%20train.csv), \n",
    "[RetinaNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/retinanet/retinanet%20-%20train.csv), \n",
    "[SSD](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ssd/ssd%20-%20train.csv), \n",
    "[YOLO_V3](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/yolo_v3/yolo_v3%20-%20train.csv), \n",
    "[YOLO_V4](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/yolo_v4/yolo_v4%20-%20train.csv), \n",
    "[YOLO_V4_Tiny](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/yolo_v4_tiny/yolo_v4_tiny%20-%20train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # Choose any metric that is present in the kpi dictionary present in the model's status.json. \n",
    "    # Example status.json for each model can be found in the respective section in NVIDIA TAO DOCS here: https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/cv_models/index.html\n",
    "    metric=\"kpi\"\n",
    "\n",
    "    additional_automl_parameters = [] #Refer to parameter list mentioned in the above links and add any extra parameter in addition to the default enabled ones\n",
    "    remove_default_automl_parameters = [] #Remove any hyperparameters that are enabled by default for AutoML\n",
    "\n",
    "    automl_information = {\"automl_enabled\":automl_enabled,\n",
    "                          \"automl_algorithm\":automl_algorithm,\n",
    "                          \"automl_max_recommendations\": 20, # Only for Bayesian\n",
    "                          \"automl_R\": 27, # Only for Hyperband\n",
    "                          \"automl_nu\": 3, # Only for Hyperband\n",
    "                          \"epoch_multiplier\": 1, # Only for Hyperband\n",
    "                          \"metric\":metric,\n",
    "                          \"automl_add_hyperparameters\":str(additional_automl_parameters),\n",
    "                          \"automl_remove_hyperparameters\":str(remove_default_automl_parameters)\n",
    "                         }\n",
    "    patched_model = subprocess.getoutput(f\"tao-client {model_name} patch-artifact-metadata --id {model_id} --job_type model --update_info '{json.dumps(automl_information)}' \")\n",
    "    patched_model = json.loads(patched_model)\n",
    "    print(json.dumps(patched_model, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Provide train specs <a class=\"anchor\" id=\"head-13\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default train model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --action train --job_type model --id {model_id}\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize train model specs\n",
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "if model_name in (\"deformable-detr\", \"dino\"):\n",
    "    specs[\"train\"][\"num_epochs\"] = 10\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1\n",
    "    specs[\"train\"][\"num_gpus\"] = 1\n",
    "\n",
    "elif model_name == \"efficientdet-tf1\":\n",
    "    specs[\"training_config\"][\"num_epochs\"] = 10\n",
    "    specs[\"training_config\"][\"train_batch_size\"] = 2\n",
    "    specs[\"training_config\"][\"num_examples_per_epoch\"] = 1414  # number of images in your dataset/number of gpu's\n",
    "    specs[\"dataset_config\"][\"num_classes\"] = int(num_classes)  # num_classes was computed during kitti_to_coco_conversion\n",
    "    specs[\"eval_config\"][\"eval_epoch_cycle\"] = 2 # Set to number of epochs or less\n",
    "    specs[\"gpus\"] = 1\n",
    "\n",
    "elif model_name == \"efficientdet-tf2\":\n",
    "    specs[\"train\"][\"num_epochs\"] = 10\n",
    "    specs[\"gpus\"] = 1\n",
    "    specs[\"train\"][\"lr_schedule\"][\"warmup_epoch\"] = 2 # Set to 1 less than number of epochs or further less\n",
    "    specs[\"train\"][\"batch_size\"] = 4\n",
    "    specs[\"train\"][\"num_examples_per_epoch\"] = 1414  # number of images in your dataset/number of gpu's\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes)  # num_classes was computed during kitti_to_coco_conversion\n",
    "    specs[\"train\"][\"checkpoint_interval\"] = 5 # Set to number of epochs or less\n",
    "\n",
    "else:\n",
    "    # Example for detectnet_v2 (for each network the parameter key might be different)\n",
    "    specs[\"training_config\"][\"num_epochs\"] = 10  # num_epochs is the parameter name for all object detection networks\n",
    "    specs[\"gpus\"] = 1\n",
    "\n",
    "if \"dataset_config\" in specs.keys() and \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "    specs[\"dataset_config\"][\"image_extension\"] = \"jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action train --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Run train <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_convert_parent = \"\"\n",
    "if model_name not in (\"deformable-detr\", \"dino\"):\n",
    "    val_convert_job_id = job_map[\"eval_convert_\" + convert_action]\n",
    "    ds_convert_parent = f\"--job {val_convert_job_id} --parent_job_type dataset --parent_id {eval_dataset_id}\"\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action train --job_type model --id {model_id} {ds_convert_parent}\")\n",
    "job_map[\"train_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor job status\n",
    "if automl_enabled:    \n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = subprocess.getoutput(f\"tao-client {model_name} get-action-status --job_type model --id {model_id} --job {job_id}\")\n",
    "        response = json.loads(response)\n",
    "        if \"error_desc\" in response.keys() and response[\"error_desc\"] in (\"Job not found\", \"No AutoML run found\"):\n",
    "            print(\"Job is being created\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "        print(json.dumps(response, sort_keys=True, indent=4))\n",
    "        assert \"status\" in response.keys() and response.get(\"status\") != \"Error\"\n",
    "        if response.get(\"status\") in [\"Done\",\"Error\"]:\n",
    "            break\n",
    "        time.sleep(15)\n",
    "else:\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To Stop an AutoML JOB\n",
    "#    1. Stop the 'Monitor job status' cell (the cell right before this cell) manually\n",
    "#    2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if automl_enabled:\n",
    "#     parent = job_map[\"train_\" + model_name]\n",
    "#     job_id = subprocess.getoutput(f\"tao-client {model_name} job-cancel --job_type model --id {model_id} --job {parent}\")\n",
    "#     job_map[\"canceled_\" + model_name] = job_id\n",
    "#     print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Resume AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status' cell above (4th cell above from this cell)\n",
    "# if automl_enabled:\n",
    "#     parent = job_map[\"train_\" + model_name]\n",
    "#     job_id = subprocess.getoutput(f\"tao-client {model_name} job-resume --job_type model --id {model_id} --job {parent}\")\n",
    "#     job_map[\"resumed_\" + model_name] = job_id\n",
    "#     print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download train job artifacts <a class=\"anchor\" id=\"head-15\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_id = job_map[\"train_\" + model_name]\n",
    "file_list = subprocess.getoutput(f\"tao-client {model_name} list-job-files --id {model_id} --job {job_id} --job_type model --retrieve_logs True --retrieve_specs False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Patch the model with proper metric before training to run this cell; By default loss is used, but some models dont log the parameter under the name 'loss'\n",
    "# file_lists = []\n",
    "# temptar = subprocess.getoutput(f\"tao-client {model_name} download-selective-files --id {model_id} --job {job_id} --job_type model --workdir {workdir}  --file_lists '{file_lists}' --best_model False --latest_model True --tar_files True\")\n",
    "# tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "# os.system(tar_command)\n",
    "# os.remove(temptar)\n",
    "# print(f\"Results at {workdir}/{job_id}\")\n",
    "# model_downloaded_path = f\"{workdir}/{job_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downloading train job takes a longer time, uncomment this cell if you want to still proceed\n",
    "if download_jobs:\n",
    "    temptar = subprocess.getoutput(f\"tao-client {model_name} download-entire-job --id {model_id} --job {job_id} --job_type model --workdir {workdir}\")\n",
    "    tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "    os.system(tar_command)\n",
    "    os.remove(temptar)\n",
    "    print(f\"Results at {workdir}/{job_id}\")\n",
    "    model_downloaded_path = f\"{workdir}/{job_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the checkpoints generated for the training job and for automl jobs, in addition view: best performing model's config and the results of all automl experiments\n",
    "if download_jobs:\n",
    "    if automl_enabled:\n",
    "        !python3 -m pip install pandas==1.5.1\n",
    "        import pandas as pd\n",
    "        model_downloaded_path = f\"{model_downloaded_path}/best_model\"\n",
    "        assert glob.glob(f\"{model_downloaded_path}/*.protobuf\") or glob.glob(f\"{model_downloaded_path}/*.yaml\")\n",
    "\n",
    "    assert os.path.exists(model_downloaded_path)\n",
    "    assert (glob.glob(model_downloaded_path + \"/**/*.tlt\", recursive=True) + glob.glob(model_downloaded_path + \"/**/*.hdf5\", recursive=True) + glob.glob(model_downloaded_path + \"/**/*.pth\", recursive=True))\n",
    "\n",
    "    if os.path.exists(model_downloaded_path):        \n",
    "        #List the binary model file\n",
    "        print(\"\\nCheckpoints for the training experiment\")\n",
    "        if os.path.exists(model_downloaded_path+\"/train/weights\") and len(os.listdir(model_downloaded_path+\"/train/weights\")) > 0:\n",
    "            print(f\"Folder: {model_downloaded_path}/train/weights\")\n",
    "            print(\"Files:\", os.listdir(model_downloaded_path+\"/train/weights\"))\n",
    "        elif os.path.exists(model_downloaded_path+\"/weights\") and len(os.listdir(model_downloaded_path+\"/weights\")) > 0:\n",
    "            print(f\"Folder: {model_downloaded_path}/weights\")\n",
    "            print(\"Files:\", os.listdir(model_downloaded_path+\"/weights\"))\n",
    "        else:\n",
    "            print(f\"Folder: {model_downloaded_path}\")\n",
    "            print(\"Files:\", os.listdir(model_downloaded_path))\n",
    "\n",
    "        if automl_enabled:\n",
    "            assert glob.glob(f\"{model_downloaded_path}/*.protobuf\") or glob.glob(f\"{model_downloaded_path}/*.yaml\")\n",
    "            experiment_artifacts = json.load(open(f\"{model_downloaded_path}/controller.json\",\"r\"))\n",
    "            data_frame = pd.DataFrame(experiment_artifacts)\n",
    "            # Print experiment id/number and the corresponding result\n",
    "            print(\"\\nResults of all experiments\")\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', None, 'display.max_colwidth', None):\n",
    "                print(data_frame[[\"id\",\"result\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide evaluate specs <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default evaluate model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --action evaluate --job_type model --id {model_id}\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize evaluate model specs\n",
    "if model_name in (\"deformable-detr\",\"dino\"):\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1\n",
    "elif model_name == \"efficientdet-tf1\":\n",
    "    specs[\"dataset_config\"][\"num_classes\"] = int(num_classes) #num_classes was computed during kitti_to_coco_conversion\n",
    "elif model_name == \"efficientdet-tf2\":\n",
    "    specs[\"evaluate\"][\"num_samples\"] = 353 #number of images in your dataset\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) #num_classes was computed during kitti_to_coco_conversion\n",
    "\n",
    "if \"dataset_config\" in specs.keys() and \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "    specs[\"dataset_config\"][\"image_extension\"] = \"jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action evaluate --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluate <a class=\"anchor\" id=\"head-17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print model handler parameters\n",
    "model_parameters = subprocess.getoutput(f\"tao-client {model_name} get-metadata --id {model_id} --job_type model\")\n",
    "model_parameters = json.loads(model_parameters)\n",
    "update_checkpoint_choosing = {}\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = model_parameters[\"checkpoint_choose_method\"]\n",
    "update_checkpoint_choosing[\"checkpoint_epoch_number\"] = model_parameters[\"checkpoint_epoch_number\"]\n",
    "print(json.dumps(update_checkpoint_choosing, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the method by which checkpoint from the parent action is chosen, when parent action is a train/retrain action.\n",
    "# Example for evaluate action below, can be applied in the same way for other actions too\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = \"latest_model\" # Choose between best_model/latest_model/from_epoch_number\n",
    "# If from_epoch_number is chosen then assign the epoch number to the dictionary key in the format 'from_epoch_number{train_job_id}'\n",
    "# update_checkpoint_choosing[\"checkpoint_epoch_number\"][\"from_epoch_number_c2f76eb7-2a75-4197-9a84-c1547f20c17d\"] = 6\n",
    "\n",
    "patched_model = subprocess.getoutput(f\"tao-client {model_name} patch-artifact-metadata --id {model_id} --job_type model --update_info '{json.dumps(update_checkpoint_choosing)}' \")\n",
    "patched_model = json.loads(patched_model)\n",
    "print(json.dumps(patched_model, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"train_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action evaluate --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "job_map[\"eval_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune, Retrain and Evaluation chaining <a class=\"anchor\" id=\"head-13\"></a>\n",
    "\n",
    "- We optimize the trained model by pruning and retraining in the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Provide prune specs <a class=\"anchor\" id=\"head-18\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default prune model specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action prune --job_type model\")\n",
    "    specs = json.loads(specs)\n",
    "    print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action prune --job_type model --specs '{json.dumps(specs)}'\")\n",
    "    print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Run prune <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "    job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action prune --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "    job_map[\"prune_\" + model_name] = job_id\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Provide retrain specs <a class=\"anchor\" id=\"head-20\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # Default retrain model specs\n",
    "    specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action retrain --job_type model\")\n",
    "    specs = json.loads(specs)\n",
    "    print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize retrain model specs\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # for efficientdet_tf1\n",
    "    if model_name == \"efficientdet-tf1\":\n",
    "        specs[\"training_config\"][\"num_epochs\"] = 10\n",
    "        specs[\"gpus\"] = 1\n",
    "        specs[\"training_config\"][\"train_batch_size\"] = 2\n",
    "        specs[\"training_config\"][\"num_examples_per_epoch\"] = 1414 #number of images in your dataset/number of gpu's\n",
    "        specs[\"dataset_config\"][\"num_classes\"] = int(num_classes) #num_classes was computed during kitti_to_coco_conversion\n",
    "        specs[\"eval_config\"][\"eval_epoch_cycle\"] = 2\n",
    "\n",
    "    # for efficientdet_tf2\n",
    "    elif model_name == \"efficientdet-tf2\":\n",
    "        specs[\"train\"][\"num_epochs\"] = 10\n",
    "        specs[\"train\"][\"lr_schedule\"][\"warmup_epoch\"] = 2\n",
    "        specs[\"train\"][\"checkpoint_interval\"] = 5\n",
    "        specs[\"gpus\"] = 1\n",
    "        specs[\"train\"][\"batch_size\"] = 4\n",
    "        specs[\"train\"][\"num_examples_per_epoch\"] = 1414 #number of images in your dataset/number of gpu's\n",
    "        specs[\"dataset\"][\"num_classes\"] = int(num_classes) #num_classes was computed during kitti_to_coco_conversion\n",
    "\n",
    "    # Example for (for each network the parameter key might be different)\n",
    "    else:\n",
    "        specs[\"training_config\"][\"num_epochs\"] = 10 # num_epochs is the parameter name for all object detection networks\n",
    "        specs[\"gpus\"] = 1\n",
    "\n",
    "    if \"dataset_config\" in specs.keys() and \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "        specs[\"dataset_config\"][\"image_extension\"] = \"jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action retrain --job_type model --specs '{json.dumps(specs)}'\")\n",
    "    print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "#### Run retrain <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    parent = job_map[\"prune_\" + model_name]\n",
    "    job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action retrain --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "    job_map[\"retrain_\" + model_name] = job_id\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run evaluate on retrained model <a class=\"anchor\" id=\"head-21-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    parent = job_map[\"retrain_\" + model_name]\n",
    "    job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action evaluate --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "    job_map[\"eval2_\" + model_name] = job_id\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in (\"deformable-detr\",\"dino\"):\n",
    "    # Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "    status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide export specs <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default export model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action export --job_type model\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize export model specs\n",
    "if model_name == \"efficientdet-tf2\":\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name in (\"deformable-detr\",\"dino\"):\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action export --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run export <a class=\"anchor\" id=\"head-23\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"train_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action export --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "job_map[\"export_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT Engine generation using TAO-Deploy <a class=\"anchor\" id=\"head-26\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide trt engine generation specs <a class=\"anchor\" id=\"head-26\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default gen_trt_engine model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action gen_trt_engine --job_type model\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize gen_trt_engine model specs\n",
    "if model_name == \"efficientdet-tf2\":\n",
    "    specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"int8\"\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name in (\"deformable-detr\", \"dino\"):\n",
    "    specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"int8\"\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1\n",
    "else:\n",
    "    specs[\"data_type\"] = \"int8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action gen_trt_engine --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TRT Engine generation <a class=\"anchor\" id=\"head-27\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"export_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action gen_trt_engine --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "job_map[\"gen_trt_engine_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAO inference <a class=\"anchor\" id=\"head-28\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide TAO inference specs <a class=\"anchor\" id=\"head-28\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action inference --job_type model\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TAO inference specs\n",
    "# Apply changes to the specs dictionary here if required\n",
    "if model_name == \"efficientdet-tf1\":\n",
    "    specs[\"dataset_config\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name == \"efficientdet-tf2\":\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name in (\"deformable-detr\",\"dino\"):\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1 \n",
    "\n",
    "if \"dataset_config\" in specs.keys() and \"image_extension\" in specs[\"dataset_config\"].keys():\n",
    "    specs[\"dataset_config\"][\"image_extension\"] = \"jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action inference --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TAO inference <a class=\"anchor\" id=\"head-29\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"train_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action inference --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "job_map[\"tlt_inference_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if download_jobs:\n",
    "    temptar = subprocess.getoutput(f\"tao-client {model_name} download-entire-job --id {model_id} --job {job_id} --job_type model --workdir {workdir}\")\n",
    "    tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "    os.system(tar_command)\n",
    "    os.remove(temptar)\n",
    "    print(f\"Results at {workdir}/{job_id}\")\n",
    "    inference_out_path = f\"{workdir}/{job_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if download_jobs:\n",
    "    from IPython.display import Image\n",
    "    import glob\n",
    "    assert glob.glob(f\"{inference_out_path}/**/*.jpg\", recursive=True)\n",
    "    sample_image = glob.glob(f\"{inference_out_path}/**/*.jpg\", recursive=True)[6]\n",
    "    Image(filename=sample_image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT inference <a class=\"anchor\" id=\"head-30\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide TRT inference specs <a class=\"anchor\" id=\"head-30\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Default inference model specs\n",
    "specs = subprocess.getoutput(f\"tao-client {model_name} get-spec --id {model_id} --action inference --job_type model\")\n",
    "specs = json.loads(specs)\n",
    "print(json.dumps(specs, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Customize TAO inference specs\n",
    "if model_name == \"efficientdet-tf1\":\n",
    "    specs[\"dataset_config\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name == \"efficientdet-tf2\":\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes)\n",
    "elif model_name in (\"deformable-detr\",\"dino\"):\n",
    "    specs[\"dataset\"][\"num_classes\"] = int(num_classes) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modified_specs = subprocess.getoutput(f\"tao-client {model_name} post-spec --id {model_id} --action inference --job_type model --specs '{json.dumps(specs)}'\")\n",
    "print(modified_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run TRT inference <a class=\"anchor\" id=\"head-31\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parent = job_map[\"gen_trt_engine_\" + model_name]\n",
    "job_id = subprocess.getoutput(f\"tao-client {model_name} run-action --action inference --job_type model --id {model_id} --job {parent} --parent_job_type model --parent_id {model_id}\")\n",
    "job_map[\"trt_inference_\" + model_name] = job_id\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check status (the file won't exist until the backend Toolkit container is running -- can take several minutes)\n",
    "status = my_tail(model_name, model_id, job_id, \"model\", workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if download_jobs:\n",
    "    temptar = subprocess.getoutput(f\"tao-client {model_name} download-entire-job --id {model_id} --job {job_id} --job_type model --workdir {workdir}\")\n",
    "    tar_command = f'tar -xvf {temptar} -C {workdir}/'\n",
    "    os.system(tar_command)\n",
    "    os.remove(temptar)\n",
    "    print(f\"Results at {workdir}/{job_id}\")\n",
    "    inference_out_path = f\"{workdir}/{job_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if download_jobs:\n",
    "    from IPython.display import Image\n",
    "    import glob\n",
    "    assert glob.glob(f\"{inference_out_path}/**/*.jpg\", recursive=True)\n",
    "    sample_image = glob.glob(f\"{inference_out_path}/**/*.jpg\", recursive=True)[6]\n",
    "    Image(filename=sample_image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete model <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao-client {model_name} model-delete --id {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete train dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao-client {model_name} dataset-delete --id {train_dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete val dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao-client {model_name} dataset-delete --id {eval_dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete test dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.getoutput(f\"tao-client {model_name} dataset-delete --id {test_dataset_id}\")"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
