{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to demonstrate TAO workflow on purpose built models\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Pulling datasets from cloud\n",
    "- Running dataset convert (for specific models)\n",
    "- Getting a PTM from NGC\n",
    "- Model Actions\n",
    "    - Train (Normal/AutoML)\n",
    "    - Evaluate\n",
    "    - Prune, retrain (for specific models)\n",
    "    - Export\n",
    "    - TAO-Deploy (for specific models)\n",
    "    - Inference on TAO, TRT\n",
    "    - Delete experiments/dataset\n",
    "    \n",
    "### Table of contents\n",
    "\n",
    "1. [FIXME's](#head-1)\n",
    "1. [Login](#head-2)\n",
    "1. [Create a cloud workspace](#head-2)\n",
    "1. [Set dataset formats](#head-3)\n",
    "1. [Create and pull train dataset](#head-4)\n",
    "1. [Create and pull val dataset](#head-5)\n",
    "1. [Create and pull test dataset](#head-6)\n",
    "1. [List the created datasets](#head-7)\n",
    "1. [Train Dataset convert action](#head-8) (for specific models)\n",
    "1. [Val dataset convert action](#head-9) (for specific models)\n",
    "1. [Create an experiment](#head-10)\n",
    "1. [List experiments](#head-11)\n",
    "1. [Assign train, eval datasets](#head-12)\n",
    "1. [Assign PTM](#head-13)\n",
    "1. [Set AutoML related configurations](#head-14)\n",
    "1. [Actions](#head-15)\n",
    "1. [Train](#head-16)\n",
    "1. [View hyperparameters that are enabled by default](#head-16.1)\n",
    "1. [Evaluate](#head-17)\n",
    "1. [Optimize: Prune, retrain and evaluate](#head-18) (for specific models)\n",
    "1. [Export](#head-19)\n",
    "1. [TRT Engine generation using TAO-Deploy](#head-20) (for specific models)\n",
    "1. [TAO inference](#head-21)\n",
    "1. [TRT inference](#head-22) (for specific models)\n",
    "1. [Delete experiment](#head-23)\n",
    "1. [Delete dataset](#head-24)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import glob\n",
    "from remove_corrupted_images import remove_corrupted_images_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To see the dataset folder structure required for the models supported in this notebook, visit the notebooks under dataset_prepare like for [this notebook](../dataset_prepare/purpose_built_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME's <a class=\"anchor\" id=\"head-1\"></a>\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "\n",
    "    1.1 Assign model type for action_recognition/pose_classification in FIXME 1.1\n",
    "    \n",
    "    1.2 Assign model input type for action_recognition in FIXME 1.2\n",
    "1. (Optional) Enable AutoML if needed in FIXME 2\n",
    "1. (Optional) Choose between bayesian and hyperband automl_algorithm in FIXME 3 (If automl was enabled in FIXME2)\n",
    "1. Assign the ip_address and port_number in FIXME 4 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
    "1. Assign the ngc_key variable in FIXME 5\n",
    "1. Assign the ngc_org_name variable in FIXME 6\n",
    "1. Set cloud storage details in FIXME 7\n",
    "1. Assign path of datasets relative to the bucket in FIXME 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a purpose built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. action_recognition - https://docs.nvidia.com/tao/tao-toolkit/text/action_recognition_net.html\n",
    "# 2. bevfusion - https://docs.nvidia.com/tao/tao-toolkit/text/bevfusion/index.html\n",
    "# 2. ml_recog - https://docs.nvidia.com/tao/tao-toolkit/text/ml_recog/index.html\n",
    "# 3. ocdnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocdnet/index.html\n",
    "# 4. ocrnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocrnet/index.html\n",
    "# 5. optical_inspection - https://docs.nvidia.com/tao/tao-toolkit/text/optical_inspection/index.html\n",
    "# 6. pose_classification - https://docs.nvidia.com/tao/tao-toolkit/text/pose_classification/index.html\n",
    "# 7. pointpillars - https://docs.nvidia.com/tao/tao-toolkit/text/point_cloud/pointpillars.html\n",
    "# 8. re_identification - https://docs.nvidia.com/tao/tao-toolkit/text/re_identification/index.html\n",
    "# 9. centerpose - https://docs.nvidia.com/tao/tao-toolkit/text/centerpose/index.html\n",
    "# 10. visual_changenet_classify - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
    "# 11. visual_changenet_segment - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
    "\n",
    "model_name = \"action_recognition\" # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in (\"action_recognition\",\"pose_classification\"):\n",
    "    # FIXME1.1 - model_type - string\n",
    "        # action-recognition: rgb/of/joint;\n",
    "        # pose-classification: kinetics/nvidia\n",
    "    model_type = \"rgb\"\n",
    "\n",
    "    if model_name == \"action_recognition\":\n",
    "        if model_type not in (\"rgb\",\"of\",\"joint\"):\n",
    "            raise Exception(\"Choose one of rgb/of/joint for action recognition model_type\")\n",
    "    elif model_name == \"pose_classification\":\n",
    "        if model_type not in (\"kinetics\",\"nvidia\"):\n",
    "            raise Exception(\"Choose one of kinetics/nvidia for pose classification model_type\")\n",
    "\n",
    "    if model_name == \"action_recognition\":\n",
    "        model_input_type = \"3d\" # FIXME1.2 3d/2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toggle AutoML params\n",
    "[AutoML documentation](https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#getting-started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_enabled = False # FIXME2 set to True if you want to run automl for the model chosen in the previous cell\n",
    "automl_algorithm = \"bayesian\" # FIXME3 example: bayesian/hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set API service's host information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_url = \"http://<ip_address>:<port_number>\" # FIXME4 example: https://10.137.149.22:32334\n",
    "# In host machine, node ip_address and port number can be obtained as follows,\n",
    "# ip_address: hostname -i\n",
    "# port_number: kubectl get service tao-api-ingress-nginx-controller -o jsonpath='{.spec.ports[0].nodePort}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set NGC Personal key for authentication and NGC org to access API services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_key = \"<ngc_key>\" # FIXME5 example: (Add NGC Personal key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_org_name = \"ea-tlt\" # FIXME6 your NGC ORG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate NGC_PERSONAL_KEY\n",
    "data = json.dumps({\"ngc_org_name\": ngc_org_name,\n",
    "                   \"ngc_key\": ngc_key,\n",
    "                   \"enable_telemetry\": True})\n",
    "response = requests.post(f\"{host_url}/api/v1/login\", data=data)\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"token\" in response.json().keys()\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)\n",
    "\n",
    "# Set base URL\n",
    "base_url = f\"{host_url}/api/v1/orgs/{ngc_org_name}\"\n",
    "print(\"API Calls will be forwarded to\",base_url)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    " One of the keys of the response json are to be used as platform_id when you run each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
    "# endpoint = f\"{base_url}:gpu_types\"\n",
    "# response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "# assert response.ok\n",
    "# print(response)\n",
    "# print((json.dumps(response.json(), indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloud workspace\n",
    "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
    "\n",
    "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME7 Dataset Cloud bucket details to download dataset for experiments (Can be read only)\n",
    "cloud_metadata = {}\n",
    "cloud_metadata[\"name\"] = \"AWS workspace info\"  # A Representative name for this cloud info\n",
    "cloud_metadata[\"cloud_type\"] = \"aws\"  # If it's AWS, HuggingFace or Azure\n",
    "cloud_metadata[\"cloud_specific_details\"] = {}\n",
    "cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] = \"us-west-1\"  # Bucket region\n",
    "cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = \"\"  # Bucket name\n",
    "# Access and Secret for AWS\n",
    "cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = \"\"\n",
    "cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cloud workspace\n",
    "data = json.dumps(cloud_metadata)\n",
    "\n",
    "endpoint = f\"{base_url}/workspaces\"\n",
    "\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert \"id\" in response.json().keys()\n",
    "workspace_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset path (path within cloud bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME8 : Set paths relative to cloud bucket\n",
    "train_dataset_path = f\"/data/purpose_built_models_{model_name}_train\"\n",
    "eval_dataset_path = f\"/data/purpose_built_models_{model_name}_val\"  # ocdnet, ocrnet, optical_inspection, visual_changenet_classify\n",
    "test_dataset_path = f\"/data/purpose_built_models_{model_name}_test\"  # optical_inspection, visual_changenet_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset formats <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in (\"visual_changenet_classify\", \"visual_changenet_segment\"):\n",
    "    ds_format = model_name\n",
    "    ds_type = model_name = \"visual_changenet\"\n",
    "else:\n",
    "    ds_type = model_name\n",
    "    ds_format = \"default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull train dataset <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "train_dataset_metadata = {\"type\":ds_type,\n",
    "                          \"format\":ds_format,\n",
    "                          \"workspace\":workspace_id,\n",
    "                          \"cloud_file_path\": train_dataset_path,\n",
    "                          \"use_for\": [\"training\"]\n",
    "                          }\n",
    "\n",
    "data = json.dumps(train_dataset_metadata)\n",
    "endpoint = f\"{base_url}/datasets\"\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "assert \"id\" in response.json().keys()\n",
    "train_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     train_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, train_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull val dataset <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create eval dataset\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\") or ds_format in (\"visual_changenet_classify\"):\n",
    "    eval_dataset_metadata = {\"type\":ds_type,\n",
    "                             \"format\":ds_format,\n",
    "                             \"workspace\":workspace_id,\n",
    "                             \"cloud_file_path\": eval_dataset_path,\n",
    "                             \"use_for\": [\"evaluation\"]\n",
    "                            }\n",
    "\n",
    "    data = json.dumps(eval_dataset_metadata)\n",
    "    endpoint = f\"{base_url}/datasets\"\n",
    "    response = requests.post(endpoint,data=data,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert \"id\" in response.json().keys()\n",
    "    eval_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\") or ds_format in (\"visual_changenet_classify\"):\n",
    "    endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        if response.json().get(\"status\") == \"invalid_pull\":\n",
    "            raise ValueError(\"Dataset pull failed\")\n",
    "        if response.json().get(\"status\") == \"pull_complete\":\n",
    "            break\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\") or ds_format in (\"visual_changenet_classify\"):\n",
    "#     try:\n",
    "#         from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#         eval_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, eval_dataset_id)\n",
    "#     except Exception as e:\n",
    "#         raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull test dataset <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create testing dataset for inference\n",
    "if model_name == \"optical_inspection\" or ds_format in (\"visual_changenet_classify\"):\n",
    "    if ds_format == \"visual_changenet_classify\": \n",
    "        ds_type = \"visual_changenet\"\n",
    "        ds_format = \"visual_changenet_classify\"\n",
    "    else:\n",
    "        ds_type = model_name\n",
    "        ds_format = \"default\"\n",
    "\n",
    "    test_dataset_metadata = {\"type\":ds_type,\n",
    "                             \"format\":ds_format,\n",
    "                             \"workspace\":workspace_id,\n",
    "                             \"cloud_file_path\": test_dataset_path,\n",
    "                             \"use_for\": [\"testing\"]\n",
    "                             }\n",
    "    data = json.dumps(test_dataset_metadata)\n",
    "\n",
    "    endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "    response = requests.post(endpoint,data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert \"id\" in response.json().keys()\n",
    "    test_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "if model_name == \"optical_inspection\" or ds_format in (\"visual_changenet_classify\"):\n",
    "    endpoint = f\"{base_url}/datasets/{test_dataset_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        if response.json().get(\"status\") == \"invalid_pull\":\n",
    "            raise ValueError(\"Dataset pull failed\")\n",
    "        if response.json().get(\"status\") == \"pull_complete\":\n",
    "            break\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# if model_name == \"optical_inspection\" or ds_format in (\"visual_changenet_classify\"):\n",
    "#     try:\n",
    "#         from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#         test_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, test_dataset_id)\n",
    "#     except Exception as e:\n",
    "#         raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets\"\n",
    "\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
    "for rsp in response.json()[\"datasets\"]:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys\n",
    "    assert \"type\" in rsp_keys\n",
    "    assert \"format\" in rsp_keys\n",
    "    assert \"name\" in rsp_keys\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dataset convert Action <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convert_action = \"dataset_convert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name in (\"bevfusion\", \"ocrnet\", \"pointpillars\"):\n",
    "    # Get default spec schema\n",
    "    endpoint = f\"{base_url}/datasets/{train_dataset_id}/specs/{convert_action}/schema\"\n",
    "\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    # print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "\n",
    "    assert \"default\" in response.json().keys()\n",
    "    train_ds_convert_specs = response.json()[\"default\"]\n",
    "\n",
    "    print(json.dumps(train_ds_convert_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes to specs dictionary if necessary\n",
    "if model_name in (\"bevfusion\", \"ocrnet\", \"pointpillars\"):\n",
    "    print(json.dumps(train_ds_convert_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name in (\"bevfusion\", \"ocrnet\", \"pointpillars\"):\n",
    "    parent = None\n",
    "    action = convert_action\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action, \"specs\":train_ds_convert_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/datasets/{train_dataset_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    train_ds_convert_id = response.json()\n",
    "    job_map[\"train_dataset_convert_\"+model_name] = train_ds_convert_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name in (\"bevfusion\", \"ocrnet\", \"pointpillars\"):\n",
    "    job_id = train_ds_convert_id\n",
    "    endpoint = f\"{base_url}/datasets/{train_dataset_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True) \n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Dataset convert Action <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name == \"ocrnet\":\n",
    "    # Get default spec schema\n",
    "    endpoint = f\"{base_url}/datasets/{eval_dataset_id}/specs/{convert_action}/schema\"\n",
    "\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    # print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "\n",
    "    assert \"default\" in response.json().keys()\n",
    "    eval_ds_convert_specs = response.json()[\"default\"]\n",
    "\n",
    "    print(json.dumps(eval_ds_convert_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes to specs dictionary if necessary\n",
    "if model_name == \"ocrnet\":\n",
    "    print(json.dumps(eval_ds_convert_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name == \"ocrnet\":\n",
    "    parent = job_map[\"train_dataset_convert_\"+model_name]\n",
    "    action = convert_action\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":eval_ds_convert_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/datasets/{eval_dataset_id}/jobs\"\n",
    "    \n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    eval_ds_convert_id = response.json()\n",
    "    job_map[\"eval_dataset_convert_\"+model_name] = eval_ds_convert_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name == \"ocrnet\":\n",
    "    job_id = eval_ds_convert_id\n",
    "    endpoint = f\"{base_url}/datasets/{eval_dataset_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True) \n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name in (\"action_recognition\", \"centerpose\", \"pose_classification\", \"ml_recog\", \"ocrnet\", \"ocdnet\", \"optical_inspection\", \"re_identification\", \"visual_changenet\"):\n",
    "    encode_key = \"nvidia_tao\"\n",
    "elif model_name == \"pointpillars\":\n",
    "    encode_key = \"tlt_encode\"\n",
    "else:\n",
    "    encode_key = \"nvidia_tlt\"\n",
    "\n",
    "checkpoint_choose_method = \"best_model\"\n",
    "data = json.dumps({\"network_arch\":model_name,\n",
    "                   \"encryption_key\":encode_key,\n",
    "                   \"checkpoint_choose_method\":checkpoint_choose_method,\n",
    "                   \"workspace\": workspace_id})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "response = requests.post(endpoint,data=data,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "assert \"id\" in response.json().keys()\n",
    "experiment_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List experiments <a class=\"anchor\" id=\"head-11\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments\"\n",
    "params = {\"network_arch\": model_name}\n",
    "response = requests.get(endpoint, params=params, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"model id\\t\\t\\t     network architecture\")\n",
    "for rsp in response.json()[\"experiments\"]:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys and \"network_arch\" in rsp_keys\n",
    "    print(rsp[\"name\"], rsp[\"id\"], rsp[\"network_arch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets <a class=\"anchor\" id=\"head-12\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docker_env_vars = {} # Update any variables to be included while triggering Docker run-time like MLOPs variables \n",
    "dataset_information = {}\n",
    "dataset_information[\"train_datasets\"] = [train_dataset_id]\n",
    "if model_name in (\"ml_recog\",\"ocdnet\",\"ocrnet\"):\n",
    "    dataset_information[\"calibration_dataset\"] = train_dataset_id\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\"):\n",
    "    dataset_information[\"eval_dataset\"] = eval_dataset_id\n",
    "if model_name == \"optical_inspection\":\n",
    "    dataset_information[\"inference_dataset\"] = test_dataset_id\n",
    "if model_name in (\"centerpose\"):\n",
    "    dataset_information[\"eval_dataset\"] = train_dataset_id\n",
    "    dataset_information[\"inference_dataset\"] = train_dataset_id\n",
    "if model_name in (\"visual_changenet\") and ds_format in (\"visual_changenet_classify\"):\n",
    "    dataset_information[\"eval_dataset\"] = eval_dataset_id\n",
    "    dataset_information[\"inference_dataset\"] = test_dataset_id\n",
    "\n",
    "dataset_information[\"docker_env_vars\"] = docker_env_vars\n",
    "\n",
    "data = json.dumps(dataset_information)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-13\"></a>\n",
    "\n",
    "Search for PTM on NGC for the Purpose built model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all pretrained models for the chosen network architecture\n",
    "endpoint = f\"{base_url}/experiments:base\"\n",
    "params = {\"network_arch\": model_name}\n",
    "response = requests.get(endpoint, params=params, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "response_json = response.json()[\"experiments\"]\n",
    "\n",
    "# Search for ptm with given ngc path\n",
    "for rsp in response_json:\n",
    "    rsp_keys = rsp.keys()\n",
    "    if \"encryption_key\" not in rsp.keys():\n",
    "        assert \"name\" in rsp_keys and \"version\" in rsp_keys and \"ngc_path\" in rsp_keys\n",
    "        print(f'PTM Name: {rsp[\"name\"]}; PTM version: {rsp[\"version\"]}; NGC PATH: {rsp[\"ngc_path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different purpose built models versions\n",
    "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
    "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
    "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
    "visual_changenet_ptm = \"visual_changenet_segmentation_levircd:visual_changenet_levircd_trainable_v1.0\" # For segmentation\n",
    "if model_name == 'visual_changenet' and ds_format == 'visual_changenet_classify':\n",
    "    visual_changenet_ptm = \"visual_changenet_classification:visual_changenet_nvpcb_trainable_v1.0\"\n",
    "pretrained_map = {\"action_recognition\":\"actionrecognitionnet:trainable_rgb_3d\",\n",
    "                  \"bevfusion\": \"bevfusion:bevfusion_1.0\",\n",
    "                  \"ml_recog\": \"retail_object_recognition:trainable_v1.0\",\n",
    "                  \"ocdnet\": \"ocdnet:trainable_resnet18_v1.0\",\n",
    "                  \"ocrnet\": \"ocrnet:trainable_v1.0\",\n",
    "                  \"optical_inspection\": \"optical_inspection:trainable_v1.0\",\n",
    "                  \"pointpillars\":\"pointpillarnet:trainable_v1.0\",\n",
    "                  \"pose_classification\":\"poseclassificationnet:trainable_v1.0\",\n",
    "                  \"re_identification\":\"reidentificationnet:trainable_v1.1\",\n",
    "                  \"visual_changenet\":visual_changenet_ptm,\n",
    "                  \"centerpose\": \"pretrained_fan_classification_nvimagenet:fan_small_hybrid_nvimagenet\"}\n",
    "if model_name == \"action_recognition\":\n",
    "    if model_type == \"of\":\n",
    "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v2.0\"\n",
    "    elif model_type == \"joint\":\n",
    "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v1.0,actionrecognitionnet:trainable_v2.0\"\n",
    "        \n",
    "no_ptm_models = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in no_ptm_models:\n",
    "    # Get pretrained model\n",
    "    endpoint = f\"{base_url}/experiments:base\"\n",
    "    params = {\"network_arch\": model_name}\n",
    "    response = requests.get(endpoint, params=params, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    response_json = response.json()[\"experiments\"]\n",
    "    ptm_model_names = pretrained_map[model_name].split(\",\")\n",
    "    ptm = []\n",
    "\n",
    "    # Search for ptm with given ngc path\n",
    "    for ptm_model_name in ptm_model_names:\n",
    "        ptm_id = None\n",
    "        for rsp in response_json:\n",
    "            rsp_keys = rsp.keys()\n",
    "            assert \"ngc_path\" in rsp_keys\n",
    "            if rsp[\"ngc_path\"].endswith(ptm_model_name):\n",
    "                assert \"id\" in rsp_keys\n",
    "                ptm_id = rsp[\"id\"]\n",
    "                print(\"Metadata for model with requested NGC Path\")\n",
    "                print(rsp)\n",
    "                break\n",
    "        ptm.append(ptm_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name not in no_ptm_models:\n",
    "    ptm_information = {\"base_experiment\":ptm}\n",
    "    data = json.dumps(ptm_information)\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "    response = requests.patch(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions <a class=\"anchor\" id=\"head-15\"></a>\n",
    "\n",
    "For all actions:\n",
    "1. Get default spec schema and derive the default values\n",
    "2. Modify defaults if needed\n",
    "3. Post spec dictionary to the service\n",
    "4. Run model action\n",
    "5. Monitor job using retrieve\n",
    "6. Download results using job download endpoint (if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train <a class=\"anchor\" id=\"head-16\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # Get default spec schema\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"automl_default_parameters\" in response.json().keys()\n",
    "    automl_params = response.json()[\"automl_default_parameters\"]\n",
    "    print(json.dumps(automl_params, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set AutoML related configurations <a class=\"anchor\" id=\"head-16.1\"></a>\n",
    "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters:\n",
    "\n",
    "[ActionRecognitionNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/action_recognition/action_recognition%20-%20train.csv), \n",
    "[MetricLearningRecognition](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ml_recog/ml_recog%20-%20train.csv), \n",
    "[OCDNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocdnet/ocdnet%20-%20train.csv), \n",
    "[OCRNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocrnet/ocrnet%20-%20train.csv), \n",
    "[OpticalInspection](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/optical_inspection/optical_inspection%20-%20train.csv), \n",
    "[Pointpillars](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pointpillars/pointpillars%20-%20train.csv), \n",
    "[PoseClassificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pose_classification/pose_classification%20-%20train.csv), \n",
    "[ReIdentificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/re_identification/re_identification%20-%20train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if automl_enabled:\n",
    "    # Choose any metric that is present in the kpi dictionary present in the model's status.json. \n",
    "    # Example status.json for each model can be found in the respective section in NVIDIA TAO DOCS here: https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/cv_models/index.html\n",
    "    metric = \"kpi\"\n",
    "\n",
    "    #Refer to parameter list mentioned in the above links and add/remove any extra parameter in addition to the default enabled ones in automl_specs\n",
    "\n",
    "    automl_information = {\"automl_enabled\": True,\n",
    "                          \"automl_algorithm\": automl_algorithm,\n",
    "                          \"automl_max_recommendations\": 20, # Only for bayesian\n",
    "                          \"automl_R\": 27, # Only for hyperband\n",
    "                          \"automl_nu\": 3, # Only for hyperband\n",
    "                          \"epoch_multiplier\": 1, # Only for hyperband\n",
    "                          # Warning: The parameters that are disabled are not tested by TAO, so there might be unexpected behaviour in overriding this\n",
    "                          \"override_automl_disabled_params\": False,\n",
    "                          \"automl_hyperparameters\": str(automl_params)}\n",
    "    data = json.dumps({\"metric\":metric, \"automl_settings\": automl_information})\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "    response = requests.patch(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    \n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/train/schema\"\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"default\" in response.json().keys()\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "train_specs = response.json()[\"default\"]\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "train_specs[\"train\"][\"num_epochs\"] = 30\n",
    "train_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
    "train_specs[\"train\"][\"validation_interval\"] = 10\n",
    "train_specs[\"train\"][\"num_gpus\"] = 1\n",
    "if model_name == \"action_recognition\":\n",
    "    train_specs[\"model\"][\"model_type\"] = model_type\n",
    "    train_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 2\n",
    "    train_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"centerpose\":\n",
    "    train_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "elif model_name == \"ocdnet\":\n",
    "    train_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
    "elif model_name == \"ocrnet\":\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 16\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        train_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        train_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        train_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        train_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        train_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        train_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    train_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "    train_specs[\"dataset\"][\"num_workers\"] = 4 #Modify the num_workers according to your hardware setup\n",
    "    train_specs[\"dataset\"][\"batch_size\"] = 16 #Modify the batch_size according to your hardware setup\n",
    "elif model_name == \"visual_changenet\":\n",
    "    if ds_format == \"visual_changenet_segment\":\n",
    "        train_specs[\"task\"] = 'segment'\n",
    "    elif ds_format == \"visual_changenet_classify\":\n",
    "        train_specs[\"task\"] = 'classify'\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = job_map.get(\"eval_dataset_convert_\"+model_name, job_map.get(\"train_dataset_convert_\"+model_name, None))\n",
    "parent_id = train_dataset_id\n",
    "if model_name == \"ocrnet\": # Only model with eval dataset convert on eval dataset\n",
    "    parent_id = eval_dataset_id\n",
    "action = \"train\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":train_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_map[\"train_\" + ds_format] = response.json()\n",
    "else:\n",
    "    job_map[\"train_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "# For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
    "\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_id = job_map[\"train_\" + ds_format]\n",
    "else:\n",
    "    job_id = job_map[\"train_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if \"error_desc\" in response.json().keys() and response.json()[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "        print(\"Job is being created\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## To Stop an AutoML JOB\n",
    "#    1. Stop the 'Monitor job status by repeatedly running this cell' cell (the cell right before this cell) manually\n",
    "#    2. Uncomment the snippet in the next cell and run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if automl_enabled:\n",
    "#     if model_name == \"visual_changenet\":\n",
    "#          job_id = job_map[\"train_\" + ds_format]\n",
    "#     else:\n",
    "#         job_id = job_map[\"train_\" + model_name]\n",
    "\n",
    "#     endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:pause\"\n",
    "\n",
    "#     response = requests.post(endpoint, headers=headers)\n",
    "#     assert response.status_code in (200, 201)\n",
    "\n",
    "#     print(response)\n",
    "#     print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Resume AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status by repeatedly running this cell' cell above (4th cell above from this cell)\n",
    "# if automl_enabled:\n",
    "#     if model_name == \"visual_changenet\":\n",
    "#          job_id = job_map[\"train_\" + ds_format]\n",
    "#     else:\n",
    "#         job_id = job_map[\"train_\" + model_name]\n",
    "#     endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:resume\"\n",
    "\n",
    "#     data = json.dumps({\"parent_job_id\":parent,\"specs\":train_specs,\n",
    "#                    \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "#                    })\n",
    "#     response = requests.post(endpoint, data=data, headers=headers)\n",
    "#     assert response.status_code in (200, 201)\n",
    "\n",
    "#     print(response)\n",
    "#     print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit the method of choosing checkpoint from list of train checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model handler parameters\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "model_parameters = response.json()\n",
    "update_checkpoint_choosing = {}\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = model_parameters[\"checkpoint_choose_method\"]\n",
    "update_checkpoint_choosing[\"checkpoint_epoch_number\"] = model_parameters[\"checkpoint_epoch_number\"]\n",
    "print(update_checkpoint_choosing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the method by which checkpoint from the parent action is chosen, when parent action is a train/retrain action.\n",
    "# Example for evaluate action below, can be applied in the same way for other actions too\n",
    "update_checkpoint_choosing[\"checkpoint_choose_method\"] = \"latest_model\" # Choose between best_model/latest_model/from_epoch_number\n",
    "# If from_epoch_number is chosen then assign the epoch number to the dictionary key in the format 'from_epoch_number{train_job_id}'\n",
    "# update_checkpoint_choosing[\"checkpoint_epoch_number\"][\"from_epoch_number_28a2754e-50ef-43a8-9733-98913776dd90\"] = 3\n",
    "data = json.dumps(update_checkpoint_choosing)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.patch(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push model to private ngc team registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"visual_changenet\":\n",
    "    job_id = job_map[\"train_\" + ds_format]\n",
    "else:\n",
    "    job_id = job_map[\"train_\" + model_name]\n",
    "data = json.dumps({\"display_name\": f\"TAO {model_name}\",\n",
    "                   \"description\": f\"Train {model_name}\",\n",
    "                   \"team_name\":\"tao_ea\"})\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:publish_model\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove model from private ngc team registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:remove_published_model\"\n",
    "# params = {\"team_name\": \"tao_ea\"}\n",
    "# response = requests.delete(endpoint, params=params, headers=headers)\n",
    "# assert response.status_code in (200, 201)\n",
    "# assert response.json()\n",
    "\n",
    "# print(response)\n",
    "# print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate <a class=\"anchor\" id=\"head-17\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/evaluate/schema\"\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "#print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "assert \"default\" in response.json().keys()\n",
    "eval_specs = response.json()[\"default\"]\n",
    "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "if model_name == \"action_recognition\":\n",
    "    eval_specs[\"model\"][\"model_type\"] = model_type\n",
    "    eval_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    eval_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        eval_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        eval_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        eval_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        eval_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        eval_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        eval_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    eval_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_segment':\n",
    "    eval_specs[\"task\"] = 'segment'\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_classify':\n",
    "    eval_specs[\"task\"] = 'classify'\n",
    "    eval_specs[\"train\"][\"classify\"][\"loss\"] = \"contrastive\"\n",
    "elif model_name == \"centerpose\":\n",
    "    eval_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name == \"visual_changenet\":\n",
    "    parent = job_map[\"train_\" + ds_format]\n",
    "else:\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "action = \"evaluate\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":eval_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_map[\"evaluate_\" + ds_format] = response.json()\n",
    "else:\n",
    "    job_map[\"evaluate_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_id = job_map[\"evaluate_\" + ds_format]\n",
    "else:\n",
    "    job_id = job_map[\"evaluate_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune, Retrain and Evaluation <a class=\"anchor\" id=\"head-18\"></a>\n",
    "\n",
    "- We optimize the trained model by pruning and retraining in the following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/prune/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    #print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    prune_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(prune_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "# None for prune\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    print(json.dumps(prune_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run actions\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "    action = \"prune\"\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":prune_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    job_map[\"prune_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell (prune)\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    job_id = job_map[\"prune_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/retrain/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    #print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    retrain_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(retrain_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes for any of the parameters listed in the previous cell as required\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    retrain_specs[\"train\"][\"num_epochs\"] = 30\n",
    "    retrain_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
    "    retrain_specs[\"train\"][\"validation_interval\"] = 10\n",
    "    retrain_specs[\"train\"][\"num_gpus\"] = 1\n",
    "    if model_name == \"ocdnet\":\n",
    "        retrain_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
    "    elif model_name == \"ocrnet\":\n",
    "        retrain_specs[\"dataset\"][\"batch_size\"] = 16\n",
    "    print(json.dumps(retrain_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run actions\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    parent = job_map[\"prune_\" + model_name]\n",
    "    action = \"retrain\"\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":retrain_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    job_map[\"retrain_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell (retrain)\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    job_id = job_map[\"retrain_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cancel job - for jobs that are pending/running (retrain)\n",
    "\n",
    "# if model_name == \"pointpillars\":\n",
    "#     job_id = job_map[\"retrain_\" + model_name]\n",
    "#     endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:pause\"\n",
    "\n",
    "#     response = requests.post(endpoint, headers=headers)\n",
    "#     assert response.status_code in (200, 201)\n",
    "\n",
    "#     print(response)\n",
    "#     print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional delete job - for jobs that are error/done (retrain)\n",
    "\n",
    "# if model_name == \"pointpillars\":\n",
    "#     job_id = job_map[\"retrain_\" + model_name]\n",
    "#     endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "#     response = requests.delete(endpoint, headers=headers)\n",
    "#     assert response.status_code in (200, 201)\n",
    "\n",
    "#     print(response)\n",
    "#     print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate after retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/evaluate/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    #print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    eval_retrain_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(eval_retrain_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply changes to specs if necessary\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    print(json.dumps(eval_retrain_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run actions\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    parent = job_map[\"retrain_\" + model_name]\n",
    "    action = \"evaluate\"\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":eval_retrain_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    job_map[\"eval_retrain_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell (evaluate)\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"pointpillars\"):\n",
    "    job_id = job_map[\"eval_retrain_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export <a class=\"anchor\" id=\"head-19\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_name != \"bevfusion\":\n",
    "    # Get default spec schema\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/export/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    # print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    export_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(export_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes to the export_specs dictionary if necessary\n",
    "if model_name == \"action_recognition\":\n",
    "    export_specs[\"model\"][\"model_type\"] = model_type\n",
    "    export_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    export_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        export_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        export_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        export_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        export_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        export_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        export_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    export_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_segment':\n",
    "    export_specs[\"export\"][\"input_height\"] = 256 \n",
    "    export_specs[\"export\"][\"input_width\"] = 256 \n",
    "    export_specs[\"task\"] = 'segment'\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_classify':\n",
    "    export_specs[\"export\"][\"input_height\"] = 448 \n",
    "    export_specs[\"export\"][\"input_width\"] = 448\n",
    "    export_specs[\"task\"] = 'classify'\n",
    "if model_name != \"bevfusion\":\n",
    "    print(json.dumps(export_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name != \"bevfusion\":\n",
    "    if model_name == \"visual_changenet\":\n",
    "        parent = job_map[\"train_\" + ds_format]\n",
    "    else:\n",
    "        parent = job_map[\"train_\" + model_name]\n",
    "    action = \"export\"\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":export_specs,\n",
    "                    #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                    })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_map[\"export_\" + ds_format] = response.json()\n",
    "    else:\n",
    "        job_map[\"export_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name != \"bevfusion\":\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_id = job_map[\"export_\" + ds_format]\n",
    "    else:\n",
    "        job_id = job_map[\"export_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:\n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT Engine generation using TAO-Deploy <a class=\"anchor\" id=\"head-20\"></a>\n",
    "\n",
    "- Here, we use the exported model to convert to target platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet\", \"centerpose\"):\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/gen_trt_engine/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    #print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    tao_deploy_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(tao_deploy_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name in (\"ml_recog\", \"ocdnet\"):\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"INT8\"\n",
    "    elif model_name in (\"ocrnet\", \"optical_inspection\"):\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
    "    elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_classify':\n",
    "        tao_deploy_specs[\"task\"] = 'classify'\n",
    "    elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_segment':\n",
    "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
    "        tao_deploy_specs[\"task\"] = 'segment'\n",
    "    print(json.dumps(tao_deploy_specs, sort_keys=True, indent=4))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name == \"visual_changenet\":\n",
    "        parent = job_map[\"export_\" + ds_format]\n",
    "    else:\n",
    "        parent = job_map[\"export_\" + model_name]\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":\"gen_trt_engine\",\"specs\":tao_deploy_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_map[\"gen_trt_engine_\" + ds_format] = response.json()\n",
    "    else:\n",
    "        job_map[\"gen_trt_engine_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_id = job_map[\"gen_trt_engine_\" + ds_format]\n",
    "    else:\n",
    "        job_id = job_map[\"gen_trt_engine_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:    \n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAO inference <a class=\"anchor\" id=\"head-21\"></a>\n",
    "\n",
    "- Run inference on a set of images using the .tlt model created at train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/specs/inference/schema\"\n",
    "while True:\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "assert \"default\" in response.json().keys()\n",
    "tao_inference_specs = response.json()[\"default\"]\n",
    "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes to the tao_inference_specs dictionary if necessary\n",
    "if model_name == \"action_recognition\":\n",
    "    tao_inference_specs[\"model\"][\"model_type\"] = model_type\n",
    "    tao_inference_specs[\"model\"][\"input_type\"] = model_input_type\n",
    "    tao_inference_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
    "elif model_name == \"pose_classification\":\n",
    "    if model_type == \"nvidia\":\n",
    "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 6\n",
    "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
    "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
    "    elif model_type == \"kinetics\":\n",
    "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 5\n",
    "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
    "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
    "elif model_name == \"re_identification\":\n",
    "    tao_inference_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_classify':\n",
    "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"classify\"]['batch_size'] \n",
    "    tao_inference_specs[\"task\"] = 'classify'\n",
    "elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_segment':\n",
    "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"segment\"]['batch_size'] \n",
    "    tao_inference_specs[\"task\"] = 'segment'\n",
    "elif model_name == \"centerpose\":\n",
    "    tao_inference_specs[\"dataset\"][\"category\"] = \"bike\"\n",
    "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name == \"visual_changenet\":\n",
    "    parent = job_map[\"train_\" + ds_format]\n",
    "else:\n",
    "    parent = job_map[\"train_\" + model_name]\n",
    "action = \"inference\"\n",
    "data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":tao_inference_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "response = requests.post(endpoint, data=data, headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_map[\"inference_tao_\" + ds_format] = response.json()\n",
    "else:\n",
    "    job_map[\"inference_tao_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name == \"visual_changenet\":\n",
    "    job_id = job_map[\"inference_tao_\" + ds_format]\n",
    "else:\n",
    "    job_id = job_map[\"inference_tao_\" + model_name]\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRT inference <a class=\"anchor\" id=\"head-22\"></a>\n",
    "\n",
    "- no need to change the specs since we already uploaded it at the tlt inference step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"ml_recog\", \"optical_inspection\", \"visual_changenet\", \"centerpose\"):\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/specs/inference/schema\"\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        if response.status_code == 404:\n",
    "            if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "                print(\"Base experiment spec file is being downloaded\")\n",
    "                time.sleep(2)\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    # print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose schema\n",
    "    assert \"default\" in response.json().keys()\n",
    "    trt_inference_specs = response.json()[\"default\"]\n",
    "    print(json.dumps(trt_inference_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply changes to the specs dictionary if necessary\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"ml_recog\", \"optical_inspection\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name == \"visual_changenet\" and ds_format == 'visual_changenet_classify':\n",
    "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"classify\"]['batch_size']\n",
    "        trt_inference_specs[\"task\"] = 'classify'\n",
    "    elif model_name == \"visual_changenet\" and ds_format == 'visual_changenet_segment':\n",
    "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"segment\"]['batch_size']\n",
    "        trt_inference_specs[\"task\"] = 'segment'\n",
    "    print(json.dumps(trt_inference_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"ml_recog\", \"optical_inspection\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name == \"visual_changenet\":\n",
    "        parent = job_map[\"gen_trt_engine_\" + ds_format]\n",
    "    else:\n",
    "        parent = job_map[\"gen_trt_engine_\" + model_name]\n",
    "    action = \"inference\"\n",
    "    data = json.dumps({\"parent_job_id\":parent,\"action\":action,\"specs\":trt_inference_specs,\n",
    "                  #  \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "                   })\n",
    "\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "\n",
    "    response = requests.post(endpoint, data=data, headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "    assert response.json()\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_map[\"inference_trt_\" + ds_format] = response.json()\n",
    "    else:\n",
    "        job_map[\"inference_trt_\" + model_name] = response.json()\n",
    "    print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "if model_name in (\"ocdnet\", \"ocrnet\", \"ml_recog\", \"optical_inspection\", \"visual_changenet\", \"centerpose\"):\n",
    "    if model_name == \"visual_changenet\":\n",
    "        job_id = job_map[\"inference_trt_\" + ds_format]\n",
    "    else:\n",
    "        job_id = job_map[\"inference_trt_\" + model_name]\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "\n",
    "    while True:    \n",
    "        clear_output(wait=True)\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        assert response.status_code in (200, 201)\n",
    "        print(response)\n",
    "        print(json.dumps(response.json(), indent=4))\n",
    "        assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "        if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "            break\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete experiment <a class=\"anchor\" id=\"head-23\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset <a class=\"anchor\" id=\"head-24\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "\n",
    "response = requests.delete(endpoint,headers=headers)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name in (\"ocdnet\", \"ocrnet\", \"optical_inspection\") or ds_format == 'visual_changenet_classify':\n",
    "    endpoint = f\"{base_url}/datasets/{eval_dataset_id}\"\n",
    "\n",
    "    response = requests.delete(endpoint,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete test dataset <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name in (\"optical_inspection\") or ds_format == 'visual_changenet_classify':\n",
    "    endpoint = f\"{base_url}/datasets/{test_dataset_id}\"\n",
    "\n",
    "    response = requests.delete(endpoint,headers=headers)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
