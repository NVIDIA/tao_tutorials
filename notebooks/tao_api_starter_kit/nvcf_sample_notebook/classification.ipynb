{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to demonstrate Image Classification workflow\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
    "\n",
    "### Sample prediction for an Image Classification model\n",
    "<img align=\"center\" src=\"../example_images/sample_image_classification.jpg\">\n",
    "\n",
    "### The workflow in a nutshell\n",
    "\n",
    "- Pulling datasets from cloud\n",
    "- Getting a PTM from NGC\n",
    "- Model Actions\n",
    "    - Train (Normal/AutoML)\n",
    "    - Evaluate\n",
    "    - Prune, retrain\n",
    "    - Export\n",
    "    - TAO-Deploy\n",
    "    - Inference on TAO, TRT\n",
    "    - Delete experiments/dataset\n",
    "\n",
    "### Table of contents\n",
    "\n",
    "1. [FIXME's](#head-1)\n",
    "1. [Login](#head-2)\n",
    "1. [Set dataset formats](#head-3)\n",
    "1. [Create and pull train dataset](#head-4)\n",
    "1. [Create and pull val dataset](#head-5)\n",
    "1. [Create and pull test dataset](#head-6)\n",
    "1. [List the created datasets](#head-7)\n",
    "1. [Create an experiment](#head-8)\n",
    "1. [List experiments](#head-9)\n",
    "1. [Assign train, eval datasets](#head-10)\n",
    "1. [Assign PTM](#head-11)\n",
    "1. [Actions](#head-14)\n",
    "1. [Train](#head-14)\n",
    "1. [Delete experiment](#head-21)\n",
    "1. [Delete dataset](#head-22)\n",
    "\n",
    "### Requirements\n",
    "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import glob\n",
    "from remove_corrupted_images import remove_corrupted_images_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To see the dataset folder structure required for the models supported in this notebook, visit the notebooks under dataset_prepare like for [this notebook](../dataset_prepare/classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXME's <a class=\"anchor\" id=\"head-1\"></a>\n",
    "\n",
    "1. Assign a model_name in FIXME 1\n",
    "1. Assign the functionID of the helm chart function in FIXME 2\n",
    "1. Assign the versionID of the helm chart function in FIXME 3\n",
    "1. Assign the ngc_key variable in FIXME 4\n",
    "1. Assign the ngc_org_name variable in FIXME 5\n",
    "1. Set cloud storage details in FIXME 6\n",
    "1. Assign path of datasets relative to the bucket in FIXME 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define model_name workspaces and other variables\n",
    "# Available models (#FIXME 1):\n",
    "# 1. classification_pyt - https://docs.nvidia.com/tao/tao-toolkit/text/image_classification.html\n",
    "# 2. classification_tf2 - https://docs.nvidia.com/tao/tao-toolkit/text/image_classification_tf2.html\n",
    "\n",
    "model_name = \"classification_pyt\" # FIXME1 (Add the model name from the above mentioned list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set API service's host information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functionId = \"9c252c9c-6559-4b16-b464-cbc87fc4ab7a\" # FIXME2\n",
    "version_id = \"4d0faf19-1443-42b2-8abd-40ab8297ef8a\" # FIXME3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set NGC Personal key for authentication and NGC org to access API services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_key = \"\" # FIXME4 example: (Add NGC Personal key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngc_org_name = \"ea-tlt\" # FIXME5 your NGC ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke NVCF helm chart deployment\n",
    "def invoke_function(request_body):\n",
    "    url = f\"https://api.nvcf.nvidia.com/v2/nvcf/pexec/functions/{functionId}/versions/{version_id}\"\n",
    "\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'Content-Type': 'application/json',\n",
    "        \"Authorization\": f\"Bearer {ngc_key}\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=request_body)\n",
    "\n",
    "    if response.ok:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Request failed.\")\n",
    "        print(\"Response status code:\", response.status_code)\n",
    "        print(\"Response status code:\", response.text)\n",
    "        print(\"Response content:\", response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate NGC_PERSONAL_KEY\n",
    "login_metadata = {\"ngc_org_name\": ngc_org_name,\n",
    "                   \"ngc_key\": ngc_key}\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"login\",\n",
    "    \"request_body\": json.dumps(login_metadata),\n",
    "    \"ngc_key\": ngc_key\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "print(response.json())\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"token\" in response.json().keys()\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    " One of the keys of the response json are to be used as platform_id when you run each job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
    "# endpoint = f\"{base_url}:gpu_types\"\n",
    "# response = requests.get(super_endpoint, headers=headers)\n",
    "\n",
    "# assert response.ok\n",
    "# print(response)\n",
    "# print((json.dumps(response.json(), indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cloud workspace\n",
    "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
    "\n",
    "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME7 Dataset Cloud bucket details to download dataset for experiments (Can be read only)\n",
    "cloud_metadata = {\n",
    "    \"name\": \"AWS workspace info\",  # A Representative name for this cloud info\n",
    "    \"cloud_type\": \"aws\",  # If it's AWS, HuggingFace or Azure\n",
    "    \"cloud_specific_details\": {\n",
    "        \"cloud_region\": \"us-west-1\",\n",
    "        \"cloud_bucket_name\": \"\",  # FIXME 6\n",
    "        \"access_key\": \"\", # FIXME 6\n",
    "        \"secret_key\": \"\", # FIXME 6\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"create\",\n",
    "    \"kind\": \"workspaces\",\n",
    "    \"request_body\": json.dumps(cloud_metadata), \n",
    "    \"ngc_key\": ngc_key\n",
    "}\n",
    "\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"id\" in response.json().keys()\n",
    "workspace_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set dataset path (path within cloud bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME7 : Set paths relative to cloud bucket\n",
    "train_dataset_path =  \"/data/classification_train\"\n",
    "eval_dataset_path = \"/data/classification_val\"\n",
    "test_dataset_path = \"/data/classification_test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset formats <a class=\"anchor\" id=\"head-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "ds_type = \"image_classification\"\n",
    "ds_format = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull train dataset <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_metadata = {\"name\":\"Train dataset\",\n",
    "                          \"description\":\"My train dataset\",\n",
    "                          \"type\":ds_type,\n",
    "                          \"format\":ds_format,\n",
    "                          \"workspace\":workspace_id,\n",
    "                          \"cloud_file_path\": train_dataset_path,\n",
    "                          \"use_for\": [\"training\"]\n",
    "                         }\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"create\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"request_body\": json.dumps(train_dataset_metadata),\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"id\" in response.json().keys()\n",
    "train_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"retrieve\",\n",
    "        \"kind\": \"datasets\",\n",
    "        \"handler_id\": train_dataset_id,\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     train_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, train_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull val dataset <a class=\"anchor\" id=\"head-5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset_metadata = {\"name\":\"Val dataset\",\n",
    "                        \"description\":\"My val dataset\",\n",
    "                        \"type\":ds_type,\n",
    "                        \"format\":ds_format,\n",
    "                        \"workspace\":workspace_id,\n",
    "                        \"cloud_file_path\": eval_dataset_path,\n",
    "                        \"use_for\": [\"evaluation\"]\n",
    "                   }\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"create\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"request_body\": json.dumps(val_dataset_metadata),\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"id\" in response.json().keys()\n",
    "eval_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check progress\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"retrieve\",\n",
    "        \"kind\": \"datasets\",\n",
    "        \"handler_id\": eval_dataset_id,\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     eval_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, eval_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and pull test dataset <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Create testing dataset for inference\n",
    "ds_type = \"image_classification\"\n",
    "ds_format = \"raw\"\n",
    "test_dataset_metadata = {\"name\":\"Test dataset\",\n",
    "                        \"description\":\"My test dataset\",\n",
    "                        \"type\":ds_type,\n",
    "                        \"format\":ds_format,\n",
    "                        \"workspace\":workspace_id,\n",
    "                        \"cloud_file_path\": test_dataset_path,\n",
    "                        \"use_for\": [\"testing\"]\n",
    "                        }\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"create\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"request_body\": json.dumps(test_dataset_metadata),\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "assert response.status_code in (200, 201)\n",
    "assert \"id\" in response.json().keys()\n",
    "test_dataset_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check progress\n",
    "\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"retrieve\",\n",
    "        \"kind\": \"datasets\",\n",
    "        \"handler_id\": test_dataset_id,\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    print(json.dumps(response.json(), indent=4))\n",
    "    if response.json().get(\"status\") == \"invalid_pull\":\n",
    "        raise ValueError(\"Dataset pull failed\")\n",
    "    if response.json().get(\"status\") == \"pull_complete\":\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncomment if you want to remove corrupted images in your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This packages data-services experiments create and running the job of removing corrupted images\n",
    "# try:\n",
    "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
    "#     test_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, test_dataset_id)\n",
    "# except Exception as e:\n",
    "#     raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the created datasets <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"retrieve\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "print(response)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
    "for rsp in response.json()[\"datasets\"]:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys\n",
    "    assert \"type\" in rsp_keys\n",
    "    assert \"format\" in rsp_keys\n",
    "    assert \"name\" in rsp_keys\n",
    "    print(rsp[\"id\"],\"\\t\",rsp[\"type\"],\"\\t\",rsp[\"format\"],\"\\t\\t\",rsp[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment <a class=\"anchor\" id=\"head-8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encode_key = \"nvidia_tlt\"\n",
    "checkpoint_choose_method = \"best_model\"\n",
    "\n",
    "experiment_metadata = {\"network_arch\":model_name,\n",
    "                       \"encryption_key\":encode_key,\n",
    "                       \"checkpoint_choose_method\":checkpoint_choose_method,\n",
    "                       \"workspace\": workspace_id}\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"create\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"request_body\": json.dumps(experiment_metadata),\n",
    "    \"ngc_key\": ngc_key,    \n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "assert \"id\" in response.json().keys()\n",
    "experiment_id = response.json()[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List experiments <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\"network_arch\": model_name}\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"retrieve\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"request_body\": params,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "\n",
    "print(response)\n",
    "assert response.status_code in (200, 201)\n",
    "# print(json.dumps(response.json(), indent=4)) ## Uncomment for verbose list output\n",
    "print(\"model id\\t\\t\\t     network architecture\")\n",
    "for rsp in response.json()[\"experiments\"]:\n",
    "    rsp_keys = rsp.keys()\n",
    "    assert \"id\" in rsp_keys and \"network_arch\" in rsp_keys\n",
    "    print(rsp[\"name\"], rsp[\"id\"],rsp[\"network_arch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign train, eval datasets <a class=\"anchor\" id=\"head-10\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_information = {\"train_datasets\":[train_dataset_id],\n",
    "                       \"eval_dataset\":eval_dataset_id,\n",
    "                       \"inference_dataset\":test_dataset_id,\n",
    "                       \"calibration_dataset\":train_dataset_id}\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"partial_update\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"handler_id\": experiment_id,\n",
    "    \"request_body\": json.dumps(dataset_information),\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign PTM <a class=\"anchor\" id=\"head-11\"></a>\n",
    "\n",
    "Search for the PTM on NGC for the Classification model chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all pretrained models for the chosen network architecture\n",
    "params = {\"network_arch\": model_name}\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"retrieve\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"request_body\": params,\n",
    "    \"is_base_experiment\": True,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "response_json = response.json()[\"experiments\"]\n",
    "\n",
    "for rsp in response_json:\n",
    "    rsp_keys = rsp.keys()\n",
    "    if \"encryption_key\" not in rsp.keys():\n",
    "        assert \"name\" in rsp_keys and \"version\" in rsp_keys and \"ngc_path\" in rsp_keys\n",
    "        print(f'PTM Name: {rsp[\"name\"]}; PTM version: {rsp[\"version\"]}; NGC PATH: {rsp[\"ngc_path\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assigning pretrained models to different classification models\n",
    "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
    "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
    "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
    "pretrained_map = {\"classification_tf2\" : \"pretrained_classification_tf2:efficientnet_b0\",\n",
    "                  \"classification_pyt\" : \"pretrained_fan_classification_imagenet:fan_hybrid_tiny\",\n",
    "                  }\n",
    "no_ptm_models = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get pretrained model for classification\n",
    "if model_name not in no_ptm_models:\n",
    "    params = {\"network_arch\": model_name}\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"retrieve\",\n",
    "        \"kind\": \"experiments\",\n",
    "        \"request_body\": params,\n",
    "        \"is_base_experiment\": True,\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "    assert response.status_code in (200, 201)\n",
    "\n",
    "    response_json = response.json()[\"experiments\"]\n",
    "\n",
    "    # Search for ptm with given ngc path\n",
    "    ptm = []\n",
    "    for rsp in response_json:\n",
    "        assert \"ngc_path\" in rsp_keys\n",
    "        if rsp[\"ngc_path\"].endswith(pretrained_map[model_name]):\n",
    "            assert \"id\" in rsp_keys\n",
    "            ptm_id = rsp[\"id\"]\n",
    "            ptm = [ptm_id]\n",
    "            print(\"Metadata for model with requested NGC Path\")\n",
    "            print(rsp)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_name not in no_ptm_models:\n",
    "    ptm_information = {\"base_experiment\":ptm}\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"partial_update\",\n",
    "        \"kind\": \"experiments\",\n",
    "        \"handler_id\": experiment_id,\n",
    "        \"request_body\": json.dumps(ptm_information),\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    \n",
    "    response = invoke_function(super_data)\n",
    "\n",
    "    assert response.status_code in (200, 201)\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions <a class=\"anchor\" id=\"head-13\"></a>\n",
    "\n",
    "For all actions:\n",
    "1. Get default spec schema and derive the default values\n",
    "2. Modify defaults if needed\n",
    "3. Post spec dictionary to the service\n",
    "4. Run model action\n",
    "5. Monitor job using retrieve\n",
    "6. Download results using job download endpoint (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_map = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train <a class=\"anchor\" id=\"head-14\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get default spec schema\n",
    "\n",
    "while True:\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"specs_schema\",\n",
    "        \"kind\": \"experiments\",\n",
    "        \"handler_id\": experiment_id,\n",
    "        \"action\": \"train\",\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "    if response.status_code == 404:\n",
    "        if \"Base spec file download state is \" in response.json()[\"error_desc\"]:\n",
    "            print(\"Base experiment spec file is being downloaded\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "train_specs = response.json()[\"default\"]\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Override any of the parameters listed in the previous cell as required\n",
    "# Example for classification_pyt\n",
    "if model_name == \"classification_pyt\":\n",
    "    train_specs[\"train\"][\"train_config\"][\"runner\"][\"max_epochs\"] = 10\n",
    "    train_specs[\"train\"][\"num_gpus\"] = 1\n",
    "# Example for classification_tf2\n",
    "elif model_name == \"classification_tf2\":\n",
    "    train_specs[\"train\"][\"num_epochs\"] = 80\n",
    "\n",
    "print(json.dumps(train_specs, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run action\n",
    "parent = None\n",
    "action = \"train\"\n",
    "train_request_body = {\"parent_job_id\":parent,\"action\":action,\"specs\":train_specs,\n",
    "        \"platform_id\": '9af1aa90-8ea5-5a11-98d9-3879cd0da92c',  # Pick a platform_from output of {base_url}:gpu_types depending on GPU_type and instance_type\n",
    "        }\n",
    "super_data = {\n",
    "    \"api_endpoint\": \"job_run\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"handler_id\": experiment_id,\n",
    "    \"action\": action,\n",
    "    \"request_body\": json.dumps(train_request_body),\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "\t\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "assert response.json()\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))\n",
    "\n",
    "job_map[\"train_\" + model_name] = response.json()\n",
    "print(job_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Monitor job status by repeatedly running this cell\n",
    "# For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
    "\n",
    "job_id = job_map[\"train_\" + model_name]\n",
    "\n",
    "while True:    \n",
    "    clear_output(wait=True)\n",
    "    super_data = {\n",
    "        \"api_endpoint\": \"retrieve\",\n",
    "        \"kind\": \"experiments\",\n",
    "        \"handler_id\": experiment_id,\n",
    "        \"is_job\": True,\n",
    "        \"job_id\": job_id,\n",
    "        \"ngc_key\": ngc_key,\n",
    "    }\n",
    "    response = invoke_function(super_data)\n",
    "\n",
    "    if \"error_desc\" in response.json().keys() and response.json()[\"error_desc\"] in (\"Job trying to retrieve not found\", \"No AutoML run found\"):\n",
    "        print(\"Job is being created\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "    print(response)\n",
    "    print(json.dumps(response.json(), sort_keys=True, indent=4))\n",
    "    assert \"status\" in response.json().keys() and response.json().get(\"status\") != \"Error\"\n",
    "    if response.json().get(\"status\") in [\"Done\",\"Error\", \"Canceled\", \"Paused\"] or response.status_code not in (200,201):\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete experiment <a class=\"anchor\" id=\"head-21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"delete\",\n",
    "    \"kind\": \"experiments\",\n",
    "    \"handler_id\": experiment_id,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "\t\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete dataset <a class=\"anchor\" id=\"head-22\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"delete\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"handler_id\": train_dataset_id,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "\t\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete val dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"delete\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"handler_id\": eval_dataset_id,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "\t\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_data = {\n",
    "    \"api_endpoint\": \"delete\",\n",
    "    \"kind\": \"datasets\",\n",
    "    \"handler_id\": test_dataset_id,\n",
    "    \"ngc_key\": ngc_key,\n",
    "}\n",
    "\t\n",
    "response = invoke_function(super_data)\n",
    "assert response.status_code in (200, 201)\n",
    "\n",
    "print(response)\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
