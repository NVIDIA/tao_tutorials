{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook to demonstrate TAO workflow on purpose built models\n",
        "\n",
        "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
        "\n",
        "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
        "\n",
        "### The workflow in a nutshell\n",
        "\n",
        "- Pulling datasets from cloud\n",
        "- Running dataset convert (for specific models)\n",
        "- Getting a PTM from NGC\n",
        "- Model Actions\n",
        "    - Train (Normal/AutoML)\n",
        "    - Evaluate\n",
        "    - Prune, retrain (for specific models)\n",
        "    - Export\n",
        "    - TAO-Deploy (for specific models)\n",
        "    - Inference on TAO, TRT\n",
        "    - Delete experiments/dataset\n",
        "    \n",
        "### Table of contents\n",
        "\n",
        "1. [FIXME's](#head-1)\n",
        "1. [Login](#head-2)\n",
        "1. [Create a cloud workspace](#head-2)\n",
        "1. [Set dataset formats](#head-3)\n",
        "1. [Create and pull train dataset](#head-4)\n",
        "1. [Create and pull val dataset](#head-5)\n",
        "1. [Create and pull test dataset](#head-6)\n",
        "1. [List the created datasets](#head-7)\n",
        "1. [Train Dataset convert action](#head-8) (for specific models)\n",
        "1. [Val dataset convert action](#head-9) (for specific models)\n",
        "1. [Create an experiment](#head-10)\n",
        "1. [List experiments](#head-11)\n",
        "1. [Assign train, eval datasets](#head-12)\n",
        "1. [Assign PTM](#head-13)\n",
        "1. [Set AutoML related configurations](#head-14)\n",
        "1. [Actions](#head-15)\n",
        "1. [Train](#head-16)\n",
        "1. [View hyperparameters that are enabled by default](#head-16.1)\n",
        "1. [Evaluate](#head-17)\n",
        "1. [Optimize: Prune, retrain and evaluate](#head-18) (for specific models)\n",
        "1. [Export](#head-19)\n",
        "1. [TRT Engine generation using TAO-Deploy](#head-20) (for specific models)\n",
        "1. [TAO inference](#head-21)\n",
        "1. [TRT inference](#head-22) (for specific models)\n",
        "1. [Delete experiment](#head-23)\n",
        "1. [Delete dataset](#head-24)\n",
        "\n",
        "### Requirements\n",
        "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXPLICIT_EVAL_DATASET_MODELS = [\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"visual_changenet_classify\"]\n",
        "EXPLICIT_TEST_DATASET_MODELS = [\"visual_changenet_classify\", \"optical_inspection\"]\n",
        "TRAIN_REUSE_FOR_EVAL_TEST_MODELS = [\"sparse4d\"]\n",
        "TRAIN_DATASET_CONVERT_MODELS = [\"bevfusion\", \"ocrnet\", \"pointpillars\", \"sparse4d\"]\n",
        "EVAL_DATASET_CONVERT_MODELS = [\"ocrnet\"]\n",
        "PRUNEABLE_MODELS = [\"ocdnet\", \"ocrnet\", \"pointpillars\"]\n",
        "UN_EXPORTABLE_MODELS = [\"bevfusion\"]\n",
        "TAO_DEPLOY_MODELS = [\"ocdnet\", \"ocrnet\", \"optical_inspection\", \"ml_recog\", \"visual_changenet_classify\", \"visual_changenet_segment\", \"centerpose\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Import TAO SDK\n",
        "from tao_sdk.client import TaoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Restore variable in case of jupyter session restart and resume execution where it left off\n",
        "%store -r model_name\n",
        "%store -r automl_enabled\n",
        "%store -r automl_algorithm\n",
        "%store -r base_url\n",
        "%store -r headers\n",
        "%store -r workspace_id\n",
        "%store -r train_dataset_id\n",
        "%store -r eval_dataset_id\n",
        "%store -r test_dataset_id\n",
        "%store -r experiment_id\n",
        "%store -r job_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### To see the dataset folder structure required for the models supported in this notebook, visit the notebooks under dataset_prepare like for [this notebook](../dataset_prepare/purpose_built_models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FIXME's <a class=\"anchor\" id=\"head-1\"></a>\n",
        "\n",
        "1. Assign a model_name in FIXME 1\n",
        "\n",
        "    1.1 Assign model type for action_recognition/pose_classification in FIXME 1.1\n",
        "    \n",
        "    1.2 Assign model input type for action_recognition in FIXME 1.2\n",
        "1. (Optional) Enable AutoML if needed in FIXME 2\n",
        "1. (Optional) Choose between bayesian and hyperband automl_algorithm in FIXME 3 (If automl was enabled in FIXME2)\n",
        "1. Assign the ip_address and port_number in FIXME 4 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
        "1. Assign the ngc_key variable in FIXME 5\n",
        "1. Assign the ngc_org_name variable in FIXME 6\n",
        "1. Set cloud storage details in FIXME 7\n",
        "1. Assign path of datasets relative to the bucket in FIXME 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Choose a purpose built model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Define model_name workspaces and other variables\n",
        "# Available models (#FIXME 1):\n",
        "# 1. action_recognition - https://docs.nvidia.com/tao/tao-toolkit/text/action_recognition_net.html\n",
        "# 2. bevfusion - https://docs.nvidia.com/tao/tao-toolkit/text/bevfusion/index.html\n",
        "# 2. ml_recog - https://docs.nvidia.com/tao/tao-toolkit/text/ml_recog/index.html\n",
        "# 3. ocdnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocdnet/index.html\n",
        "# 4. ocrnet - https://docs.nvidia.com/tao/tao-toolkit/text/ocrnet/index.html\n",
        "# 5. optical_inspection - https://docs.nvidia.com/tao/tao-toolkit/text/optical_inspection/index.html\n",
        "# 6. pose_classification - https://docs.nvidia.com/tao/tao-toolkit/text/pose_classification/index.html\n",
        "# 7. pointpillars - https://docs.nvidia.com/tao/tao-toolkit/text/point_cloud/pointpillars.html\n",
        "# 8. re_identification - https://docs.nvidia.com/tao/tao-toolkit/text/re_identification/index.html\n",
        "# 9. sparse4d - https://docs.nvidia.com/tao/tao-toolkit/text/sparse4d/index.html\n",
        "# 10. centerpose - https://docs.nvidia.com/tao/tao-toolkit/text/centerpose/index.html\n",
        "# 11. visual_changenet_classify - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
        "# 12. visual_changenet_segment - https://docs.nvidia.com/tao/tao-toolkit/text/visual_changenet/index.html\n",
        "\n",
        "os.environ[\"TAO_MODEL_NAME\"] = model_name = os.environ.get(\"TAO_MODEL_NAME\", \"ocrnet\")  # Pick the model name from the above mentioned list\n",
        "%store model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if model_name in (\"action_recognition\",\"pose_classification\"):\n",
        "    # FIXME1.1 - model_type - string\n",
        "        # action-recognition: rgb/of/joint;\n",
        "        # pose-classification: kinetics/nvidia\n",
        "    model_type = \"rgb\"\n",
        "\n",
        "    if model_name == \"action_recognition\":\n",
        "        if model_type not in (\"rgb\",\"of\",\"joint\"):\n",
        "            raise Exception(\"Choose one of rgb/of/joint for action recognition model_type\")\n",
        "    elif model_name == \"pose_classification\":\n",
        "        if model_type not in (\"kinetics\",\"nvidia\"):\n",
        "            raise Exception(\"Choose one of kinetics/nvidia for pose classification model_type\")\n",
        "\n",
        "    if model_name == \"action_recognition\":\n",
        "        model_input_type = \"3d\" # FIXME1.2 3d/2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Toggle AutoML params\n",
        "[AutoML documentation](https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#getting-started)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 2: Set to True if you want to run automl for the model chosen in the previous cell\n",
        "automl_enabled = os.environ.get(\"TAO_AUTOML_ENABLED\", \"False\").lower() == \"true\"\n",
        "os.environ[\"TAO_AUTOML_ENABLED\"] = str(automl_enabled)\n",
        "# One of bayesian/hyperband\n",
        "os.environ[\"TAO_AUTOML_ALGORITHM\"] = automl_algorithm = os.environ.get(\"TAO_AUTOML_ALGORITHM\", \"bayesian\")\n",
        "\n",
        "%store automl_enabled\n",
        "%store automl_algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set API service's host information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 4: Set TAO API environment variables\n",
        "\n",
        "# Set to your TAO API endpoint\n",
        "os.environ[\"TAO_BASE_URL\"] = os.environ.get(\"TAO_BASE_URL\", \"https://your_tao_ip_address:port/api/v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set NGC Personal key for authentication and NGC org to access API services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 5: Your NGC personal key\n",
        "os.environ[\"NGC_KEY\"] = ngc_key = os.environ.get(\"NGC_KEY\", \"your_ngc_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 6: Your NGC ORG name\n",
        "os.environ[\"NGC_ORG\"] = ngc_org_name = os.environ.get(\"NGC_ORG\", \"nvstaging\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Login <a class=\"anchor\" id=\"head-2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize TAO Client and login using SDK\n",
        "tao_client = TaoClient()\n",
        "\n",
        "# Login using TAO SDK - this will automatically save credentials to environment variables\n",
        "login_response = tao_client.login(\n",
        "    ngc_key=ngc_key,\n",
        "    ngc_org_name=ngc_org_name,\n",
        "    enable_telemetry=True\n",
        ")\n",
        "\n",
        "print(\"Login successful!\")\n",
        "print(\"JWT Token:\", tao_client.token)\n",
        "print(\"API Base URL:\", tao_client.base_url)\n",
        "print(\"Organization:\", tao_client.org_name)\n",
        "\n",
        "%store tao_client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
        "\n",
        " One of the keys of the response json are to be used as platform_id when you run each job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
        "# # Get available GPU types using TAO SDK\n",
        "# try:\n",
        "#     gpu_types = tao_client.get_gpu_types()\n",
        "#     print(\"Available GPU types:\")\n",
        "#     print(json.dumps(gpu_types, indent=4))\n",
        "# except Exception as e:\n",
        "#     print(\"Could not fetch GPU types (may not be available on this deployment):\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create cloud workspace\n",
        "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
        "\n",
        "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 7: Dataset Cloud bucket details to download dataset or push job artifacts for jobs\n",
        "\n",
        "cloud_metadata = {}\n",
        "\n",
        "# A Representative name for this cloud info\n",
        "os.environ[\"TAO_WORKSPACE_NAME\"] = cloud_metadata[\"name\"] = os.environ.get(\"TAO_WORKSPACE_NAME\", \"AWS workspace info\")\n",
        "\n",
        "# Cloud specific details. Below is assuming AWS.\n",
        "cloud_metadata[\"cloud_specific_details\"] = {}\n",
        "\n",
        " # Whether it is AWS, HuggingFace or Azure\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_TYPE\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_TYPE\", \"aws\")\n",
        "\n",
        "# Bucket region\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_REGION\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_REGION\", \"us-west-1\")\n",
        "\n",
        "# Bucket name\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\", \"bucket_name\")\n",
        "\n",
        "# Access and Secret keys\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\", \"access_key\")\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_SECRET_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_SECRET_KEY\", \"secret_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cloud workspace using TAO SDK\n",
        "workspace_id = tao_client.create_workspace(\n",
        "    name=cloud_metadata[\"name\"],\n",
        "    cloud_type=cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"],\n",
        "    cloud_specific_details=cloud_metadata[\"cloud_specific_details\"]\n",
        ")\n",
        "\n",
        "print(\"Workspace created successfully!\")\n",
        "print(f\"Workspace ID: {workspace_id}\")\n",
        "\n",
        "# Get workspace details to confirm creation\n",
        "workspace_details = tao_client.get_workspace_metadata(workspace_id)\n",
        "print(\"Workspace details:\")\n",
        "print(json.dumps(workspace_details, indent=4))\n",
        "\n",
        "%store workspace_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set dataset path (path within cloud bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME8 : Set paths relative to cloud bucket\n",
        "os.environ[\"TAO_TRAIN_DATASET_PATH\"] = train_dataset_path = os.environ.get(\"TAO_TRAIN_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_train\")\n",
        "os.environ[\"TAO_EVAL_DATASET_PATH\"] = eval_dataset_path = os.environ.get(\"TAO_EVAL_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_val\")  # ocdnet, ocrnet, optical_inspection, visual_changenet_classify\n",
        "os.environ[\"TAO_TEST_DATASET_PATH\"] = test_dataset_path = os.environ.get(\"TAO_TEST_DATASET_PATH\", f\"/data/purpose_built_models_{model_name}_test\")  # optical_inspection, visual_changenet_classify\n",
        "train_dataset_id = None\n",
        "eval_dataset_id = None\n",
        "test_dataset_id = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set dataset formats <a class=\"anchor\" id=\"head-3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if model_name == \"sparse4d\":\n",
        "    ds_type = model_name\n",
        "    ds_format = \"ovpkl\"\n",
        "else:\n",
        "    ds_type = model_name\n",
        "    ds_format = \"default\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create and pull train dataset <a class=\"anchor\" id=\"head-4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create train dataset using TAO SDK\n",
        "train_dataset_id = tao_client.create_dataset(\n",
        "    dataset_type=ds_type,\n",
        "    dataset_format=ds_format,\n",
        "    workspace_id=workspace_id,\n",
        "    cloud_file_path=train_dataset_path,\n",
        "    use_for=[\"training\"]\n",
        ")\n",
        "\n",
        "print(\"Train dataset created successfully!\")\n",
        "print(f\"Train Dataset ID: {train_dataset_id}\")\n",
        "\n",
        "if model_name in TRAIN_REUSE_FOR_EVAL_TEST_MODELS:\n",
        "    eval_dataset_id = train_dataset_id\n",
        "    test_dataset_id = train_dataset_id\n",
        "    %store test_dataset_id\n",
        "\n",
        "%store train_dataset_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check train dataset progress using TAO SDK\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    dataset_details = tao_client.get_dataset_metadata(train_dataset_id)\n",
        "    \n",
        "    print(f\" Train Dataset Status: {dataset_details.get('status', 'Unknown')}\")\n",
        "    print(f\"Dataset ID: {train_dataset_id}\")\n",
        "    \n",
        "    if dataset_details.get(\"status\") == \"invalid_pull\":\n",
        "        print(\"Dataset pull failed!\")\n",
        "        validation_details = dataset_details.get(\"validation_details\", {})\n",
        "        if validation_details:\n",
        "            print(\"Validation details:\")\n",
        "            print(json.dumps(validation_details, indent=4))\n",
        "        raise ValueError(\"Dataset pull failed\")\n",
        "        \n",
        "    if dataset_details.get(\"status\") == \"pull_complete\":\n",
        "        print(\"Train dataset pull completed successfully!\")\n",
        "        print(\"Dataset details:\")\n",
        "        print(json.dumps(dataset_details, indent=4))\n",
        "        break\n",
        "        \n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Uncomment if you want to remove corrupted images in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # This packages data-services experiments create and running the job of removing corrupted images\n",
        "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "# # try:\n",
        "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "#     train_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, train_dataset_id)\n",
        "#     %store train_dataset_id\n",
        "# except Exception as e:\n",
        "#     raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create and pull val dataset <a class=\"anchor\" id=\"head-5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create eval dataset using TAO SDK\n",
        "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
        "    eval_dataset_id = tao_client.create_dataset(\n",
        "        dataset_type=ds_type,\n",
        "        dataset_format=ds_format,\n",
        "        workspace_id=workspace_id,\n",
        "        cloud_file_path=eval_dataset_path,\n",
        "        use_for=[\"evaluation\"]\n",
        "    )\n",
        "\n",
        "    print(\"Eval dataset created successfully!\")\n",
        "    print(f\"Eval Dataset ID: {eval_dataset_id}\")\n",
        "    %store eval_dataset_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check eval dataset progress using TAO SDK\n",
        "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        dataset_details = tao_client.get_dataset_metadata(eval_dataset_id)\n",
        "        \n",
        "        print(f\" Eval Dataset Status: {dataset_details.get('status', 'Unknown')}\")\n",
        "        print(f\"Dataset ID: {eval_dataset_id}\")\n",
        "        \n",
        "        if dataset_details.get(\"status\") == \"invalid_pull\":\n",
        "            print(\"Dataset pull failed!\")\n",
        "            validation_details = dataset_details.get(\"validation_details\", {})\n",
        "            if validation_details:\n",
        "                print(\"Validation details:\")\n",
        "                print(json.dumps(validation_details, indent=4))\n",
        "            raise ValueError(\"Dataset pull failed\")\n",
        "            \n",
        "        if dataset_details.get(\"status\") == \"pull_complete\":\n",
        "            print(\"Eval dataset pull completed successfully!\")\n",
        "            print(\"Dataset details:\")\n",
        "            print(json.dumps(dataset_details, indent=4))\n",
        "            break\n",
        "            \n",
        "        time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Uncomment if you want to remove corrupted images in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # This packages data-services experiments create and running the job of removing corrupted images\n",
        "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "# if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
        "# #     try:\n",
        "#         from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "#         eval_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, eval_dataset_id)\n",
        "#         %store eval_dataset_id\n",
        "#     except Exception as e:\n",
        "#         raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create and pull test dataset <a class=\"anchor\" id=\"head-6\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create testing dataset for inference\n",
        "if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
        "    ds_type = model_name\n",
        "    ds_format = \"default\"\n",
        "\n",
        "    # Create test dataset using TAO SDK\n",
        "    test_dataset_id = tao_client.create_dataset(\n",
        "        dataset_type=ds_type,\n",
        "        dataset_format=ds_format,\n",
        "        workspace_id=workspace_id,\n",
        "        cloud_file_path=test_dataset_path,\n",
        "        use_for=[\"testing\"]\n",
        "    )\n",
        "\n",
        "    print(\"Test dataset created successfully!\")\n",
        "    print(f\"Test Dataset ID: {test_dataset_id}\")\n",
        "\n",
        "    %store test_dataset_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check progress\n",
        "if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
        "    # Check test dataset progress using TAO SDK\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        dataset_details = tao_client.get_dataset_metadata(test_dataset_id)\n",
        "        \n",
        "        print(f\"Test Dataset Status: {dataset_details.get('status', 'Unknown')}\")\n",
        "        print(f\"Dataset ID: {test_dataset_id}\")\n",
        "        \n",
        "        if dataset_details.get(\"status\") == \"invalid_pull\":\n",
        "            print(\"Dataset pull failed!\")\n",
        "            validation_details = dataset_details.get(\"validation_details\", {})\n",
        "            if validation_details:\n",
        "                print(\"Validation details:\")\n",
        "                print(json.dumps(validation_details, indent=4))\n",
        "            raise ValueError(\"Dataset pull failed\")\n",
        "            \n",
        "        if dataset_details.get(\"status\") == \"pull_complete\":\n",
        "            print(\"Test dataset pull completed successfully!\")\n",
        "            print(\"Dataset details:\")\n",
        "            print(json.dumps(dataset_details, indent=4))\n",
        "            break\n",
        "            \n",
        "        time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Uncomment if you want to remove corrupted images in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # This packages data-services experiments create and running the job of removing corrupted images\n",
        "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "# # if model_name in EXPLICIT_TEST_DATASET_MODELS:\n",
        "#     try:\n",
        "#         from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "#         test_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, test_dataset_id)\n",
        "#         %store test_dataset_id\n",
        "#     except Exception as e:\n",
        "#         raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the created datasets <a class=\"anchor\" id=\"head-7\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# List datasets using TAO SDK\n",
        "datasets = tao_client.list_datasets()\n",
        "\n",
        "print(\"Available datasets:\")\n",
        "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_id = dataset.get(\"id\", \"N/A\")\n",
        "    dataset_type = dataset.get(\"type\", \"N/A\")\n",
        "    dataset_format = dataset.get(\"format\", \"N/A\")\n",
        "    dataset_name = dataset.get(\"name\", \"N/A\")\n",
        "    print(f\"{dataset_id}\\t{dataset_type}\\t{dataset_format}\\t\\t{dataset_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "job_map = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Dataset convert Action <a class=\"anchor\" id=\"head-8\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "convert_action = \"dataset_convert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get default train dataset convert specs using TAO SDK\n",
        "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
        "    train_ds_convert_spec_response = tao_client.get_job_schema(action=\"dataset_convert\", network_arch=model_name)\n",
        "    train_ds_convert_specs = train_ds_convert_spec_response.get(\"default\", {})\n",
        "    print(\"Default train dataset convert specifications:\")\n",
        "    print(json.dumps(train_ds_convert_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to specs dictionary if necessary\n",
        "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
        "    if model_name == \"sparse4d\":\n",
        "        train_ds_convert_specs[\"data\"][\"input_format\"] = \"AICity\"\n",
        "        train_ds_convert_specs[\"data\"][\"output_format\"] = \"OVPKL\"\n",
        "        train_ds_convert_specs[\"aicity\"][\"num_frames\"] = 90\n",
        "    print(json.dumps(train_ds_convert_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Run action\n",
        "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
        "    action = convert_action\n",
        "    train_ds_convert_job_name = f\"{model_name}_train_dataset_convert_job\"\n",
        "\n",
        "    train_ds_convert_job = tao_client.create_job(\n",
        "        kind=\"dataset\",\n",
        "        name=train_ds_convert_job_name,\n",
        "        network_arch=model_name,\n",
        "        workspace=workspace_id,\n",
        "        dataset_id=train_dataset_id,\n",
        "        action=action,\n",
        "        specs=train_ds_convert_specs,  # Pass as dict, not JSON string\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Train Dataset Convert job created successfully!\")\n",
        "    print(f\"Train Dataset Convert Job ID: {train_ds_convert_job}\")\n",
        "    print(f\"Action: train dataset_convert\")\n",
        "\n",
        "    job_map[\"train_dataset_convert_\" + model_name] = train_ds_convert_job\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor job status by repeatedly running this cell\n",
        "if model_name in TRAIN_DATASET_CONVERT_MODELS:\n",
        "    train_ds_convert_job_id = job_map[\"train_dataset_convert_\" + model_name]\n",
        "\n",
        "    while True:    \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(train_ds_convert_job_id)\n",
        "            \n",
        "            print(f\"Train Dataset Convert Job Status\")\n",
        "            print(f\"Job ID: {train_ds_convert_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Train Dataset Convert job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Train Dataset Convert job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\"Train Dataset Convert job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching inference job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eval Dataset convert Action <a class=\"anchor\" id=\"head-9\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
        "    eval_ds_convert_spec_response = tao_client.get_job_schema(action=\"dataset_convert\", network_arch=model_name)\n",
        "    eval_ds_convert_specs = eval_ds_convert_spec_response.get(\"default\", {})\n",
        "    print(\"Default eval dataset convert specifications:\")\n",
        "    print(json.dumps(eval_ds_convert_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to specs dictionary if necessary\n",
        "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
        "    print(json.dumps(eval_ds_convert_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create eval dataset convert job using TAO SDK\n",
        "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
        "    parent = job_map[\"train_dataset_convert_\"+model_name]\n",
        "    action = convert_action\n",
        "    eval_ds_convert_job_name = f\"{model_name}_eval_dataset_convert_job\"\n",
        "\n",
        "    eval_ds_convert_job = tao_client.create_job(\n",
        "        kind=\"dataset\",\n",
        "        name=eval_ds_convert_job_name,\n",
        "        network_arch=model_name,\n",
        "        workspace=workspace_id,\n",
        "        dataset_id=eval_dataset_id,\n",
        "        action=action,\n",
        "        specs=eval_ds_convert_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Evaluate Dataset Convert job created successfully!\")\n",
        "    print(f\"Evaluate Dataset Convert Job ID: {eval_ds_convert_job}\")\n",
        "    print(f\"Parent Job ID: {parent}\")\n",
        "    print(f\"Action: evaluate dataset_convert\")\n",
        "\n",
        "    job_map[\"eval_dataset_convert_\" + model_name] = eval_ds_convert_job\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor eval dataset convert job status using TAO SDK\n",
        "if model_name in EVAL_DATASET_CONVERT_MODELS:\n",
        "    eval_ds_convert_job_id = job_map[\"eval_dataset_convert_\" + model_name]\n",
        "\n",
        "    while True:    \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(eval_ds_convert_job_id)\n",
        "            \n",
        "            print(f\"Eval Dataset Convert Job Status\")\n",
        "            print(f\"Job ID: {eval_ds_convert_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Eval Dataset Convert job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Eval Dataset Convert job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\"Eval Dataset Convert job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching inference job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set common params across all jobs <a class=\"anchor\" id=\"head-10\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "encode_key = \"nvidia_tlt\"\n",
        "if model_name in (\"action_recognition\", \"pose_classification\", \"re_identification\"):\n",
        "    encode_key = \"nvidia_tao\"\n",
        "elif model_name == \"pointpillars\":\n",
        "    encode_key = \"tlt_encode\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assign PTM <a class=\"anchor\" id=\"head-13\"></a>\n",
        "\n",
        "Search for PTM on NGC for the Purpose built model chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# List base experiments (PTMs) using TAO SDK  \n",
        "# These are the pre-trained models available for the selected network architecture\n",
        "base_experiments = tao_client.list_base_experiments(filter_params={\"network_arch\": model_name})\n",
        "\n",
        "print(f\" Available base experiments (PTMs) for {model_name}:\")\n",
        "print(\"name\\t\\t\\t     model id\\t\\t\\t     network architecture\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "for exp in base_experiments:\n",
        "    exp_name = exp.get(\"name\", \"N/A\")\n",
        "    exp_id = exp.get(\"id\", \"N/A\")\n",
        "    exp_arch = exp.get(\"network_arch\", \"N/A\")\n",
        "    print(f\"{exp_name}\\t{exp_id}\\t{exp_arch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Assigning pretrained models to different purpose built models versions\n",
        "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
        "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
        "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
        "pretrained_map = {\"action_recognition\":\"actionrecognitionnet:trainable_rgb_3d\",\n",
        "                  \"bevfusion\": \"bevfusion:bevfusion_1.0\",\n",
        "                  \"ml_recog\": \"retail_object_recognition:trainable_v1.0\",\n",
        "                  \"ocdnet\": \"ocdnet:trainable_resnet18_v1.0\",\n",
        "                  \"ocrnet\": \"nvidia/tao/ocrnet:trainable_v1.0\",\n",
        "                  \"optical_inspection\": \"optical_inspection:trainable_v1.0\",\n",
        "                  \"pointpillars\":\"pointpillarnet:trainable_v1.0\",\n",
        "                  \"pose_classification\":\"poseclassificationnet:trainable_v1.0\",\n",
        "                  \"re_identification\":\"reidentificationnet_transformer:swin_tiny_256_1\",\n",
        "                  \"sparse4d\": \"sparse4d:resnet_101\",\n",
        "                  \"visual_changenet_classify\": \"visual_changenet_classification:visual_changenet_nvpcb_trainable_v1.0\",\n",
        "                  \"visual_changenet_segment\": \"visual_changenet_segmentation_levircd:visual_changenet_levircd_trainable_v1.0\",\n",
        "                  \"centerpose\": \"pretrained_fan_classification_nvimagenet:fan_small_hybrid_nvimagenet\"}\n",
        "if model_name == \"action_recognition\":\n",
        "    if model_type == \"of\":\n",
        "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v2.0\"\n",
        "    elif model_type == \"joint\":\n",
        "        pretrained_map[\"action_recognition\"] = \"actionrecognitionnet:trainable_v1.0,actionrecognitionnet:trainable_v2.0\"\n",
        "        \n",
        "no_ptm_models = set([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get pretrained model using TAO SDK\n",
        "selected_ptm_id = None\n",
        "if model_name not in no_ptm_models:\n",
        "    base_experiments_detailed = tao_client.list_base_experiments(filter_params={\"network_arch\": model_name})\n",
        "    \n",
        "    # Search for PTM with given NGC path\n",
        "    for exp in base_experiments_detailed:\n",
        "        ngc_path = exp.get(\"ngc_path\", \"\")\n",
        "        if ngc_path.endswith(pretrained_map[model_name]):\n",
        "            selected_ptm_id = exp.get(\"id\")\n",
        "            print(\"Selected PTM metadata:\")\n",
        "            print(json.dumps(exp, indent=4))\n",
        "            break\n",
        "    \n",
        "    if not selected_ptm_id:\n",
        "        print(f\" PTM with NGC path ending in '{pretrained_map[model_name]}' not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#  TAO: PTM assignment happens during job creation\n",
        "# The selected PTM ID will be used in the job creation step\n",
        "if model_name not in no_ptm_models and selected_ptm_id:\n",
        "    print(f\" PTM ID {selected_ptm_id} will be used as base_experiment_id in job creation\")\n",
        "else:\n",
        "    print(\"No PTM will be used (training from scratch)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Actions <a class=\"anchor\" id=\"head-15\"></a>\n",
        "\n",
        "For all actions:\n",
        "1. Get default spec schema and derive the default values\n",
        "2. Modify defaults if needed\n",
        "3. Post spec dictionary to the service\n",
        "4. Run model action\n",
        "5. Monitor job using retrieve\n",
        "6. Download results using job download (if needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train <a class=\"anchor\" id=\"head-16\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### View hyperparameters that are enabled for AutoML by default <a class=\"anchor\" id=\"head-14\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Initialize automl_params (needed for AutoML configuration)\n",
        "automl_params = {}\n",
        "\n",
        "if automl_enabled:\n",
        "    # Get default AutoML parameters using TAO SDK\n",
        "    # This is retrieved using the base experiment ID (PTM)\n",
        "    automl_params = tao_client.get_automl_defaults(network_arch=model_name, action=\"train\")\n",
        "    print(\"Default AutoML parameters:\")\n",
        "    print(json.dumps(automl_params, sort_keys=True, indent=4))\n",
        "else:\n",
        "    print(\"AutoML is disabled - automl_params initialized as empty dict\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set AutoML related configurations <a class=\"anchor\" id=\"head-16.1\"></a>\n",
        "Refer to these hyper-links to see the parameters supported by each network and add more parameters if necessary in addition to the default automl enabled parameters:\n",
        "\n",
        "[ActionRecognitionNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/action_recognition/action_recognition%20-%20train.csv), \n",
        "[MetricLearningRecognition](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ml_recog/ml_recog%20-%20train.csv), \n",
        "[OCDNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocdnet/ocdnet%20-%20train.csv), \n",
        "[OCRNET](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/ocrnet/ocrnet%20-%20train.csv), \n",
        "[OpticalInspection](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/optical_inspection/optical_inspection%20-%20train.csv), \n",
        "[Pointpillars](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pointpillars/pointpillars%20-%20train.csv), \n",
        "[PoseClassificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/pose_classification/pose_classification%20-%20train.csv), \n",
        "[ReIdentificationNet](https://github.com/NVIDIA/tao_front_end_services/tree/main/api/specs_utils/specs/re_identification/re_identification%20-%20train.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#  TAO: Prepare AutoML configuration for job creation\n",
        "automl_information = None\n",
        "\n",
        "if automl_enabled:\n",
        "    # Choose any metric that is present in the kpi dictionary present in the model's status.json. \n",
        "    # Example status.json for each model can be found in the respective section in NVIDIA TAO DOCS here: https://docs.nvidia.com/tao/tao-toolkit/text/model_zoo/cv_models/index.html\n",
        "    metric = \"kpi\"\n",
        "\n",
        "    # Refer to parameter list mentioned in the above links and add/remove any extra parameter in addition to the default enabled ones in automl_specs\n",
        "    automl_information = {\n",
        "        \"automl_enabled\": True,\n",
        "        \"automl_algorithm\": automl_algorithm,\n",
        "        \"automl_max_recommendations\": 20,  # Only for bayesian\n",
        "        \"automl_R\": 27,  # Only for hyperband\n",
        "        \"automl_nu\": 3,  # Only for hyperband\n",
        "        \"epoch_multiplier\": 1,  # Only for hyperband\n",
        "        # Warning: The parameters that are disabled are not tested by TAO, so there might be unexpected behaviour in overriding this\n",
        "        \"override_automl_disabled_params\": False,\n",
        "        \"automl_hyperparameters\": str(automl_params),\n",
        "        \"metric\": metric\n",
        "    }\n",
        "    \n",
        "    print(\"AutoML configuration prepared for job creation:\")\n",
        "    print(json.dumps(automl_information, sort_keys=True, indent=4))\n",
        "    print(\"This will be included in the job_run_experiment call\")\n",
        "else:\n",
        "    print(\"AutoML is disabled - training will use standard approach\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default train specs using TAO SDK\n",
        "train_spec_response = tao_client.get_job_schema(action=\"train\", network_arch=model_name)\n",
        "train_specs = train_spec_response.get(\"default\", {})\n",
        "print(\"Default train specifications:\")\n",
        "print(json.dumps(train_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes for any of the parameters listed in the previous cell as required\n",
        "train_specs[\"train\"][\"num_epochs\"] = 30\n",
        "train_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
        "train_specs[\"train\"][\"validation_interval\"] = 10\n",
        "train_specs[\"train\"][\"num_gpus\"] = 1\n",
        "if model_name == \"action_recognition\":\n",
        "    train_specs[\"model\"][\"model_type\"] = model_type\n",
        "    train_specs[\"model\"][\"input_type\"] = model_input_type\n",
        "    train_specs[\"dataset\"][\"batch_size\"] = 2\n",
        "    train_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
        "elif model_name == \"centerpose\":\n",
        "    train_specs[\"dataset\"][\"category\"] = \"bike\"\n",
        "    train_specs[\"dataset\"][\"batch_size\"] = 4\n",
        "elif model_name == \"ocdnet\":\n",
        "    train_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
        "elif model_name == \"ocrnet\":\n",
        "    train_specs[\"dataset\"][\"batch_size\"] = 16\n",
        "elif model_name == \"pose_classification\":\n",
        "    if model_type == \"nvidia\":\n",
        "        train_specs[\"dataset\"][\"num_classes\"] = 6\n",
        "        train_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
        "        train_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
        "    elif model_type == \"kinetics\":\n",
        "        train_specs[\"dataset\"][\"num_classes\"] = 5\n",
        "        train_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
        "        train_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
        "elif model_name == \"re_identification\":\n",
        "    train_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
        "    train_specs[\"dataset\"][\"num_workers\"] = 4 #Modify the num_workers according to your hardware setup\n",
        "    train_specs[\"dataset\"][\"batch_size\"] = 16 #Modify the batch_size according to your hardware setup\n",
        "elif model_name == \"sparse4d\":\n",
        "    train_specs[\"dataset\"][\"sequences\"][\"split_num\"] = 90\n",
        "    train_specs[\"dataset\"][\"train_dataset\"][\"sequences_split_num\"] = 90\n",
        "print(json.dumps(train_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create train job using SDK\n",
        "parent = job_map.get(\"eval_dataset_convert_\"+model_name, job_map.get(\"train_dataset_convert_\"+model_name, None))\n",
        "\n",
        "job_name = f\"{model_name}_training_job\"\n",
        "\n",
        "if not eval_dataset_id:\n",
        "    eval_dataset_id = train_dataset_id\n",
        "\n",
        "# Prepare job creation parameters\n",
        "job_params = {\n",
        "    \"kind\": \"experiment\",\n",
        "    \"name\": job_name,\n",
        "    \"network_arch\": model_name,\n",
        "    \"encryption_key\": encode_key,\n",
        "    \"parent_job_id\": parent,\n",
        "    \"workspace\": workspace_id,\n",
        "    \"action\": \"train\",\n",
        "    \"specs\": train_specs,  # Pass as dict, not JSON string\n",
        "    \"base_experiment_ids\": [selected_ptm_id] if selected_ptm_id else None,\n",
        "    \"train_datasets\": [train_dataset_id] if train_dataset_id else None,\n",
        "    \"eval_dataset\": eval_dataset_id,\n",
        "    \"inference_dataset\": test_dataset_id if test_dataset_id else None,\n",
        "    \"automl_settings\": automl_information if automl_information else None,\n",
        "    # \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "}\n",
        "\n",
        "# Create experiment job using TAO SDK interface\n",
        "job_id = tao_client.create_job(**job_params)\n",
        "\n",
        "print(\"Train job created successfully!\")\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Job Name: {job_name}\")\n",
        "print(f\"Network Architecture: {model_name}\")\n",
        "print(f\"Action: train\")\n",
        "if automl_information:\n",
        "    print(f\"AutoML: {automl_information.get('automl_algorithm', 'N/A')} algorithm\")\n",
        "\n",
        "job_map[\"train_\" + model_name] = job_id\n",
        "print(\"\\nJob Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Monitor job status using TAO SDK\n",
        "# For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
        "\n",
        "train_job_id = job_map[\"train_\" + model_name]\n",
        "\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(train_job_id)\n",
        "        \n",
        "        print(f\"Training Job Status\")\n",
        "        print(f\"Job ID: {train_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Training job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\" Job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## To Stop an AutoML JOB\n",
        "#    1. Stop the 'Monitor job status by repeatedly running this cell' cell (the cell right before this cell) manually\n",
        "#    2. Uncomment the snippet in the next cell and run the cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # Pause AutoML job using TAO SDK\n",
        "# if automl_enabled:\n",
        "#     train_job_id = job_map[\"train_\" + model_name]\n",
        "#     try:\n",
        "#         pause_result = tao_client.pause_job(train_job_id)\n",
        "#         print(\"Job paused successfully!\")\n",
        "#         print(json.dumps(pause_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to pause job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "## Resume AutoML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # Resume AutoML job using TAO SDK\n",
        "# # Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status' cell above\n",
        "# if automl_enabled:\n",
        "#     train_job_id = job_map[\"train_\" + model_name]\n",
        "#     try:\n",
        "#         resume_result = tao_client.resume_job(\n",
        "#             job_id=train_job_id,\n",
        "#             parent_job_id=None,\n",
        "#             specs=json.dumps(train_specs)\n",
        "#         )\n",
        "#         print(\"Job resumed successfully!\")\n",
        "#         print(json.dumps(resume_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to resume job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Publish model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Edit the method of choosing checkpoint from list of train checkpoint files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model handler parameters are managed differently\n",
        "# Checkpoint selection is handled during job creation rather than experiment-level settings\n",
        "# For now, we'll use the default checkpoint selection method\n",
        "print(\"In TAO, checkpoint selection is managed per-job rather than per-experiment\")\n",
        "print(\"Using default checkpoint selection method: best_model\")\n",
        "\n",
        "update_checkpoint_choosing = {\n",
        "    \"checkpoint_choose_method\": \"best_model\",\n",
        "    \"checkpoint_epoch_number\": {}\n",
        "}\n",
        "print(\"Current checkpoint choosing configuration:\")\n",
        "print(json.dumps(update_checkpoint_choosing, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint method configuration\n",
        "# Checkpoint selection is handled per-job, not per-experiment\n",
        "# You can configure this when creating export/inference jobs if needed\n",
        "\n",
        "# Example: Change checkpoint selection method for future jobs\n",
        "update_checkpoint_choosing[\"checkpoint_choose_method\"] = \"latest_model\"  # Choose between best_model/latest_model/from_epoch_number\n",
        "# Note: If from_epoch_number is chosen, you would specify the epoch in job creation specs\n",
        "\n",
        "print(\"Checkpoint selection configuration updated:\")\n",
        "print(f\"Method: {update_checkpoint_choosing['checkpoint_choose_method']}\")\n",
        "print(\"This will be applied to future job creations\")\n",
        "print(json.dumps(update_checkpoint_choosing, sort_keys=True, indent=4))\n",
        "\n",
        "updated_job = tao_client.update_job(job_id=job_map[\"train_\" + model_name], update_data=update_checkpoint_choosing)\n",
        "print(json.dumps(updated_job, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Push model to private ngc team registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Publish model using TAO SDK\n",
        "train_job_id = job_map[\"train_\" + model_name]\n",
        "\n",
        "try:\n",
        "    publish_result = tao_client.publish_model(\n",
        "        job_id=train_job_id,\n",
        "        display_name=f\"TAO {model_name}\",\n",
        "        description=f\"Trained {model_name} model\",\n",
        "        team_name=\"tao\"\n",
        "    )\n",
        "    \n",
        "    print(\"Model published successfully to NGC!\")\n",
        "    print(f\"Job ID: {train_job_id}\")\n",
        "    print(f\"Display Name: TAO {model_name}\")\n",
        "    print(f\"Team: tao\")\n",
        "    print(\"\\nPublish Response:\")\n",
        "    print(json.dumps(publish_result, indent=4))\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\" Failed to publish model: {str(e)}\")\n",
        "    print(\"Make sure the job completed successfully and you have appropriate permissions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Remove model from private ngc team registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Remove published model using TAO SDK\n",
        "# train_job_id = job_map[\"train_\" + model_name]\n",
        "# try:\n",
        "#     remove_result = tao_client.remove_published_model(\n",
        "#         job_id=train_job_id,\n",
        "#         team=\"tao\"\n",
        "#     )\n",
        "#     print(\"Published model removed successfully!\")\n",
        "#     print(json.dumps(remove_result, indent=4))\n",
        "# except Exception as e:\n",
        "#     print(f\" Failed to remove published model: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate <a class=\"anchor\" id=\"head-17\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default eval specs using TAO SDK\n",
        "eval_spec_response = tao_client.get_job_schema(action=\"evaluate\", network_arch=model_name)\n",
        "eval_specs = eval_spec_response.get(\"default\", {})\n",
        "print(\"Default evaluate specifications:\")\n",
        "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes\n",
        "if model_name == \"action_recognition\":\n",
        "    eval_specs[\"model\"][\"model_type\"] = model_type\n",
        "    eval_specs[\"model\"][\"input_type\"] = model_input_type\n",
        "    eval_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
        "elif model_name == \"pose_classification\":\n",
        "    if model_type == \"nvidia\":\n",
        "        eval_specs[\"dataset\"][\"num_classes\"] = 6\n",
        "        eval_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
        "        eval_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
        "    elif model_type == \"kinetics\":\n",
        "        eval_specs[\"dataset\"][\"num_classes\"] = 5\n",
        "        eval_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
        "        eval_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
        "elif model_name == \"re_identification\":\n",
        "    eval_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
        "elif model_name == \"visual_changenet_classify\":\n",
        "    eval_specs[\"train\"][\"classify\"][\"loss\"] = \"contrastive\"\n",
        "elif model_name == \"centerpose\":\n",
        "    eval_specs[\"dataset\"][\"category\"] = \"bike\"\n",
        "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create evaluate job using TAO SDK\n",
        "parent_job_id = job_map[\"train_\" + model_name]\n",
        "eval_job_name = f\"{model_name}_eval_job\"\n",
        "\n",
        "eval_job_id = tao_client.create_job(\n",
        "    kind=\"experiment\",\n",
        "    name=eval_job_name,\n",
        "    network_arch=model_name,\n",
        "    encryption_key=encode_key,\n",
        "    workspace=workspace_id,\n",
        "    train_datasets=[train_dataset_id],\n",
        "    eval_dataset=eval_dataset_id,\n",
        "    inference_dataset=test_dataset_id,\n",
        "    action=\"evaluate\",\n",
        "    specs=eval_specs,  # Pass as dict, not JSON string\n",
        "    parent_job_id=parent_job_id,\n",
        "    base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "    # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        ")\n",
        "\n",
        "print(\"Evaluate job created successfully!\")\n",
        "print(f\"Evaluate Job ID: {eval_job_id}\")\n",
        "print(f\"Parent Job ID: {parent_job_id}\")\n",
        "print(f\"Action: evaluate\")\n",
        "\n",
        "job_map[\"evaluate_\" + model_name] = eval_job_id\n",
        "print(\"\\nUpdated Job Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor evaluate job status using TAO SDK\n",
        "eval_job_id = job_map[\"evaluate_\" + model_name]\n",
        "\n",
        "while True:    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(eval_job_id)\n",
        "        \n",
        "        print(f\"Evaluate Job Status\")\n",
        "        print(f\"Job ID: {eval_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Evaluate job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Evaluate job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\"Evaluate job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching inference job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prune, Retrain and Evaluation <a class=\"anchor\" id=\"head-18\"></a>\n",
        "\n",
        "- We optimize the trained model by pruning and retraining in the following cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get default spec schema\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    prune_spec_response = tao_client.get_job_schema(action=\"prune\", network_arch=model_name)\n",
        "    prune_specs = prune_spec_response.get(\"default\", {})\n",
        "    print(\"Default prune specifications:\")\n",
        "    print(json.dumps(prune_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes\n",
        "# None for prune\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    print(json.dumps(prune_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run actions\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    parent_job_id = job_map[\"train_\" + model_name]\n",
        "    action = \"prune\"\n",
        "\n",
        "    prune_job_name = f\"{model_name}_prune_job\"\n",
        "\n",
        "    prune_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=prune_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        train_datasets=[train_dataset_id],\n",
        "        eval_dataset=eval_dataset_id,\n",
        "        action=\"prune\",\n",
        "        specs=prune_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Generate trt engine job created successfully!\")\n",
        "    print(f\"Prune Job ID: {prune_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: prune\")\n",
        "\n",
        "    job_map[\"prune_\" + model_name] = prune_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor job status using TAO SDK\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    prune_job_id = job_map[\"prune_\" + model_name]\n",
        "\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(prune_job_id)\n",
        "            \n",
        "            print(f\"Prune Job Status\")\n",
        "            print(f\"Job ID: {prune_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Prune job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\" Job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Retrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default spec schema\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    retrain_spec_response = tao_client.get_job_schema(action=\"retrain\", network_arch=model_name)\n",
        "    retrain_specs = retrain_spec_response.get(\"default\", {})\n",
        "    print(\"Default retrain specifications:\")\n",
        "    print(json.dumps(retrain_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes for any of the parameters listed in the previous cell as required\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    retrain_specs[\"train\"][\"num_epochs\"] = 30\n",
        "    retrain_specs[\"train\"][\"checkpoint_interval\"] = 10\n",
        "    retrain_specs[\"train\"][\"validation_interval\"] = 10\n",
        "    retrain_specs[\"train\"][\"num_gpus\"] = 1\n",
        "    if model_name == \"ocdnet\":\n",
        "        retrain_specs[\"dataset\"][\"train_dataset\"][\"loader\"][\"batch_size\"] = 16\n",
        "    elif model_name == \"ocrnet\":\n",
        "        retrain_specs[\"dataset\"][\"batch_size\"] = 16\n",
        "    print(json.dumps(retrain_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run actions\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    parent_job_id = job_map[\"prune_\" + model_name]\n",
        "    action = \"retrain\"\n",
        "\n",
        "    retrain_job_name = f\"{model_name}_retrain_job\"\n",
        "\n",
        "    retrain_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=retrain_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        train_datasets=[train_dataset_id],\n",
        "        eval_dataset=eval_dataset_id,\n",
        "        action=\"retrain\",\n",
        "        specs=retrain_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Retrain job created successfully!\")\n",
        "    print(f\"Retrain Job ID: {retrain_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: retrain\")\n",
        "\n",
        "    job_map[\"retrain_\" + model_name] = retrain_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor job status using TAO SDK\n",
        "\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    retrain_job_id = job_map[\"retrain_\" + model_name]\n",
        "\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(retrain_job_id)\n",
        "            \n",
        "            print(f\"Re-Training Job Status\")\n",
        "            print(f\"Job ID: {train_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Retrain job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\" Job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional cancel job - for jobs that are pending/running (retrain)\n",
        "\n",
        "# if model_name == \"pointpillars\":\n",
        "#     job_id = job_map[\"retrain_\" + model_name]\n",
        "#     try:\n",
        "#         pause_result = tao_client.cancel_job(job_id)\n",
        "#         print(\"Job paused successfully!\")\n",
        "#         print(json.dumps(pause_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to pause job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional delete job - for jobs that are error/done (retrain)\n",
        "\n",
        "# if model_name == \"pointpillars\":\n",
        "#     job_id = job_map[\"retrain_\" + model_name]\n",
        "#     try:\n",
        "#         resume_result = tao_client.resume_job(\n",
        "#             job_id=job_id,\n",
        "#             parent_job_id=None,\n",
        "#             specs=json.dumps(retrain_specs)\n",
        "#         )\n",
        "#         print(\"Job resumed successfully!\")\n",
        "#         print(json.dumps(resume_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to resume job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate after retrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get default spec schema\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    eval_retrain_spec_response = tao_client.get_job_schema(action=\"evaluate\", network_arch=model_name)\n",
        "    eval_retrain_specs = eval_retrain_spec_response.get(\"default\", {})\n",
        "    print(\"Default evaluate specifications:\")\n",
        "    print(json.dumps(eval_retrain_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply changes to specs if necessary\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    print(json.dumps(eval_retrain_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create evaluate job using TAO SDK\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    parent_job_id = job_map[\"retrain_\" + model_name]\n",
        "\n",
        "    eval_retrain_job_name = f\"{model_name}_eval_retrain_job\"\n",
        "\n",
        "    eval_retrain_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=eval_retrain_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        train_datasets=[train_dataset_id],\n",
        "        eval_dataset=eval_dataset_id,\n",
        "        action=\"evaluate\",\n",
        "        specs=eval_retrain_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Evaluate after retrain job created successfully!\")\n",
        "    print(f\"Evaluate after retrain Job ID: {eval_retrain_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: evaluate\")\n",
        "\n",
        "    job_map[\"eval_retrain_\" + model_name] = eval_retrain_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor job status using TAO SDK\n",
        "# For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
        "\n",
        "if model_name in PRUNEABLE_MODELS:\n",
        "    eval_retrain_job_id = job_map[\"eval_retrain_\" + model_name]\n",
        "\n",
        "    while True:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(eval_retrain_job_id)\n",
        "            \n",
        "            print(f\"Evaluate after retrain Job Status\")\n",
        "            print(f\"Job ID: {eval_retrain_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Evaluate after retrain job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\" Job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export <a class=\"anchor\" id=\"head-19\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if model_name not in UN_EXPORTABLE_MODELS:\n",
        "    # Get default export specs using TAO SDK\n",
        "    export_spec_response = tao_client.get_job_schema(action=\"export\", network_arch=model_name)\n",
        "    export_specs = export_spec_response.get(\"default\", {})\n",
        "    print(\"Default export specifications:\")\n",
        "    print(json.dumps(export_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to the export_specs dictionary if necessary\n",
        "if model_name == \"action_recognition\":\n",
        "    export_specs[\"model\"][\"model_type\"] = model_type\n",
        "    export_specs[\"model\"][\"input_type\"] = model_input_type\n",
        "    export_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
        "elif model_name == \"pose_classification\":\n",
        "    if model_type == \"nvidia\":\n",
        "        export_specs[\"dataset\"][\"num_classes\"] = 6\n",
        "        export_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
        "        export_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
        "    elif model_type == \"kinetics\":\n",
        "        export_specs[\"dataset\"][\"num_classes\"] = 5\n",
        "        export_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
        "        export_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
        "elif model_name == \"re_identification\":\n",
        "    export_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
        "elif model_name == \"visual_changenet_segment\":\n",
        "    export_specs[\"export\"][\"input_height\"] = 224 \n",
        "    export_specs[\"export\"][\"input_width\"] = 224\n",
        "elif model_name == \"visual_changenet_classify\":\n",
        "    export_specs[\"export\"][\"input_height\"] = 896 \n",
        "    export_specs[\"export\"][\"input_width\"] = 224\n",
        "if model_name not in UN_EXPORTABLE_MODELS:\n",
        "    print(json.dumps(export_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create export job using TAO SDK\n",
        "if model_name not in UN_EXPORTABLE_MODELS:\n",
        "    parent_job_id = job_map[\"train_\" + model_name]\n",
        "    export_job_name = f\"{model_name}_export_job\"\n",
        "\n",
        "    export_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=export_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        train_datasets=[train_dataset_id],\n",
        "        eval_dataset=eval_dataset_id,\n",
        "        inference_dataset=test_dataset_id,\n",
        "        action=\"export\",\n",
        "        specs=export_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Export job created successfully!\")\n",
        "    print(f\"Export Job ID: {export_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: export\")\n",
        "\n",
        "    job_map[\"export_\" + model_name] = export_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor export job status using TAO SDK\n",
        "if model_name not in UN_EXPORTABLE_MODELS:\n",
        "    export_job_id = job_map[\"export_\" + model_name]\n",
        "\n",
        "    while True:    \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(export_job_id)\n",
        "            \n",
        "            print(f\"Export Job Status\")\n",
        "            print(f\"Job ID: {export_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Export job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Export job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\" Export job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching export job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TRT Engine generation using TAO-Deploy <a class=\"anchor\" id=\"head-20\"></a>\n",
        "\n",
        "- Here, we use the exported model to convert to target platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Get default generate trt engine specs using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    tao_deploy_spec_response = tao_client.get_job_schema(action=\"gen_trt_engine\", network_arch=model_name)\n",
        "    tao_deploy_specs = tao_deploy_spec_response.get(\"default\", {})\n",
        "    print(\"Default trt engine specifications:\")\n",
        "    print(json.dumps(tao_deploy_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    if model_name in (\"ml_recog\", \"ocdnet\"):\n",
        "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"INT8\"\n",
        "    elif model_name in (\"ocrnet\", \"optical_inspection\"):\n",
        "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
        "    elif model_name == \"visual_changenet_segment\":\n",
        "        tao_deploy_specs[\"gen_trt_engine\"][\"tensorrt\"][\"data_type\"] = \"fp16\"\n",
        "    print(json.dumps(tao_deploy_specs, sort_keys=True, indent=4))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create generate trt engine job using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    parent_job_id = job_map[\"export_\" + model_name]\n",
        "    gen_trt_engine_job_name = f\"{model_name}_gen_trt_engine_job\"\n",
        "\n",
        "    gen_trt_engine_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=gen_trt_engine_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        calibration_dataset=train_dataset_id,\n",
        "        action=\"gen_trt_engine\",\n",
        "        specs=tao_deploy_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"Generate trt engine job created successfully!\")\n",
        "    print(f\"Generate trt engine Job ID: {gen_trt_engine_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: gen_trt_engine\")\n",
        "\n",
        "    job_map[\"gen_trt_engine_\" + model_name] = gen_trt_engine_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor gen_trt_engine job status using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    gen_trt_engine_job_id = job_map[\"gen_trt_engine_\" + model_name]\n",
        "\n",
        "    while True:    \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(gen_trt_engine_job_id)\n",
        "            \n",
        "            print(f\"Generate trt engine Job Status\")\n",
        "            print(f\"Job ID: {gen_trt_engine_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"Generate trt engine job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"Generate trt engine job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\"Generate trt engine job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\"Error fetching gen_trt_engine job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TAO inference <a class=\"anchor\" id=\"head-21\"></a>\n",
        "\n",
        "- Run inference on a set of images using the .tlt model created at train step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default inference specs using TAO SDK\n",
        "inference_spec_response = tao_client.get_job_schema(action=\"inference\", network_arch=model_name)\n",
        "tao_inference_specs = inference_spec_response.get(\"default\", {})\n",
        "print(\"Default inference specifications:\")\n",
        "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to the tao_inference_specs dictionary if necessary\n",
        "if model_name == \"action_recognition\":\n",
        "    tao_inference_specs[\"model\"][\"model_type\"] = model_type\n",
        "    tao_inference_specs[\"model\"][\"input_type\"] = model_input_type\n",
        "    tao_inference_specs[\"dataset\"][\"label_map\"] = {\"catch\": 0, \"smile\": 1}\n",
        "elif model_name == \"pose_classification\":\n",
        "    if model_type == \"nvidia\":\n",
        "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 6\n",
        "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"nvidia\"\n",
        "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"sitting_down\": 0,\"getting_up\": 1,\"sitting\": 2,\"standing\": 3,\"walking\": 4,\"jumping\": 5}\n",
        "    elif model_type == \"kinetics\":\n",
        "        tao_inference_specs[\"dataset\"][\"num_classes\"] = 5\n",
        "        tao_inference_specs[\"model\"][\"graph_layout\"] = \"openpose\"\n",
        "        tao_inference_specs[\"dataset\"][\"label_map\"] = {\"front_raises\": 0,\"pull_ups\": 1,\"clean_and_jerk\": 2,\"presenting_weather_forecast\": 3,\"deadlifting\": 4}\n",
        "elif model_name == \"re_identification\":\n",
        "    tao_inference_specs[\"dataset\"][\"num_classes\"] = 100 #The number set in obtain_subset script\n",
        "elif model_name == 'visual_changenet_classify':\n",
        "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"classify\"]['batch_size'] \n",
        "elif model_name == 'visual_changenet_segment':\n",
        "    tao_inference_specs[\"inference\"][\"batch_size\"] = tao_inference_specs[\"dataset\"][\"segment\"]['batch_size'] \n",
        "elif model_name == \"centerpose\":\n",
        "    tao_inference_specs[\"dataset\"][\"category\"] = \"bike\"\n",
        "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create inference job using TAO SDK\n",
        "parent_job_id = job_map[\"train_\" + model_name]\n",
        "inference_job_name = f\"{model_name}_inference_job\"\n",
        "\n",
        "inference_dataset = test_dataset_id\n",
        "if not inference_dataset:\n",
        "    inference_dataset = eval_dataset_id\n",
        "if not inference_dataset:\n",
        "    inference_dataset = train_dataset_id\n",
        "\n",
        "inference_job_id = tao_client.create_job(\n",
        "    kind=\"experiment\",\n",
        "    name=inference_job_name,\n",
        "    network_arch=model_name,\n",
        "    encryption_key=encode_key,\n",
        "    workspace=workspace_id,\n",
        "    train_datasets=[train_dataset_id],\n",
        "    eval_dataset=eval_dataset_id,\n",
        "    inference_dataset=inference_dataset,\n",
        "    action=\"inference\",\n",
        "    specs=tao_inference_specs,  # Pass as dict, not JSON string\n",
        "    parent_job_id=parent_job_id,\n",
        "    base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "    # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        ")\n",
        "\n",
        "print(\"Inference job created successfully!\")\n",
        "print(f\"Inference Job ID: {inference_job_id}\")\n",
        "print(f\"Parent Job ID: {parent_job_id}\")\n",
        "print(f\"Action: inference\")\n",
        "\n",
        "job_map[\"inference_tao_\" + model_name] = inference_job_id\n",
        "print(\"\\nUpdated Job Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor inference job status using TAO SDK\n",
        "inference_job_id = job_map[\"inference_tao_\" + model_name]\n",
        "\n",
        "while True:    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(inference_job_id)\n",
        "        \n",
        "        print(f\" Inference Job Status\")\n",
        "        print(f\"Job ID: {inference_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Inference job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Inference job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\" Inference job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching inference job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TRT inference <a class=\"anchor\" id=\"head-22\"></a>\n",
        "\n",
        "- no need to change the specs since we already uploaded it at the tlt inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default trt inference specs using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    trt_inference_spec_response = tao_client.get_job_schema(action=\"inference\", network_arch=model_name)\n",
        "    trt_inference_specs = trt_inference_spec_response.get(\"default\", {})\n",
        "    print(\"Default trt inference specifications:\")\n",
        "    print(json.dumps(trt_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to the specs dictionary if necessary\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    if model_name == \"visual_changenet_classify\":\n",
        "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"classify\"]['batch_size']\n",
        "    elif model_name == \"visual_changenet_segment\":\n",
        "        trt_inference_specs[\"inference\"][\"batch_size\"] = trt_inference_specs[\"dataset\"][\"segment\"]['batch_size']\n",
        "    print(json.dumps(trt_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create trt inference job using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    inference_dataset = test_dataset_id\n",
        "    if not inference_dataset:\n",
        "        inference_dataset = eval_dataset_id\n",
        "    if not inference_dataset:\n",
        "        inference_dataset = train_dataset_id\n",
        "\n",
        "    parent_job_id = job_map[\"gen_trt_engine_\" + model_name]\n",
        "    trt_inference_job_name = f\"{model_name}_trt_inference_job\"\n",
        "\n",
        "    trt_inference_job_id = tao_client.create_job(\n",
        "        kind=\"experiment\",\n",
        "        name=trt_inference_job_name,\n",
        "        network_arch=model_name,\n",
        "        encryption_key=encode_key,\n",
        "        workspace=workspace_id,\n",
        "        train_datasets=[train_dataset_id],\n",
        "        eval_dataset=eval_dataset_id,\n",
        "        inference_dataset=inference_dataset,\n",
        "        action=\"inference\",\n",
        "        specs=trt_inference_specs,  # Pass as dict, not JSON string\n",
        "        parent_job_id=parent_job_id,\n",
        "        base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "        # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "    )\n",
        "\n",
        "    print(\"TRT Inference job created successfully!\")\n",
        "    print(f\"TRT Inference Job ID: {trt_inference_job_id}\")\n",
        "    print(f\"Parent Job ID: {parent_job_id}\")\n",
        "    print(f\"Action: inference\")\n",
        "\n",
        "    job_map[\"trt_inference_\" + model_name] = trt_inference_job_id\n",
        "    print(\"\\nUpdated Job Map:\")\n",
        "    print(json.dumps(job_map, indent=4))\n",
        "    %store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor trt inference job status using TAO SDK\n",
        "if model_name in TAO_DEPLOY_MODELS:\n",
        "    trt_inference_job_id = job_map[\"trt_inference_\" + model_name]\n",
        "\n",
        "    while True:    \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        try:\n",
        "            job_status = tao_client.get_job_metadata(trt_inference_job_id)\n",
        "            \n",
        "            print(f\"TRT Inference Job Status\")\n",
        "            print(f\"Job ID: {trt_inference_job_id}\")\n",
        "            print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "            print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "            \n",
        "            # Show detailed status information\n",
        "            print(\"\\nDetailed Status:\")\n",
        "            print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "            \n",
        "            current_status = job_status.get(\"status\", \"Unknown\")\n",
        "            \n",
        "            if current_status == \"Error\":\n",
        "                raise Exception(\"TRT Inference job failed!\")\n",
        "                \n",
        "            if current_status in [\"Done\", \"Completed\"]:\n",
        "                print(\"TRT Inference job completed successfully!\")\n",
        "                break\n",
        "                \n",
        "            if current_status in [\"Canceled\", \"Paused\"]:\n",
        "                print(f\"TRT Inference job {current_status}\")\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            if \"failed\" in str(e).lower():\n",
        "                raise\n",
        "            print(f\" Error fetching  job status: {str(e)}\")\n",
        "            print(\"Job might still be starting up...\")\n",
        "            \n",
        "        time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete Jobs<a class=\"anchor\" id=\"head-22\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete jobs instead of experiments\n",
        "# Delete all created jobs using TAO SDK\n",
        "\n",
        "print(\" Deleting all created jobs...\")\n",
        "\n",
        "jobs_to_delete = []\n",
        "for job_key, job_id in job_map.items():\n",
        "    try:\n",
        "        delete_result = tao_client.delete_job(job_id)\n",
        "        print(f\" Deleted job: {job_key} (ID: {job_id})\")\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to delete job {job_key} (ID: {job_id}): {str(e)}\")\n",
        "\n",
        "print(f\"\\n Job cleanup completed! Processed {len(jobs_to_delete)} jobs.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete dataset <a class=\"anchor\" id=\"head-24\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Delete train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete train dataset using TAO SDK\n",
        "try:\n",
        "    delete_result = tao_client.delete_dataset(train_dataset_id)\n",
        "    print(\"Train dataset deleted successfully!\")\n",
        "    print(f\"Dataset ID: {train_dataset_id}\")\n",
        "    if delete_result:\n",
        "        print(\"Delete Response:\")\n",
        "        print(json.dumps(delete_result, indent=4))\n",
        "except Exception as e:\n",
        "    print(f\" Failed to delete train dataset {train_dataset_id}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Delete val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete eval dataset using TAO SDK\n",
        "if model_name in EXPLICIT_EVAL_DATASET_MODELS:\n",
        "    try:\n",
        "        delete_result = tao_client.delete_dataset(eval_dataset_id)\n",
        "        print(\"Eval dataset deleted successfully!\")\n",
        "        print(f\"Dataset ID: {eval_dataset_id}\")\n",
        "        if delete_result:\n",
        "            print(\"Delete Response:\")\n",
        "            print(json.dumps(delete_result, indent=4))\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to delete eval dataset {eval_dataset_id}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Delete test dataset <a class=\"anchor\" id=\"head-21\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete test dataset using TAO SDK\n",
        "if model_name in (\"optical_inspection\"):\n",
        "    try:\n",
        "        delete_result = tao_client.delete_dataset(test_dataset_id)\n",
        "        print(\"Test dataset deleted successfully!\")\n",
        "        print(f\"Dataset ID: {test_dataset_id}\")\n",
        "        if delete_result:\n",
        "            print(\"Delete Response:\")\n",
        "            print(json.dumps(delete_result, indent=4))\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to delete test dataset {test_dataset_id}: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
