{
  "cells": [
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Notebook to demonstrate Auto-Labeling workflow\n",
        "\n",
        "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
        "\n",
        "![image](https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png)\n",
        "\n",
        "\n",
        "### The workflow in a nutshell\n",
        "\n",
        "- Pulling datasets from cloud\n",
        "- Getting a PTM from NGC\n",
        "- Model Actions\n",
        "    - Train (Normal/AutoML)\n",
        "    - Evaluate\n",
        "    - Inference\n",
        "    - Delete experiments/datasets\n",
        "\n",
        "### Table of contents\n",
        "\n",
        "1. [FIXME's](#head-1)\n",
        "1. [Login](#head-2)\n",
        "1. [Create a cloud workspace](#head-2)\n",
        "1. [Create and pull train dataset](#head-3)\n",
        "1. [Create and pull val dataset](#head-4)\n",
        "1. [List the created datasets](#head-5)\n",
        "1. [Create an experiment](#head-6)\n",
        "1. [List experiments](#head-7)\n",
        "1. [Assign train, eval datasets](#head-8)\n",
        "1. [Assign PTM](#head-9)\n",
        "1. [View hyperparameters that are enabled by default](#head-10)\n",
        "1. [Actions](#head-11)\n",
        "1. [Train](#head-12)\n",
        "1. [Set AutoML related configurations](#head-12.1)\n",
        "1. [Evaluate](#head-13)\n",
        "1. [TAO inference](#head-14)\n",
        "1. [Delete experiment](#head-15)\n",
        "1. [Delete dataset](#head-16)\n",
        "\n",
        "### Requirements\n",
        "Please find the server requirements [here](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_setup.html#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Import TAO SDK\n",
        "from tao_sdk.client import TaoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Restore variable in case of jupyter session restart and resume execution where it left off\n",
        "%store -r model_name\n",
        "%store -r base_url\n",
        "%store -r headers\n",
        "%store -r workspace_id\n",
        "%store -r train_dataset_id\n",
        "%store -r eval_dataset_id\n",
        "%store -r experiment_id\n",
        "%store -r job_map"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### To see the dataset folder structure required for the models supported in this notebook, visit the notebooks under dataset_prepare like for [this notebook](../dataset_prepare/auto_labeling.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### FIXME's <a class=\"anchor\" id=\"head-1\"></a>\n",
        "\n",
        "1. (Optional) Enable AutoML if needed in FIXME 1\n",
        "1. (Optional) Choose between bayesian and hyperband automl_algorithm in FIXME 2 (If automl was enabled in FIXME1)\n",
        "1. Assign the ip_address and port_number in FIXME 3 ([info](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_api/api_rest_api.html))\n",
        "1. Assign the ngc_key variable in FIXME 4\n",
        "1. Assign the ngc_org_name variable in FIXME 5\n",
        "1. Set cloud storage details in FIXME 6\n",
        "1. Assign path of datasets relative to the bucket in FIXME 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"TAO_MODEL_NAME\"] = model_name = os.environ.get(\"TAO_MODEL_NAME\", \"mal\")\n",
        "%store model_name"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Set API service's host information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 4: Set TAO API environment variables\n",
        "\n",
        "# Set to your TAO API endpoint\n",
        "os.environ[\"TAO_BASE_URL\"] = os.environ.get(\"TAO_BASE_URL\", \"https://your_tao_ip_address:port/api/v2\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Set NGC Personal key for authentication and NGC org to access API services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 5: Your NGC personal key\n",
        "os.environ[\"NGC_KEY\"] = ngc_key = os.environ.get(\"NGC_KEY\", \"your_ngc_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 6: Your NGC ORG name\n",
        "os.environ[\"NGC_ORG\"] = ngc_org_name = os.environ.get(\"NGC_ORG\", \"nvstaging\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Login <a class=\"anchor\" id=\"head-2\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize TAO Client and login using SDK\n",
        "tao_client = TaoClient()\n",
        "\n",
        "# Login using TAO SDK - this will automatically save credentials to environment variables\n",
        "login_response = tao_client.login(\n",
        "    ngc_key=ngc_key,\n",
        "    ngc_org_name=ngc_org_name,\n",
        "    enable_telemetry=True\n",
        ")\n",
        "\n",
        "print(\"Login successful!\")\n",
        "print(\"JWT Token:\", tao_client.token)\n",
        "print(\"API Base URL:\", tao_client.base_url)\n",
        "print(\"Organization:\", tao_client.org_name)\n",
        "\n",
        "%store tao_client"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Get NVCF gpu details <a class=\"anchor\" id=\"head-2\"></a>\n",
        "\n",
        " One of the keys of the response json are to be used as platform_id when you run each job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# # Valid only for NVCF backend during TAO-API helm deployment currently\n",
        "# # Get available GPU types using TAO SDK\n",
        "# try:\n",
        "#     gpu_types = tao_client.get_gpu_types()\n",
        "#     print(\"Available GPU types:\")\n",
        "#     print(json.dumps(gpu_types, indent=4))\n",
        "# except Exception as e:\n",
        "#     print(\"Could not fetch GPU types (may not be available on this deployment):\", str(e))"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Create cloud workspace\n",
        "This workspace will be the place where your datasets reside and your results of TAO API jobs will be pushed to.\n",
        "\n",
        "If you want to have different workspaces for dataset and experiment, duplocate the workspace creation part and adjust the metadata accordingly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 7: Dataset Cloud bucket details to download dataset or push job artifacts for jobs\n",
        "\n",
        "cloud_metadata = {}\n",
        "\n",
        "# A Representative name for this cloud info\n",
        "os.environ[\"TAO_WORKSPACE_NAME\"] = cloud_metadata[\"name\"] = os.environ.get(\"TAO_WORKSPACE_NAME\", \"AWS workspace info\")\n",
        "\n",
        "# Cloud specific details. Below is assuming AWS.\n",
        "cloud_metadata[\"cloud_specific_details\"] = {}\n",
        "\n",
        " # Whether it is AWS, HuggingFace or Azure\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_TYPE\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_TYPE\", \"aws\")\n",
        "\n",
        "# Bucket region\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_REGION\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_region\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_REGION\", \"us-west-1\")\n",
        "\n",
        "# Bucket name\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\"] = cloud_metadata[\"cloud_specific_details\"][\"cloud_bucket_name\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_BUCKET_NAME\", \"bucket_name\")\n",
        "\n",
        "# Access and Secret keys\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"access_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_ACCESS_KEY\", \"access_key\")\n",
        "os.environ[\"TAO_WORKSPACE_CLOUD_SECRET_KEY\"] = cloud_metadata[\"cloud_specific_details\"][\"secret_key\"] = os.environ.get(\"TAO_WORKSPACE_CLOUD_SECRET_KEY\", \"secret_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Create cloud workspace using TAO SDK\n",
        "workspace_id = tao_client.create_workspace(\n",
        "    name=cloud_metadata[\"name\"],\n",
        "    cloud_type=cloud_metadata[\"cloud_specific_details\"][\"cloud_type\"],\n",
        "    cloud_specific_details=cloud_metadata[\"cloud_specific_details\"]\n",
        ")\n",
        "\n",
        "print(\"Workspace created successfully!\")\n",
        "print(f\"Workspace ID: {workspace_id}\")\n",
        "\n",
        "# Get workspace details to confirm creation\n",
        "workspace_details = tao_client.get_workspace_metadata(workspace_id)\n",
        "print(\"Workspace details:\")\n",
        "print(json.dumps(workspace_details, indent=4))\n",
        "\n",
        "%store workspace_id"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Set dataset path (path within cloud bucket)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# FIXME 7 : Set paths relative to cloud bucket\n",
        "os.environ[\"TAO_TRAIN_DATASET_PATH\"] = train_dataset_path = os.environ.get(\"TAO_TRAIN_DATASET_PATH\", \"/data/auto_label_train\")\n",
        "os.environ[\"TAO_EVAL_DATASET_PATH\"] = eval_dataset_path = os.environ.get(\"TAO_EVAL_DATASET_PATH\", \"/data/auto_label_val\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Create and pull train dataset <a class=\"anchor\" id=\"head-3\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create train dataset\n",
        "ds_type = \"segmentation\"\n",
        "ds_format = \"default\"\n",
        "\n",
        "# Create train dataset using TAO SDK\n",
        "train_dataset_id = tao_client.create_dataset(\n",
        "    dataset_type=ds_type,\n",
        "    dataset_format=ds_format,\n",
        "    workspace_id=workspace_id,\n",
        "    cloud_file_path=train_dataset_path,\n",
        "    use_for=[\"training\"]\n",
        ")\n",
        "\n",
        "print(\"Train dataset created successfully!\")\n",
        "print(f\"Train Dataset ID: {train_dataset_id}\")\n",
        "\n",
        "%store train_dataset_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Check train dataset progress using TAO SDK\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    dataset_details = tao_client.get_dataset_metadata(train_dataset_id)\n",
        "    \n",
        "    print(f\" Train Dataset Status: {dataset_details.get('status', 'Unknown')}\")\n",
        "    print(f\"Dataset ID: {train_dataset_id}\")\n",
        "    \n",
        "    if dataset_details.get(\"status\") == \"invalid_pull\":\n",
        "        print(\"Dataset pull failed!\")\n",
        "        validation_details = dataset_details.get(\"validation_details\", {})\n",
        "        if validation_details:\n",
        "            print(\"Validation details:\")\n",
        "            print(json.dumps(validation_details, indent=4))\n",
        "        raise ValueError(\"Dataset pull failed\")\n",
        "        \n",
        "    if dataset_details.get(\"status\") == \"pull_complete\":\n",
        "        print(\"Train dataset pull completed successfully!\")\n",
        "        print(\"Dataset details:\")\n",
        "        print(json.dumps(dataset_details, indent=4))\n",
        "        break\n",
        "        \n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Uncomment if you want to remove corrupted images in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# # This packages data-services experiments create and running the job of removing corrupted images\n",
        "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "# try:\n",
        "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "#     train_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, train_dataset_id)\n",
        "#     %store train_dataset_id\n",
        "# except Exception as e:\n",
        "#     raise e"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Create and pull val dataset <a class=\"anchor\" id=\"head-4\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Create eval dataset using TAO SDK\n",
        "eval_dataset_id = tao_client.create_dataset(\n",
        "    dataset_type=ds_type,\n",
        "    dataset_format=ds_format,\n",
        "    workspace_id=workspace_id,\n",
        "    cloud_file_path=eval_dataset_path,\n",
        "    use_for=[\"evaluation\"]\n",
        ")\n",
        "\n",
        "print(\"Eval dataset created successfully!\")\n",
        "print(f\"Eval Dataset ID: {eval_dataset_id}\")\n",
        "\n",
        "%store eval_dataset_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Check eval dataset progress using TAO SDK\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    dataset_details = tao_client.get_dataset_metadata(eval_dataset_id)\n",
        "    \n",
        "    print(f\" Eval Dataset Status: {dataset_details.get('status', 'Unknown')}\")\n",
        "    print(f\"Dataset ID: {eval_dataset_id}\")\n",
        "    \n",
        "    if dataset_details.get(\"status\") == \"invalid_pull\":\n",
        "        print(\"Dataset pull failed!\")\n",
        "        validation_details = dataset_details.get(\"validation_details\", {})\n",
        "        if validation_details:\n",
        "            print(\"Validation details:\")\n",
        "            print(json.dumps(validation_details, indent=4))\n",
        "        raise ValueError(\"Dataset pull failed\")\n",
        "        \n",
        "    if dataset_details.get(\"status\") == \"pull_complete\":\n",
        "        print(\"Eval dataset pull completed successfully!\")\n",
        "        print(\"Dataset details:\")\n",
        "        print(json.dumps(dataset_details, indent=4))\n",
        "        break\n",
        "        \n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Uncomment if you want to remove corrupted images in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# # This packages data-services experiments create and running the job of removing corrupted images\n",
        "# from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "# try:\n",
        "#     from remove_corrupted_images import remove_corrupted_images_workflow\n",
        "#     eval_dataset_id = remove_corrupted_images_workflow(base_url, headers, workspace_id, eval_dataset_id)\n",
        "#     %store eval_dataset_id\n",
        "# except Exception as e:\n",
        "#     raise e"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### List the created datasets <a class=\"anchor\" id=\"head-5\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# List datasets using TAO SDK\n",
        "datasets = tao_client.list_datasets()\n",
        "\n",
        "print(\"Available datasets:\")\n",
        "print(\"id\\t\\t\\t\\t\\t type\\t\\t\\t format\\t\\t name\")\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for dataset in datasets:\n",
        "    dataset_id = dataset.get(\"id\", \"N/A\")\n",
        "    dataset_type = dataset.get(\"type\", \"N/A\")\n",
        "    dataset_format = dataset.get(\"format\", \"N/A\")\n",
        "    dataset_name = dataset.get(\"name\", \"N/A\")\n",
        "    print(f\"{dataset_id}\\t{dataset_type}\\t{dataset_format}\\t\\t{dataset_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Set common params across all jobs <a class=\"anchor\" id=\"head-6\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# These parameters are common to all jobs and will be used when creating the actual job:\n",
        "encode_key = \"tlt_encode\""
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Assign PTM <a class=\"anchor\" id=\"head-9\"></a>\n",
        "\n",
        "Search for the PTM on NGC for the Segmentation model chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# List base experiments (PTMs) using TAO SDK  \n",
        "# These are the pre-trained models available for the selected network architecture\n",
        "base_experiments = tao_client.list_base_experiments(filter_params={\"network_arch\": model_name})\n",
        "\n",
        "print(f\" Available base experiments (PTMs) for {model_name}:\")\n",
        "print(\"name\\t\\t\\t     model id\\t\\t\\t     network architecture\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "for exp in base_experiments:\n",
        "    exp_name = exp.get(\"name\", \"N/A\")\n",
        "    exp_id = exp.get(\"id\", \"N/A\")\n",
        "    exp_arch = exp.get(\"network_arch\", \"N/A\")\n",
        "    print(f\"{exp_name}\\t{exp_id}\\t{exp_arch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Assigning pretrained models to different networks\n",
        "# From the output of previous cell make the appropriate changes to this map if you want to change the default PTM backbone.\n",
        "# Changing the default backbone here requires changing default spec/config during train/eval etc like for example\n",
        "# If you are changing the ptm to resnet34, then you have to modify the config key num_layers if it exists to 34 manually\n",
        "pretrained_map = {\"mal\" : \"mask_auto_label:trainable_v1.0\"}\n",
        "no_ptm_models = set([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Get pretrained model using TAO SDK\n",
        "selected_ptm_id = None\n",
        "if model_name not in no_ptm_models:\n",
        "    base_experiments_detailed = tao_client.list_base_experiments(filter_params={\"network_arch\": model_name})\n",
        "    \n",
        "    # Search for PTM with given NGC path\n",
        "    for exp in base_experiments_detailed:\n",
        "        ngc_path = exp.get(\"ngc_path\", \"\")\n",
        "        if ngc_path.endswith(pretrained_map[model_name]):\n",
        "            selected_ptm_id = exp.get(\"id\")\n",
        "            print(\"Selected PTM metadata:\")\n",
        "            print(json.dumps(exp, indent=4))\n",
        "            break\n",
        "    \n",
        "    if not selected_ptm_id:\n",
        "        print(f\" PTM with NGC path ending in '{pretrained_map[model_name]}' not found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#  TAO: PTM assignment happens during job creation\n",
        "# The selected PTM ID will be used in the job creation step\n",
        "if model_name not in no_ptm_models and selected_ptm_id:\n",
        "    print(f\" PTM ID {selected_ptm_id} will be used as base_experiment_id in job creation\")\n",
        "else:\n",
        "    print(\"No PTM will be used (training from scratch)\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Actions <a class=\"anchor\" id=\"head-11\"></a>\n",
        "\n",
        "For all actions:\n",
        "1. Get default spec schema and derive the default values\n",
        "1. Modify defaults if needed\n",
        "1. Run model action with modified specs\n",
        "1. Monitor job using retrieve\n",
        "1. Download results using job download endpoint (if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "job_map = {}"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Train <a class=\"anchor\" id=\"head-12\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default train specs using TAO SDK\n",
        "train_spec_response = tao_client.get_job_schema(action=\"train\", network_arch=model_name)\n",
        "train_specs = train_spec_response.get(\"default\", {})\n",
        "print(\"Default train specifications:\")\n",
        "print(json.dumps(train_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Override any of the parameters listed in the previous cell as required\n",
        "train_specs[\"train\"][\"num_gpus\"] = 1\n",
        "train_specs[\"train\"][\"gpu_ids\"] = [0]\n",
        "train_specs[\"train\"][\"num_epochs\"] = 5\n",
        "train_specs[\"train\"][\"checkpoint_interval\"] = 5\n",
        "train_specs[\"train\"][\"validation_interval\"] = 5\n",
        "print(json.dumps(train_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Create train job using SDK\n",
        "\n",
        "job_name = f\"{model_name}_training_job\"\n",
        "\n",
        "# Prepare job creation parameters\n",
        "job_params = {\n",
        "    \"kind\": \"experiment\",\n",
        "    \"name\": job_name,\n",
        "    \"network_arch\": model_name,\n",
        "    \"encryption_key\": encode_key,\n",
        "    \"workspace\": workspace_id,\n",
        "    \"action\": \"train\",\n",
        "    \"specs\": train_specs,  # Pass as dict, not JSON string\n",
        "    \"base_experiment_ids\": [selected_ptm_id] if selected_ptm_id else None,\n",
        "    \"train_datasets\": [train_dataset_id] if train_dataset_id else None,\n",
        "    \"eval_dataset\": eval_dataset_id,\n",
        "    # \"platform_id\": \"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        "}\n",
        "\n",
        "# Create experiment job using TAO SDK interface\n",
        "job_id = tao_client.create_job(**job_params)\n",
        "\n",
        "print(\"Train job created successfully!\")\n",
        "print(f\"Job ID: {job_id}\")\n",
        "print(f\"Job Name: {job_name}\")\n",
        "print(f\"Network Architecture: {model_name}\")\n",
        "print(f\"Action: train\")\n",
        "\n",
        "job_map[\"train_\" + model_name] = job_id\n",
        "print(\"\\nJob Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Monitor job status using TAO SDK\n",
        "# For automl: Training times for different models benchmarked on 1 GPU V100 machine can be found here: https://docs.nvidia.com/tao/tao-toolkit/text/automl/automl.html#results-of-automl-experiments\n",
        "\n",
        "train_job_id = job_map[\"train_\" + model_name]\n",
        "\n",
        "while True:\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(train_job_id)\n",
        "        \n",
        "        print(f\"Training Job Status\")\n",
        "        print(f\"Job ID: {train_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Training job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\" Job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "## To Stop an AutoML JOB\n",
        "#    1. Stop the 'Monitor job status by repeatedly running this cell' cell (the cell right before this cell) manually\n",
        "#    2. Uncomment the snippet in the next cell and run the cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# # Pause AutoML job using TAO SDK\n",
        "# if automl_enabled:\n",
        "#     train_job_id = job_map[\"train_\" + model_name]\n",
        "#     try:\n",
        "#         pause_result = tao_client.pause_job(train_job_id)\n",
        "#         print(\"Job paused successfully!\")\n",
        "#         print(json.dumps(pause_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to pause job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "## Resume AutoML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # Resume AutoML job using TAO SDK\n",
        "# # Uncomment the below snippet if you want to resume an already stopped AutoML job and then run the 'Monitor job status' cell above\n",
        "# if automl_enabled:\n",
        "#     train_job_id = job_map[\"train_\" + model_name]\n",
        "#     try:\n",
        "#         resume_result = tao_client.resume_job(\n",
        "#             job_id=train_job_id,\n",
        "#             parent_job_id=None,\n",
        "#             specs=json.dumps(train_specs)\n",
        "#         )\n",
        "#         print(\"Job resumed successfully!\")\n",
        "#         print(json.dumps(resume_result, indent=4))\n",
        "#     except Exception as e:\n",
        "#         print(f\" Failed to resume job: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Publish model"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Edit the method of choosing checkpoint from list of train checkpoint files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Model handler parameters are managed differently\n",
        "# Checkpoint selection is handled during job creation rather than experiment-level settings\n",
        "# For now, we'll use the default checkpoint selection method\n",
        "print(\"In TAO, checkpoint selection is managed per-job rather than per-experiment\")\n",
        "print(\"Using default checkpoint selection method: best_model\")\n",
        "\n",
        "update_checkpoint_choosing = {\n",
        "    \"checkpoint_choose_method\": \"best_model\",\n",
        "    \"checkpoint_epoch_number\": {}\n",
        "}\n",
        "print(\"Current checkpoint choosing configuration:\")\n",
        "print(json.dumps(update_checkpoint_choosing, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Checkpoint method configuration\n",
        "# Checkpoint selection is handled per-job, not per-experiment\n",
        "# You can configure this when creating export/inference jobs if needed\n",
        "\n",
        "# Example: Change checkpoint selection method for future jobs\n",
        "update_checkpoint_choosing[\"checkpoint_choose_method\"] = \"latest_model\"  # Choose between best_model/latest_model/from_epoch_number\n",
        "# Note: If from_epoch_number is chosen, you would specify the epoch in job creation specs\n",
        "\n",
        "print(\"Checkpoint selection configuration updated:\")\n",
        "print(f\"Method: {update_checkpoint_choosing['checkpoint_choose_method']}\")\n",
        "print(\"This will be applied to future job creations\")\n",
        "print(json.dumps(update_checkpoint_choosing, sort_keys=True, indent=4))\n",
        "\n",
        "updated_job = tao_client.update_job(job_id=job_map[\"train_\" + model_name], update_data=update_checkpoint_choosing)\n",
        "print(json.dumps(updated_job, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Push model to private ngc team registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Publish model using TAO SDK\n",
        "train_job_id = job_map[\"train_\" + model_name]\n",
        "\n",
        "try:\n",
        "    publish_result = tao_client.publish_model(\n",
        "        job_id=train_job_id,\n",
        "        display_name=f\"TAO {model_name}\",\n",
        "        description=f\"Trained {model_name} model\",\n",
        "        team_name=\"tao\"\n",
        "    )\n",
        "    \n",
        "    print(\"Model published successfully to NGC!\")\n",
        "    print(f\"Job ID: {train_job_id}\")\n",
        "    print(f\"Display Name: TAO {model_name}\")\n",
        "    print(f\"Team: tao\")\n",
        "    print(\"\\nPublish Response:\")\n",
        "    print(json.dumps(publish_result, indent=4))\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\" Failed to publish model: {str(e)}\")\n",
        "    print(\"Make sure the job completed successfully and you have appropriate permissions\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Remove model from private ngc team registry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# # Remove published model using TAO SDK\n",
        "# train_job_id = job_map[\"train_\" + model_name]\n",
        "# try:\n",
        "#     remove_result = tao_client.remove_published_model(\n",
        "#         job_id=train_job_id,\n",
        "#         team=\"tao\"\n",
        "#     )\n",
        "#     print(\"Published model removed successfully!\")\n",
        "#     print(json.dumps(remove_result, indent=4))\n",
        "# except Exception as e:\n",
        "#     print(f\" Failed to remove published model: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Evaluate <a class=\"anchor\" id=\"head-13\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default eval specs using TAO SDK\n",
        "eval_spec_response = tao_client.get_job_schema(action=\"evaluate\", network_arch=model_name)\n",
        "eval_specs = eval_spec_response.get(\"default\", {})\n",
        "print(\"Default evaluate specifications:\")\n",
        "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Apply changes to the specs if required\n",
        "print(json.dumps(eval_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Create evaluate job using TAO SDK\n",
        "parent_job_id = job_map[\"train_\" + model_name]\n",
        "eval_job_name = f\"{model_name}_eval_job\"\n",
        "\n",
        "eval_job_id = tao_client.create_job(\n",
        "    kind=\"experiment\",\n",
        "    name=eval_job_name,\n",
        "    network_arch=model_name,\n",
        "    encryption_key=encode_key,\n",
        "    workspace=workspace_id,\n",
        "    eval_dataset=eval_dataset_id,\n",
        "    action=\"evaluate\",\n",
        "    specs=eval_specs,  # Pass as dict, not JSON string\n",
        "    parent_job_id=parent_job_id,\n",
        "    base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "    # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        ")\n",
        "\n",
        "print(\"Evaluate job created successfully!\")\n",
        "print(f\"Evaluate Job ID: {eval_job_id}\")\n",
        "print(f\"Parent Job ID: {parent_job_id}\")\n",
        "print(f\"Action: evaluate\")\n",
        "\n",
        "job_map[\"evaluate_\" + model_name] = eval_job_id\n",
        "print(\"\\nUpdated Job Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Monitor evaluate job status using TAO SDK\n",
        "eval_job_id = job_map[\"evaluate_\" + model_name]\n",
        "\n",
        "while True:    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(eval_job_id)\n",
        "        \n",
        "        print(f\"Evaluate Job Status\")\n",
        "        print(f\"Job ID: {eval_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Evaluate job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Evaluate job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\"Evaluate job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching inference job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### TAO inference <a class=\"anchor\" id=\"head-14\"></a>\n",
        "\n",
        "- Run inference on a set of images using the .tlt model created at train step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Get default inference specs using TAO SDK\n",
        "inference_spec_response = tao_client.get_job_schema(action=\"inference\", network_arch=model_name)\n",
        "tao_inference_specs = inference_spec_response.get(\"default\", {})\n",
        "print(\"Default inference specifications:\")\n",
        "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Apply changes to specs if necessary\n",
        "print(json.dumps(tao_inference_specs, sort_keys=True, indent=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Create inference job using TAO SDK\n",
        "parent_job_id = job_map[\"train_\" + model_name]\n",
        "inference_job_name = f\"{model_name}_inference_job\"\n",
        "\n",
        "inference_job_id = tao_client.create_job(\n",
        "    kind=\"experiment\",\n",
        "    name=inference_job_name,\n",
        "    network_arch=model_name,\n",
        "    encryption_key=encode_key,\n",
        "    workspace=workspace_id,\n",
        "    inference_dataset=eval_dataset_id,\n",
        "    action=\"inference\",\n",
        "    specs=tao_inference_specs,  # Pass as dict, not JSON string\n",
        "    parent_job_id=parent_job_id,\n",
        "    base_experiment_ids=[selected_ptm_id] if selected_ptm_id else None,\n",
        "    # platform_id=\"9af1aa90-8ea5-5a11-98d9-3879cd0da92c\",  # Optional: Pick from get_gpu_types output\n",
        ")\n",
        "\n",
        "print(\"Inference job created successfully!\")\n",
        "print(f\"Inference Job ID: {inference_job_id}\")\n",
        "print(f\"Parent Job ID: {parent_job_id}\")\n",
        "print(f\"Action: inference\")\n",
        "\n",
        "job_map[\"inference_tao_\" + model_name] = inference_job_id\n",
        "print(\"\\nUpdated Job Map:\")\n",
        "print(json.dumps(job_map, indent=4))\n",
        "%store job_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor inference job status using TAO SDK\n",
        "inference_job_id = job_map[\"inference_tao_\" + model_name]\n",
        "\n",
        "while True:    \n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    try:\n",
        "        job_status = tao_client.get_job_metadata(inference_job_id)\n",
        "        \n",
        "        print(f\" Inference Job Status\")\n",
        "        print(f\"Job ID: {inference_job_id}\")\n",
        "        print(f\"Status: {job_status.get('status', 'Unknown')}\")\n",
        "        print(f\"Progress: {job_status.get('progress', 'N/A')}\")\n",
        "        \n",
        "        # Show detailed status information\n",
        "        print(\"\\nDetailed Status:\")\n",
        "        print(json.dumps(job_status.get(\"job_details\", {}), sort_keys=True, indent=4))\n",
        "        \n",
        "        current_status = job_status.get(\"status\", \"Unknown\")\n",
        "        \n",
        "        if current_status == \"Error\":\n",
        "            raise Exception(\"Inference job failed!\")\n",
        "            \n",
        "        if current_status in [\"Done\", \"Completed\"]:\n",
        "            print(\"Inference job completed successfully!\")\n",
        "            break\n",
        "            \n",
        "        if current_status in [\"Canceled\", \"Paused\"]:\n",
        "            print(f\" Inference job {current_status}\")\n",
        "            break\n",
        "            \n",
        "    except Exception as e:\n",
        "        if \"failed\" in str(e).lower():\n",
        "            raise\n",
        "        print(f\" Error fetching inference job status: {str(e)}\")\n",
        "        print(\"Job might still be starting up...\")\n",
        "        \n",
        "    time.sleep(15)"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Delete Jobs<a class=\"anchor\" id=\"head-22\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Delete jobs instead of experiments\n",
        "# Delete all created jobs using TAO SDK\n",
        "\n",
        "print(\" Deleting all created jobs...\")\n",
        "\n",
        "jobs_to_delete = []\n",
        "for job_key, job_id in job_map.items():\n",
        "    try:\n",
        "        delete_result = tao_client.delete_job(job_id)\n",
        "        print(f\" Deleted job: {job_key} (ID: {job_id})\")\n",
        "    except Exception as e:\n",
        "        print(f\" Failed to delete job {job_key} (ID: {job_id}): {str(e)}\")\n",
        "\n",
        "print(f\"\\n Job cleanup completed! Processed {len(jobs_to_delete)} jobs.\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "### Delete dataset <a class=\"anchor\" id=\"head-16\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Delete train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Delete train dataset using TAO SDK\n",
        "try:\n",
        "    delete_result = tao_client.delete_dataset(train_dataset_id)\n",
        "    print(\"Train dataset deleted successfully!\")\n",
        "    print(f\"Dataset ID: {train_dataset_id}\")\n",
        "    if delete_result:\n",
        "        print(\"Delete Response:\")\n",
        "        print(json.dumps(delete_result, indent=4))\n",
        "except Exception as e:\n",
        "    print(f\" Failed to delete train dataset {train_dataset_id}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
   "metadata": {},
      "source": [
        "#### Delete val dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
   "metadata": {},
      "outputs": [],
      "source": [
        "# Delete eval dataset using TAO SDK\n",
        "try:\n",
        "    delete_result = tao_client.delete_dataset(eval_dataset_id)\n",
        "    print(\"Eval dataset deleted successfully!\")\n",
        "    print(f\"Dataset ID: {eval_dataset_id}\")\n",
        "    if delete_result:\n",
        "        print(\"Delete Response:\")\n",
        "        print(json.dumps(delete_result, indent=4))\n",
        "except Exception as e:\n",
        "    print(f\" Failed to delete eval dataset {eval_dataset_id}: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
