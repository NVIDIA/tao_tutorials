{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Inspection using TAO Siamese Network\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n",
    "\n",
    "Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "<img align=\"center\" src=\"https://d29g4g2dyqv443.cloudfront.net/sites/default/files/akamai/TAO/tlt-tao-toolkit-bring-your-own-model-diagram.png\" width=\"1080\">\n",
    "\n",
    "## What is a Siamese Network?\n",
    "\n",
    "A Siamese Network is a class of neural network architectures that contain two or more identical subnetworks.\n",
    "The training algorithm works by updating the parameters across all the sub-networks in tandem.\n",
    "It is used to find the similarity between the inputs by computing the Euclidean distance between the feature vectors.\n",
    "In this specific use case, the inputs are a \"golden or reference\" image and the image of the PCB component under inspection.\n",
    "\n",
    "### Sample inference from the optical inspection siamese model\n",
    "\n",
    "| **Pass** | **Fail** |\n",
    "| :--: | :--: |\n",
    "|<img align=\"center\" title=\"no defects\" src=\"https://github.com/vpraveen-nv/model_card_images/blob/main/cv/notebook/optical_inspection/pass.png?raw=true\" width=\"400\" > no defects | <img align=\"center\" title=\"missing component\" src=\"https://github.com/vpraveen-nv/model_card_images/blob/main/cv/notebook/optical_inspection/defect.png?raw=true\" width=\"400\" >  missing component |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
    "\n",
    "* Train a Siamese Network for Optical Inspection on PCB Dataset.\n",
    "* Explore options to combine images of multiple LED light sources within Siamese Network \n",
    "* Evaluate the trained model & results.\n",
    "* Run Inference on the trained model.\n",
    "* Export the trained model to a .onnx file (encrypted ONNX model) for deployment to DeepStream or TensorRT.\n",
    "\n",
    "At the end of this notebook, you will have generated a trained and optimized `opticalinspection` model, \n",
    "which you may deploy with this [end-to-end sample](https://github.com/NVIDIA-AI-IOT/tao-toolkit-triton-apps) with Triton.\n",
    "\n",
    "Siamese Network TAO Features:\n",
    "\n",
    "* Combine multiple LED intensities, camera angles or different sensory inputs for image-pair comparison within Siamese Network\n",
    "    * Multiple Inputs (1....N)\n",
    "* Mode of concat\n",
    "    * Linear concat (1 X N)\n",
    "    * Grid concat (N X M)\n",
    "* Backbone networks supported for Siamese\n",
    "    * Custom\n",
    "* Backbone with pre-trained weights\n",
    "    * Yes\n",
    "    * No\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook shows an example usecase of Siamese Network using Train Adapt Optimize (TAO) Toolkit.\n",
    "\n",
    "0. [Set up env variables and map drives](#head-0)\n",
    "1. [Installing the TAO launcher](#head-1)\n",
    "2. [Prepare dataset](#head-2)\n",
    "3. [Download the pretrained model from NGC](#head-3)\n",
    "4. [Provide training specification](#head-4)\n",
    "5. [Run TAO training](#head-5)\n",
    "6. [Evaluate trained models](#head-6)\n",
    "7. [Inferences](#head-7)\n",
    "8. [Deploy](#head-8)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables and map drives <a class=\"anchor\" id=\"head-0\"></a>\n",
    "\n",
    "The TAO launcher uses docker containers under the hood, and **for our data and results directory to be visible to the docker, they need to be mapped**. The launcher can be configured using the config file `~/.tao_mounts.json`. Apart from the mounts, you can also configure additional options like the Environment Variables and amount of Shared Memory available to the TAO launcher. <br>\n",
    "\n",
    "`IMPORTANT NOTE:` The code below creates a sample `~/.tao_mounts.json`  file. Here, we can map directories in which we save the data, specs, results and cache. You should configure it for your specific case so these directories are correctly visible to the docker container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Please define this local project directory that needs to be mapped to the TAO docker session.\n",
    "%env LOCAL_PROJECT_DIR=FIXME\n",
    "\n",
    "os.environ[\"HOST_DATA_DIR\"] = os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()), \"data\", \"optical_inspection\")\n",
    "os.environ[\"HOST_RESULTS_DIR\"] = os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()), \"optical_inspection\", \"results\")\n",
    "os.environ[\"HOST_MODEL_DIR\"] = os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\", os.getcwd()), \"optical_inspection\", \"model\")\n",
    "\n",
    "# Set this path if you don't run the notebook from the samples directory.\n",
    "# %env NOTEBOOK_ROOT=/path/to/local/tao-experiments/optical_inspection\n",
    "# The sample spec files are present in the same path as the downloaded samples.\n",
    "os.environ[\"HOST_SPECS_DIR\"] = os.path.join(\n",
    "    os.getenv(\"NOTEBOOK_ROOT\", os.getcwd()),\n",
    "    \"specs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $HOST_DATA_DIR\n",
    "! mkdir -p $HOST_SPECS_DIR\n",
    "! mkdir -p $HOST_RESULTS_DIR\n",
    "! mkdir -p $HOST_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping up the local directories to the TAO docker.\n",
    "import json\n",
    "import os\n",
    "mounts_file = os.path.expanduser(\"~/.tao_mounts.json\")\n",
    "tlt_configs = {\n",
    "   \"Mounts\":[\n",
    "       # Mapping the data directory\n",
    "       {\n",
    "           \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "           \"destination\": \"/workspace/tao-experiments\"\n",
    "       },\n",
    "       {\n",
    "           \"source\": os.environ[\"HOST_DATA_DIR\"],\n",
    "           \"destination\": \"/data\"\n",
    "       },\n",
    "       {\n",
    "           \"source\": os.environ[\"HOST_MODEL_DIR\"],\n",
    "           \"destination\": \"/model\"\n",
    "       },\n",
    "       {\n",
    "           \"source\": os.environ[\"HOST_SPECS_DIR\"],\n",
    "           \"destination\": \"/specs\"\n",
    "       },\n",
    "       {\n",
    "           \"source\": os.environ[\"HOST_RESULTS_DIR\"],\n",
    "           \"destination\": \"/results\"\n",
    "       }\n",
    "   ],\n",
    "   \"DockerOptions\": {\n",
    "        \"shm_size\": \"16G\",\n",
    "        \"ulimits\": {\n",
    "            \"memlock\": -1,\n",
    "            \"stack\": 67108864\n",
    "         }\n",
    "   }\n",
    "}\n",
    "# Writing the mounts file.\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(tlt_configs, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/.tao_mounts.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing the TAO launcher <a class=\"anchor\" id=\"head-1\"></a>\n",
    "The TAO launcher is a python package distributed as a python wheel listed in PyPI. You may install the launcher by executing the following cell.\n",
    "\n",
    "Please note that TAO Toolkit recommends users to run the TAO launcher in a virtual env with python 3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the `virtualenv` and `virtualenvwrapper` packages. Once you have setup virtualenvwrapper, please set the version of python to be used in the virtual env by using the `VIRTUALENVWRAPPER_PYTHON` variable. You may do so by running\n",
    "\n",
    "```sh\n",
    "export VIRTUALENVWRAPPER_PYTHON=/path/to/bin/python3.x\n",
    "```\n",
    "where x >= 6 and <= 8\n",
    "\n",
    "We recommend performing this step first and then launching the notebook from the virtual environment. In addition to installing TAO python package, please make sure of the following software requirements:\n",
    "* python >=3.7, <=3.10.x\n",
    "* docker-ce > 19.03.5\n",
    "* docker-API 1.40\n",
    "* nvidia-container-toolkit > 1.3.0-1\n",
    "* nvidia-container-runtime > 3.4.0-1\n",
    "* nvidia-docker2 > 2.5.0-1\n",
    "* nvidia-driver > 455+\n",
    "\n",
    "Once you have installed the pre-requisites, please log in to the docker registry nvcr.io by following the command below\n",
    "\n",
    "```sh\n",
    "docker login nvcr.io\n",
    "```\n",
    "\n",
    "You will be triggered to enter a username and password. The username is `$oauthtoken` and the password is the API key generated from `ngc.nvidia.com`. Please follow the instructions in the [NGC setup guide](https://docs.nvidia.com/ngc/ngc-overview/index.html#generating-api-key) to generate your own API key.\n",
    "\n",
    "Please note that TAO Toolkit recommends users to run the TAO launcher in a virtual env with python >=3.6.9. You may follow the instruction in this [page](https://virtualenvwrapper.readthedocs.io/en/latest/install.html) to set up a python virtual env using the virtualenv and virtualenvwrapper packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP this step IF you have already installed the TAO launcher.\n",
    "!pip3 install nvidia-tao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the versions of the TAO launcher\n",
    "!tao info --verbose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare a sample dataset <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    "TAO optical inspection trainer uses a custom dataset format. The sections below walk through this format, specifically how the dataset should be structured and the files required."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optical Inspection data format\n",
    "\n",
    "Optical Inspection expects directories of images and csv files in the dataset root directory. The image directory consists of golden images (non-defective reference images) and test images to be\n",
    "compared with golden samples for PCB defect classification.  \n",
    "\n",
    "\n",
    "    |--dataset_root:\n",
    "       |--images\n",
    "            |--input:\n",
    "               |--C1.jpg\n",
    "               |--C2.jpg\n",
    "            |--golden:\n",
    "               |--C1.jpg\n",
    "               |--C2.jpg\n",
    "            |--input1:\n",
    "               |--C1.jpg\n",
    "               |--C3.jpg\n",
    "            |--golden1:\n",
    "               |--C1.jpg\n",
    "               |--C3.jpg\n",
    "       |--labels\n",
    "           |-- train.csv\n",
    "           |-- validation.csv\n",
    "\n",
    "Here's a description of the structure:\n",
    "\n",
    "* The images directory contains the following:\n",
    "    * input: Directory containing input images to be compared with golden images\n",
    "    * golden: Directory containing golden reference images\n",
    "* The labels directory contains the csv files for pair-wise images input to the SiameseOI model with corresponding class labels. Details of this file are included in the `Label Files` section below. \n",
    "\n",
    "#### Label Files\n",
    "\n",
    "A SiameseOI label file is a simple csv file containing the following fields.\n",
    "\n",
    "| **input_path** | **golden_path** | **label** | **object_name** |\n",
    "| :-- | :-- | :--- | :--- |\n",
    "| `/path/to/input/image/directory` | `/path/to/golden/image/directory` | The class to which the object belongs | `/component/name` |\n",
    "\n",
    "Here's a description of the structure:\n",
    "\n",
    "* ``input_path``: The path to the directory containing input compare image\n",
    "* ``golden_path``: The path to the directory containing corresponding golden reference image\n",
    "* ``label``: The labels for the pair-wise images (Use `PASS` for non-defective components, and any other specific defect type label for defective components).\n",
    "* ``object_name``: The name of the component to be compared. The object name is the same for input and golden images and represents the image name without the file extension.\n",
    "    * For each :code:`object_name`, TAO supports combining multiple LED intensities, camera angles or different sensory inputs for each of the input and golden images to be\n",
    "      compared within the SiameseOI model. For more details, refer to the :ref:`Input Mapping<input_map_siamese>` section below.\n",
    "\n",
    "Here is a sample label file corresponding to the sample directory structure as describe in the :ref:`Optical Inspection Format <optical_inspection_format>` section.\n",
    "\n",
    "| **input_path** | **golden_path** | **label** | **object_name** |\n",
    "| :-- | :-- | :--- | :--- |\n",
    "| /dataset_root/images/input/  | /dataset_root/images/golden/  | PASS      | C1  |\n",
    "| /dataset_root/images/input/  | /dataset_root/images/golden/  | PASS      | C2  |\n",
    "| /dataset_root/images/input1/ | /dataset_root/images/golden1/ | MISSING   | C1  |\n",
    "| /dataset_root/images/input1/ | /dataset_root/images/golden1/ | PASS      | C3  |\n",
    "\n",
    "``Note``: In the label file, ensure that non-defective samples are consistently labeled as PASS, \n",
    "while defective samples can be assigned any specific defect type label. \n",
    "The model is designed to treat all defects collectively and train for binary defect classification.\n",
    "\n",
    "#### Input Mapping\n",
    "\n",
    "TAO supports combining several lighting conditions (1...N) for each image-golden pair to be combined for comparison within Siamese Network. The following modes are supported: \n",
    "\n",
    "* Linear concat (1 x N)\n",
    "* Grid concat (M x N)\n",
    "\n",
    "Each `object_name` is appended with name of the lighting condition as specified in the experiment spec under `input_map`. Here is an example of dataset experiment spec changes for combining 4 input lighting conditions as a 1x4 linear grid:\n",
    "\n",
    "```yaml\n",
    "    dataset: \n",
    "        num_input: 4\n",
    "        concat_type: linear\n",
    "        input_map:\n",
    "            LowAngleLight: 0\n",
    "            SolderLight: 1\n",
    "            UniformLight: 2\n",
    "            WhiteLight: 3\n",
    "```\n",
    "\n",
    "The dataset also supports single lighting condition per input-golden image pair as input to the Siamese Network. Here is an example of dataset experiment spec changes for single lighting condition where `object_name` represents the image name:\n",
    "\n",
    "```yaml\n",
    "    dataset: \n",
    "        num_inputs: 1\n",
    "        input_map: null\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify\n",
    "!ls -l $HOST_DATA_DIR/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download the pretrained model from NGC <a class=\"anchor\" id=\"head-3\"></a>\n",
    "\n",
    "Download the pretrained model from NGC. We will use NGC CLI to get the data and model. For more details, go to https://ngc.nvidia.com and click the SETUP on the navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing NGC CLI on the local machine.\n",
    "## Download and install\n",
    "import os\n",
    "import platform\n",
    "\n",
    "if platform.machine() == \"x86_64\":\n",
    "    os.environ[\"CLI\"]=\"ngccli_linux.zip\"\n",
    "else:\n",
    "    os.environ[\"CLI\"]=\"ngccli_arm64.zip\"\n",
    "\n",
    "\n",
    "# # Remove any previously existing CLI installations\n",
    "!rm -rf $HOST_RESULTS_DIR/ngccli/*\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $HOST_RESULTS_DIR/ngccli\n",
    "!unzip -u \"$HOST_RESULTS_DIR/ngccli/$CLI\" -d $HOST_RESULTS_DIR/ngccli/\n",
    "!rm $HOST_RESULTS_DIR/ngccli/*.zip\n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"HOST_RESULTS_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model list nvidia/tao/optical_inspection:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $HOST_RESULTS_DIR/pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ngc registry model download-version \"nvidia/tao/optical_inspection:trainable_v1.0\" --dest $HOST_RESULTS_DIR/pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $HOST_RESULTS_DIR/pretrained/optical_inspection_vtrainable_v1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Provide training specification <a class=\"anchor\" id=\"head-4\"></a>\n",
    "\n",
    "We provide specification files to configure the training parameters including:\n",
    "\n",
    "* model:\n",
    "  * model_type: Siamese_3\n",
    "  * model_backbone: custom\n",
    "  * embedding_vectors: 5\n",
    "  * margin: 2.0\n",
    "* dataset:\n",
    "  * train_dataset:\n",
    "    * csv_path: /data/dataset_convert/train_combined.csv\n",
    "    * images_dir: /data/images/\n",
    "  * validation_dataset:\n",
    "    * csv_path: /data/dataset_convert/valid_combined.csv\n",
    "    * images_dir: /data/images/\n",
    "  * test_dataset:\n",
    "    * csv_path: /data/dataset_convert/valid_combined.csv\n",
    "    * images_dir: /data/images/\n",
    "  * infer_dataset:\n",
    "    * csv_path: /data/dataset_convert/valid_combined.csv\n",
    "    * images_dir: /data/images/\n",
    "  * image_ext: .jpg\n",
    "  * batch_size: 4\n",
    "  * workers: 1\n",
    "  * fpratio_sampling: 0.1\n",
    "  * num_input: 4\n",
    "  * input_map:\n",
    "    * LowAngleLight: 0\n",
    "    * SolderLight: 1\n",
    "    * UniformLight: 2\n",
    "    * WhiteLight: 3\n",
    "  * concat_type: linear\n",
    "  * grid_map:\n",
    "    * x: 2\n",
    "    * y: 2\n",
    "  * image_width: 128\n",
    "  * image_height: 128\n",
    "  * augmentation_config:\n",
    "    * rgb_input_mean: [0.485, 0.456, 0.406]\n",
    "    * rgb_input_std: [0.229, 0.224, 0.225]\n",
    "* train:\n",
    "  * optim:\n",
    "    * type: Adam\n",
    "    * lr: 0.0005\n",
    "  * loss: contrastive\n",
    "  * epochs: 5\n",
    "  * checkpoint_interval: 5\n",
    "  * results_dir: results/train\n",
    "  * tensorboard:\n",
    "    * enabled: True\n",
    " \n",
    "Please refer to the TAO documentation about Optical Inspection to get all the parameters that are configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat $HOST_SPECS_DIR/experiment.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run TAO training <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* Provide the sample spec file and the output directory location for models.\n",
    "* WARNING: Training will take several hours or one day to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The following paths are set from the perspective of the TAO Docker.\n",
    "# The data is saved here\n",
    "%env DATA_DIR = /data\n",
    "%env MODEL_DIR = /model\n",
    "%env SPECS_DIR = /specs\n",
    "%env RESULTS_DIR = /results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Train Siamese model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a Siamese model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Train model\")\n",
    "!tao model optical_inspection train \\\n",
    "                  -e $SPECS_DIR/experiment.yaml \\\n",
    "                  train.pretrained_model_path=$RESULTS_DIR/pretrained/optical_inspection_vtrainable_v1.0/oi_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training command for multi-gpu training. We can define the number of gpus and specify which GPU's are to be used by setting the `train.gpu_ids` parameter.\n",
    "## The following command will trigger multi-gpu training on gpu 0 and gpu 1.\n",
    "# !tao model optical_inspection train \\\n",
    "#                   -e $SPECS_DIR/experiment.yaml \\\n",
    "#                   train.gpu_ids=[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model checkpoints:')\n",
    "!ls -ltrh $HOST_RESULTS_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set NUM_EPOCH to the epoch corresponding to any saved checkpoint\n",
    "# %env NUM_EPOCH=029\n",
    "\n",
    "# Get the name of the checkpoint corresponding to your set epoch\n",
    "# tmp=!ls $HOST_RESULTS_DIR/train/*.pth | grep epoch_$NUM_EPOCH\n",
    "# %env CHECKPOINT={tmp[0]}\n",
    "\n",
    "# Or get the latest checkpoint\n",
    "os.environ[\"CHECKPOINT\"] = os.path.join(os.getenv(\"HOST_RESULTS_DIR\"), \"train/oi_model_latest.pth\")\n",
    "\n",
    "print('Rename a trained model: ')\n",
    "print('---------------------')\n",
    "!cp $CHECKPOINT $HOST_RESULTS_DIR/train/oi_model.pth\n",
    "!ls -ltrh $HOST_RESULTS_DIR/train/oi_model.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate trained models <a class=\"anchor\" id=\"head-6\"></a>\n",
    "Evaluate trained model.\n",
    "\n",
    "For Siamese model evaluation, we use the following metrics:\n",
    "\n",
    "* Defect Accuracy: Defect detection accurary.\n",
    "* False Positive Rate (FPR): False Alarm Rate for for non-defective samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao model optical_inspection evaluate \\\n",
    "                   -e $SPECS_DIR/experiment.yaml \\\n",
    "                    evaluate.checkpoint=$RESULTS_DIR/train/oi_model.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inferences <a class=\"anchor\" id=\"head-7\"></a>\n",
    "In this section, we run the optical inspection inference tool to generate inferences with the trained models and save the results under `$RESULTS_DIR`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao model optical_inspection inference \\\n",
    "                   -e $SPECS_DIR/experiment.yaml \\\n",
    "                    inference.checkpoint=$RESULTS_DIR/train/oi_model.pth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deploy <a class=\"anchor\" id=\"head-8\"></a>\n",
    "Export the model to encrypted ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $HOST_RESULTS_DIR/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!tao model optical_inspection export \\\n",
    "                    -e $SPECS_DIR/experiment.yaml \\\n",
    "                    export.checkpoint=$RESULTS_DIR/train/oi_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment this cell to export an onnx file with dynamic batching enabled for\n",
    "# # integration with trtexec and deepstream.\n",
    "# # Export the model with export.batch_size=-1 for dynamic batching.\n",
    "# ! tao model optical_inspection export \\\n",
    "#                     -e $SPECS_DIR/experiment.yaml \\\n",
    "#                     export.batch_size=-1 \\\n",
    "#                     export.results_dir=$RESULTS_DIR/export_dynamic\n",
    "#                     export.checkpoint=$RESULTS_DIR/train/oi_model.pth\n",
    "\n",
    "# # Profiling the exported model via trtexec.\n",
    "# ! tao deploy trtexec --onnx=$RESULTS_DIR/export_dynamic/oi_model.onnx \\\n",
    "#                      --minShapes=input_1:1x3x512x128,input_2:1x3x512x128 \\\n",
    "#                      --optShapes=input_1:8x3x512x128,input_2:8x3x512x128 \\\n",
    "#                      --maxShapes=input_1:16x3x512x128,input_2:16x3x512x128 \\\n",
    "#                      --fp16 \\\n",
    "#                      --saveEngine=$RESULTS_DIR/export_dynamic/oi_model_fp16.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lth $HOST_RESULTS_DIR/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao deploy optical_inspection gen_trt_engine \\\n",
    "            -e $SPECS_DIR/experiment.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tao deploy optical_inspection inference \\\n",
    "            -e $SPECS_DIR/experiment.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may continue by deploying the exported model to [TensorRT](https://developer.nvidia.com/tensorrt) for optimized inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
